{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkIHgprez3Cn",
        "outputId": "695a2358-e154-46af-ae24-a3a5ce94db03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Air_temperature  Process_temperature  Rotational_speed  Target  \\\n",
            "0             295.7                306.2              2270       1   \n",
            "1             295.8                306.3              1235       1   \n",
            "2             295.3                305.7              1473       0   \n",
            "3             295.4                305.9              1518       0   \n",
            "4             296.3                307.2              1319       1   \n",
            "5             296.4                307.4              2833       1   \n",
            "6             295.4                305.8              1526       0   \n",
            "7             295.4                305.8              1407       0   \n",
            "8             295.5                306.1              1650       0   \n",
            "9             295.6                306.2              1584       0   \n",
            "10            297.5                308.1              1334       1   \n",
            "11            297.6                309.6              1501       1   \n",
            "12            297.7                308.5              1373       1   \n",
            "13            297.8                307.3              1327       1   \n",
            "14            295.9                306.6              1678       0   \n",
            "15            295.9                306.5              1594       0   \n",
            "16            295.9                306.4              1892       0   \n",
            "17            295.9                306.4              1575       0   \n",
            "18            295.9                306.6              1532       0   \n",
            "19            297.2                307.9              1825       0   \n",
            "20            297.2                307.9              1469       0   \n",
            "21            303.6                312.0              1309       1   \n",
            "22            303.6                312.2              1371       1   \n",
            "23            303.6                312.8              2659       1   \n",
            "24            303.7                311.9              1332       1   \n",
            "25            303.7                312.0              2663       1   \n",
            "26            302.9                311.2              1330       1   \n",
            "27            303.0                311.2              1374       1   \n",
            "28            303.4                311.9              1377       0   \n",
            "\n",
            "                Failure_Type  \n",
            "0              Power Failure  \n",
            "1              Power Failure  \n",
            "2                 No Failure  \n",
            "3                 No Failure  \n",
            "4              Power Failure  \n",
            "5              Power Failure  \n",
            "6                 No Failure  \n",
            "7                 No Failure  \n",
            "8                 No Failure  \n",
            "9                 No Failure  \n",
            "10             Power Failure  \n",
            "11        Overstrain Failure  \n",
            "12        Overstrain Failure  \n",
            "13        Overstrain Failure  \n",
            "14                No Failure  \n",
            "15                No Failure  \n",
            "16                No Failure  \n",
            "17                No Failure  \n",
            "18                No Failure  \n",
            "19                No Failure  \n",
            "20                No Failure  \n",
            "21  Heat Dissipation Failure  \n",
            "22  Heat Dissipation Failure  \n",
            "23             Power Failure  \n",
            "24  Heat Dissipation Failure  \n",
            "25             Power Failure  \n",
            "26  Heat Dissipation Failure  \n",
            "27  Heat Dissipation Failure  \n",
            "28  Heat Dissipation Failure  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DF = pd.read_csv(\"/content/predictive_maintenance_nn.csv\")\n",
        "print(DF)\n",
        "\n",
        "DF.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DF.drop([], axis=1)\n",
        "DF.drop(columns=['Failure_Type'], inplace=True)\n",
        "DF.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2MOrAEJ0ik3",
        "outputId": "5466193d-0b4a-4bd8-99d8-dfc1ff2df5ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WBUh64U9j-BK",
        "outputId": "5c45a517-57ab-40fc-b170-857ce6058561"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Air_temperature  Process_temperature  Rotational_speed  Target\n",
              "0            295.7                306.2              2270       1\n",
              "1            295.8                306.3              1235       1\n",
              "2            295.3                305.7              1473       0\n",
              "3            295.4                305.9              1518       0\n",
              "4            296.3                307.2              1319       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0577af59-c722-4161-9814-f93bd97234e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Air_temperature</th>\n",
              "      <th>Process_temperature</th>\n",
              "      <th>Rotational_speed</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>295.7</td>\n",
              "      <td>306.2</td>\n",
              "      <td>2270</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>295.8</td>\n",
              "      <td>306.3</td>\n",
              "      <td>1235</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>295.3</td>\n",
              "      <td>305.7</td>\n",
              "      <td>1473</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>295.4</td>\n",
              "      <td>305.9</td>\n",
              "      <td>1518</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>296.3</td>\n",
              "      <td>307.2</td>\n",
              "      <td>1319</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0577af59-c722-4161-9814-f93bd97234e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0577af59-c722-4161-9814-f93bd97234e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0577af59-c722-4161-9814-f93bd97234e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(DF.iloc[:,-1]).T\n",
        "y = np.array([y]).T\n",
        "# print(\"y is\\n\", y)"
      ],
      "metadata": {
        "id": "paAZwz5P0ijE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalize the data (not the label!)\n",
        "## or min/max\n",
        "## normalized_df=(df-df.min())/(df.max()-df.min())\n",
        "\n",
        "DF=DF.iloc[:, [0, 1, 2]]\n",
        "DF=(DF-DF.mean())/DF.std()\n",
        "print(DF)\n",
        "X = np.array(DF)\n",
        "# print(\"X is\\n\", X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4I3mlG-0ibK",
        "outputId": "db72fcfc-96d6-434e-b4fb-ce36a9bf489c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Air_temperature  Process_temperature  Rotational_speed\n",
            "0         -0.756038            -0.837934          1.476756\n",
            "1         -0.726208            -0.797299         -0.919181\n",
            "2         -0.875359            -1.041112         -0.368231\n",
            "3         -0.845529            -0.959841         -0.264060\n",
            "4         -0.577058            -0.431578         -0.724728\n",
            "5         -0.547228            -0.350307          2.780053\n",
            "6         -0.845529            -1.000477         -0.245541\n",
            "7         -0.845529            -1.000477         -0.521016\n",
            "8         -0.815698            -0.878570          0.041509\n",
            "9         -0.785868            -0.837934         -0.111276\n",
            "10        -0.219097            -0.065858         -0.690004\n",
            "11        -0.189267             0.543676         -0.303414\n",
            "12        -0.159437             0.096685         -0.599723\n",
            "13        -0.129607            -0.390943         -0.706209\n",
            "14        -0.696378            -0.675392          0.106326\n",
            "15        -0.696378            -0.716027         -0.088126\n",
            "16        -0.696378            -0.756663          0.601718\n",
            "17        -0.696378            -0.756663         -0.132110\n",
            "18        -0.696378            -0.675392         -0.231651\n",
            "19        -0.308587            -0.147129          0.446619\n",
            "20        -0.308587            -0.147129         -0.377491\n",
            "21         1.600538             1.518931         -0.747877\n",
            "22         1.600538             1.600202         -0.604352\n",
            "23         1.600538             1.844016          2.377258\n",
            "24         1.630368             1.478295         -0.694634\n",
            "25         1.630368             1.518931          2.386518\n",
            "26         1.391728             1.193846         -0.699264\n",
            "27         1.421558             1.193846         -0.597408\n",
            "28         1.540878             1.478295         -0.590463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Set y to the label. Check the shape!\n",
        "InputColumns = 3\n",
        "NumberOfLabels = 2\n",
        "n = len(DF) ## number of rows of entire X\n",
        "## Take the label off of X and make it a numpy array\n",
        "\n",
        "LR=.01\n",
        "LRB = .01\n",
        "#................................................\n",
        "\n",
        "  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "class NeuralNetwork(object):\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.InputNumColumns = InputColumns  \n",
        "        self.OutputSize = 1 \n",
        "        self.HiddenUnits = 3  \n",
        "        self.n = n  \n",
        "        \n",
        "        # print(\"Initialize NN\\n\")\n",
        "        #Random W1\n",
        "        self.W1 = np.random.randn(self.InputNumColumns, self.HiddenUnits) # c by h  \n",
        "       \n",
        "        # print(\"INIT W1 is\\n\", self.W1)\n",
        "              \n",
        "        self.W2 = np.random.randn(self.HiddenUnits, self.OutputSize) # h by o \n",
        "        # print(\"W2 is:\\n\", self.W2)\n",
        "        \n",
        "        self.b = np.random.randn(1, self.HiddenUnits)\n",
        "        # print(\"The b's are:\\n\", self.b)\n",
        "        ## biases for layer 1\n",
        "        \n",
        "        self.c = np.random.randn(1, self.OutputSize)\n",
        "        # print(\"The c is\\n\", self.c)\n",
        "        ## bias for last layer\n",
        "        \n",
        "        \n",
        "    def FeedForward(self, X):\n",
        "        # print(\"FeedForward\\n\\n\")\n",
        "        self.z = (np.dot(X, self.W1)) + self.b \n",
        "        #X is n by c   W1  is c by h -->  n by h\n",
        "        # print(\"Z1 is:\\n\", self.z)\n",
        "        \n",
        "        self.h = self.Sigmoid(self.z) #activation function    shape: n by h\n",
        "        # print(\"H is:\\n\", self.h)\n",
        "        \n",
        "        self.z2 = (np.dot(self.h, self.W2)) + self.c # n by h  @  h by o  -->  n by o  \n",
        "        # print(\"Z2 is:\\n\", self.z2)\n",
        "        \n",
        "        ## Using Softmax for the output activation\n",
        "        output = self.Sigmoid(self.z2)  \n",
        "        # print(\"output Y^ is:\\n\", output)\n",
        "        return output\n",
        "        \n",
        "    def Sigmoid(self, s, deriv=False):\n",
        "        if (deriv == True):\n",
        "            return s * (1 - s)\n",
        "        return 1/(1 + np.exp(-s))\n",
        "\n",
        "    def BackProp(self, X, y, output):\n",
        "        # print(\"\\n\\nBackProp\\n\")\n",
        "        self.LR = LR\n",
        "        self.LRB=LRB  ## LR for biases\n",
        "        \n",
        "        # Y^ - Y\n",
        "        self.output_error = output - y    \n",
        "        # print(\"Y^ - Y\\n\", self.output_error)\n",
        "        \n",
        "        self.output_delta = self.output_error \n",
        "          \n",
        "        ##(Y^ - Y)(W2)\n",
        "        self.D_Error_W2 = self.output_delta.dot(self.W2.T) #  D_Error times W2\n",
        "        \n",
        "        self.H_D_Error_W2 = self.D_Error_W2 * self.Sigmoid(self.h, deriv=True) \n",
        "\n",
        "        self.X_H_D_Error_W2 = X.T.dot(self.H_D_Error_W2) ## this is dW1\n",
        "        \n",
        "        ## (H)T (Y^ - Y) - \n",
        "        self.h_output_delta = self.h.T.dot(self.output_delta) ## this is for dW2\n",
        "\n",
        "        # print(\"Using sum gradient........\\n\")\n",
        "        self.W1 = self.W1 - self.LR*(self.X_H_D_Error_W2) # c by h  adjusting first set (input -> hidden) weights\n",
        "        self.W2 = self.W2 - self.LR*(self.h_output_delta) \n",
        "        \n",
        "        \n",
        "        print(\"The sum of the b update is\\n\", np.mean(self.H_D_Error_W2, axis=0))\n",
        "        print(\"The b biases before the update are:\\n\", self.b)\n",
        "        self.b = self.b  - self.LRB*np.mean(self.H_D_Error_W2, axis=0)\n",
        "        #print(\"The H_D_Error_W2 is...\\n\", self.H_D_Error_W2)\n",
        "        print(\"Updated bs are:\\n\", self.b)\n",
        "        \n",
        "        self.c = self.c - self.LR*np.mean(self.output_delta, axis=0)\n",
        "        #print(\"Updated c's are:\\n\", self.c)\n",
        "        \n",
        "        print(\"The W1 is: \\n\", self.W1)\n",
        "        print(\"The W1 gradient is: \\n\", self.X_H_D_Error_W2)\n",
        "        #print(\"The W1 gradient average is: \\n\", self.X_H_D_Error_W2/self.n)\n",
        "        print(\"The W2 gradient  is: \\n\", self.h_output_delta)\n",
        "        #print(\"The W2 gradient average is: \\n\", self.h_output_delta/self.n)\n",
        "        print(\"The biases b gradient is:\\n\",np.mean(self.H_D_Error_W2, axis=0 ))\n",
        "        print(\"The bias c gradient is: \\n\", np.mean(self.output_delta, axis=0))\n",
        "        ################################################################\n",
        "        \n",
        "    def TrainNetwork(self, X, y):\n",
        "        output = self.FeedForward(X)\n",
        "        # print(\"Output in TNN\\n\", output)\n",
        "        self.BackProp(X, y, output)\n",
        "        return output\n",
        "\n",
        "#-------------------------------------------------------------------        \n"
      ],
      "metadata": {
        "id": "xylhSh_y0iNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyNN = NeuralNetwork()\n",
        "\n",
        "TotalLoss=[]\n",
        "AvgLoss=[]\n",
        "Epochs=125\n",
        "\n",
        "for i in range(Epochs): \n",
        "    print(\"\\nRUN:\\n \", i)\n",
        "    output=MyNN.TrainNetwork(X, y)\n",
        "   \n",
        "    #print(\"The y is ...\\n\", y)\n",
        "    # print(\"The output is: \\n\", output)\n",
        "    output=np.where(output > 0.5, 1, 0)\n",
        "    # print('Prediction y^ is', output)\n",
        "    ## Using Categorical Cross Entropy...........\n",
        "    #loss = np.mean(-y * np.log(output))  ## We need y to place the \"1\" in the right place\n",
        "    loss=np.sum(np.square(output-y))\n",
        "    avgLoss=np.mean(np.square(output-y))\n",
        "    # print(\"The current average loss is\\n\", loss)\n",
        "    TotalLoss.append(loss)\n",
        "    AvgLoss.append(avgLoss)\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlUrd5Wf9Jcl",
        "outputId": "8acf7e29-83ae-4192-f3b3-92eee4d8fc83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RUN:\n",
            "  0\n",
            "The sum of the b update is\n",
            " [0.0353159  0.13986796 0.14865783]\n",
            "The b biases before the update are:\n",
            " [[-0.18261125 -0.67317763  0.04706044]]\n",
            "Updated bs are:\n",
            " [[-0.18296441 -0.67457631  0.04557386]]\n",
            "The W1 is: \n",
            " [[-0.78844571 -0.44157535 -0.24329369]\n",
            " [-2.62270796  0.14210698 -0.32708958]\n",
            " [-1.18362469 -2.35772911 -1.38048495]]\n",
            "The W1 gradient is: \n",
            " [[-0.62156471 -3.08798506 -3.28731882]\n",
            " [-0.61587025 -3.29467513 -3.46154226]\n",
            " [-0.23179148 -0.51829165 -0.49157852]]\n",
            "The W2 gradient  is: \n",
            " [[10.10938587]\n",
            " [ 5.21591527]\n",
            " [ 7.36030606]]\n",
            "The biases b gradient is:\n",
            " [0.0353159  0.13986796 0.14865783]\n",
            "The bias c gradient is: \n",
            " [0.3237595]\n",
            "\n",
            "RUN:\n",
            "  1\n",
            "The sum of the b update is\n",
            " [0.03141656 0.1327038  0.14193681]\n",
            "The b biases before the update are:\n",
            " [[-0.18296441 -0.67457631  0.04557386]]\n",
            "Updated bs are:\n",
            " [[-0.18327857 -0.67590335  0.04415449]]\n",
            "The W1 is: \n",
            " [[-0.78287024 -0.41222402 -0.2117333 ]\n",
            " [-2.61715291  0.17349978 -0.293762  ]\n",
            " [-1.18142333 -2.35271189 -1.37551698]]\n",
            "The W1 gradient is: \n",
            " [[-0.55754697 -2.93513348 -3.15603878]\n",
            " [-0.55550442 -3.13928052 -3.33275784]\n",
            " [-0.22013695 -0.50172222 -0.49679676]]\n",
            "The W2 gradient  is: \n",
            " [[9.89406084]\n",
            " [4.97153063]\n",
            " [7.07732955]]\n",
            "The biases b gradient is:\n",
            " [0.03141656 0.1327038  0.14193681]\n",
            "The bias c gradient is: \n",
            " [0.31483052]\n",
            "\n",
            "RUN:\n",
            "  2\n",
            "The sum of the b update is\n",
            " [0.02764876 0.12541114 0.13483229]\n",
            "The b biases before the update are:\n",
            " [[-0.18327857 -0.67590335  0.04415449]]\n",
            "Updated bs are:\n",
            " [[-0.18355506 -0.67715746  0.04280617]]\n",
            "The W1 is: \n",
            " [[-0.77791666 -0.38437479 -0.18151373]\n",
            " [-2.61218808  0.20335627 -0.26176448]\n",
            " [-1.17935561 -2.34790979 -1.37055887]]\n",
            "The W1 gradient is: \n",
            " [[-0.49535812 -2.78492257 -3.02195713]\n",
            " [-0.49648294 -2.98564926 -3.19975219]\n",
            " [-0.20677176 -0.48020992 -0.49581152]]\n",
            "The W2 gradient  is: \n",
            " [[9.65594769]\n",
            " [4.71978204]\n",
            " [6.78002734]]\n",
            "The biases b gradient is:\n",
            " [0.02764876 0.12541114 0.13483229]\n",
            "The bias c gradient is: \n",
            " [0.30478401]\n",
            "\n",
            "RUN:\n",
            "  3\n",
            "The sum of the b update is\n",
            " [0.02404786 0.11807104 0.12744833]\n",
            "The b biases before the update are:\n",
            " [[-0.18355506 -0.67715746  0.04280617]]\n",
            "Updated bs are:\n",
            " [[-0.18379554 -0.67833817  0.04153169]]\n",
            "The W1 is: \n",
            " [[-0.7735613  -0.3579964  -0.15265529]\n",
            " [-2.60779485  0.2317005  -0.2311303 ]\n",
            " [-1.17743631 -2.34336448 -1.36566689]]\n",
            "The W1 gradient is: \n",
            " [[-0.43553597 -2.63783945 -2.88584412]\n",
            " [-0.43932391 -2.83442295 -3.06341809]\n",
            " [-0.19192952 -0.45453117 -0.48919736]]\n",
            "The W2 gradient  is: \n",
            " [[9.39547255]\n",
            " [4.46127463]\n",
            " [6.46968464]]\n",
            "The biases b gradient is:\n",
            " [0.02404786 0.11807104 0.12744833]\n",
            "The bias c gradient is: \n",
            " [0.29366877]\n",
            "\n",
            "RUN:\n",
            "  4\n",
            "The sum of the b update is\n",
            " [0.020647   0.11076343 0.11989481]\n",
            "The b biases before the update are:\n",
            " [[-0.18379554 -0.67833817  0.04153169]]\n",
            "Updated bs are:\n",
            " [[-0.18400201 -0.6794458   0.04033274]]\n",
            "The W1 is: \n",
            " [[-0.76977539 -0.33305189 -0.12516858]\n",
            " [-2.60394958  0.25856374 -0.20188157]\n",
            " [-1.17567734 -2.33910968 -1.36089045]]\n",
            "The W1 gradient is: \n",
            " [[-0.37859172 -2.4944507  -2.74867072]\n",
            " [-0.38452689 -2.68632337 -2.92487312]\n",
            " [-0.17589736 -0.42547958 -0.47764402]]\n",
            "The W2 gradient  is: \n",
            " [[9.11387979]\n",
            " [4.19705349]\n",
            " [6.14817777]]\n",
            "The biases b gradient is:\n",
            " [0.020647   0.11076343 0.11989481]\n",
            "The bias c gradient is: \n",
            " [0.28156605]\n",
            "\n",
            "RUN:\n",
            "  5\n",
            "The sum of the b update is\n",
            " [0.01747543 0.1035647  0.11228277]\n",
            "The b biases before the update are:\n",
            " [[-0.18400201 -0.6794458   0.04033274]]\n",
            "Updated bs are:\n",
            " [[-0.18417677 -0.68048145  0.03920991]]\n",
            "The W1 is: \n",
            " [[-0.76652555 -0.30949804 -0.09905283]\n",
            " [-2.6006241   0.28398506 -0.17402736]\n",
            " [-1.17408734 -2.33517122 -1.3562712 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.32498338 -2.35538523 -2.61157519]\n",
            " [-0.33254756 -2.54213179 -2.78542039]\n",
            " [-0.15899968 -0.39384637 -0.46192486]]\n",
            "The W2 gradient  is: \n",
            " [[8.81324091]\n",
            " [3.92857703]\n",
            " [5.81792218]]\n",
            "The biases b gradient is:\n",
            " [0.01747543 0.1035647  0.11228277]\n",
            "The bias c gradient is: \n",
            " [0.26858936]\n",
            "\n",
            "RUN:\n",
            "  6\n",
            "The sum of the b update is\n",
            " [0.01455693 0.09654536 0.10471964]\n",
            "The b biases before the update are:\n",
            " [[-0.18417677 -0.68048145  0.03920991]]\n",
            "Updated bs are:\n",
            " [[-0.18432233 -0.6814469   0.03816271]]\n",
            "The W1 is: \n",
            " [[-0.76377464 -0.28728506 -0.07429482]\n",
            " [-2.59778637  0.30801155 -0.14756257]\n",
            " [-1.17267156 -2.33156721 -1.35184259]]\n",
            "The W1 gradient is: \n",
            " [[-0.27509099 -2.22129799 -2.47580102]\n",
            " [-0.28377355 -2.40264905 -2.64647928]\n",
            " [-0.14157851 -0.36040064 -0.44286179]]\n",
            "The W2 gradient  is: \n",
            " [[8.49638564]\n",
            " [3.65765235]\n",
            " [5.48176873]]\n",
            "The biases b gradient is:\n",
            " [0.01455693 0.09654536 0.10471964]\n",
            "The bias c gradient is: \n",
            " [0.25488118]\n",
            "\n",
            "RUN:\n",
            "  7\n",
            "The sum of the b update is\n",
            " [0.01190858 0.08976769 0.09730452]\n",
            "The b biases before the update are:\n",
            " [[-0.18432233 -0.6814469   0.03816271]]\n",
            "Updated bs are:\n",
            " [[-0.18444142 -0.68234458  0.03718967]]\n",
            "The W1 is: \n",
            " [[-0.76148267 -0.26635682 -0.05086865]\n",
            " [-2.59540132  0.330698   -0.12246759]\n",
            " [-1.17143183 -2.32830852 -1.34762971]]\n",
            "The W1 gradient is: \n",
            " [[-0.22919701 -2.09282357 -2.34261757]\n",
            " [-0.23850472 -2.26864542 -2.5094982 ]\n",
            " [-0.12397284 -0.32586926 -0.42128804]]\n",
            "The W2 gradient  is: \n",
            " [[8.1667586 ]\n",
            " [3.3863377 ]\n",
            " [5.14285742]]\n",
            "The biases b gradient is:\n",
            " [0.01190858 0.08976769 0.09730452]\n",
            "The bias c gradient is: \n",
            " [0.24060676]\n",
            "\n",
            "RUN:\n",
            "  8\n",
            "The sum of the b update is\n",
            " [0.00954012 0.08328394 0.09012429]\n",
            "The b biases before the update are:\n",
            " [[-0.18444142 -0.68234458  0.03718967]]\n",
            "Updated bs are:\n",
            " [[-0.18453682 -0.68317742  0.03628843]]\n",
            "The W1 is: \n",
            " [[-0.75960793 -0.24665153 -0.02873627]\n",
            " [-2.59343191  0.3521061  -0.09870895]\n",
            " [-1.17036684 -2.32539934 -1.34364959]]\n",
            "The W1 gradient is: \n",
            " [[-0.18747444 -1.97052883 -2.21323718]\n",
            " [-0.19694054 -2.14080969 -2.37586368]\n",
            " [-0.10649909 -0.29091774 -0.39801162]]\n",
            "The W2 gradient  is: \n",
            " [[7.82821838]\n",
            " [3.11682282]\n",
            " [4.8044454 ]]\n",
            "The biases b gradient is:\n",
            " [0.00954012 0.08328394 0.09012429]\n",
            "The bias c gradient is: \n",
            " [0.22594573]\n",
            "\n",
            "RUN:\n",
            "  9\n",
            "The sum of the b update is\n",
            " [0.00745378 0.07713497 0.08325071]\n",
            "The b biases before the update are:\n",
            " [[-0.18453682 -0.68317742  0.03628843]]\n",
            "Updated bs are:\n",
            " [[-0.18461136 -0.68394877  0.03545592]]\n",
            "The W1 is: \n",
            " [[-0.75810809 -0.22810281 -0.00784886]\n",
            " [-2.59184015  0.37230316 -0.07624076]\n",
            " [-1.16947249 -2.322838   -1.33991176]]\n",
            "The W1 gradient is: \n",
            " [[-0.149984   -1.85487243 -2.08874126]\n",
            " [-0.15917592 -2.01970586 -2.24681922]\n",
            " [-0.08943521 -0.25613374 -0.37378254]]\n",
            "The W2 gradient  is: \n",
            " [[7.48480557]\n",
            " [2.85130154]\n",
            " [4.46973054]]\n",
            "The biases b gradient is:\n",
            " [0.00745378 0.07713497 0.08325071]\n",
            "The bias c gradient is: \n",
            " [0.21108253]\n",
            "\n",
            "RUN:\n",
            "  10\n",
            "The sum of the b update is\n",
            " [0.00564477 0.0713498  0.07673888]\n",
            "The b biases before the update are:\n",
            " [[-0.18461136 -0.68394877  0.03545592]]\n",
            "Updated bs are:\n",
            " [[-0.18466781 -0.68466227  0.03468853]]\n",
            "The W1 is: \n",
            " [[-0.75694129 -0.21064104  0.01185139]\n",
            " [-2.5905881   0.39136059 -0.05500672]\n",
            " [-1.16874239 -2.32061785 -1.3364191 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.11668022 -1.74617693 -1.97002482]\n",
            " [-0.12520551 -1.90574339 -2.12340431]\n",
            " [-0.07300978 -0.22201509 -0.34926686]]\n",
            "The W2 gradient  is: \n",
            " [[7.14051057]\n",
            " [2.59185212]\n",
            " [4.14169123]]\n",
            "The biases b gradient is:\n",
            " [0.00564477 0.0713498  0.07673888]\n",
            "The bias c gradient is: \n",
            " [0.19619692]\n",
            "\n",
            "RUN:\n",
            "  11\n",
            "The sum of the b update is\n",
            " [0.00410215 0.06594581 0.07062696]\n",
            "The b biases before the update are:\n",
            " [[-0.18466781 -0.68466227  0.03468853]]\n",
            "Updated bs are:\n",
            " [[-0.18470883 -0.68532172  0.03398226]]\n",
            "The W1 is: \n",
            " [[-0.75606704 -0.19419488  0.03042903]\n",
            " [-2.58963875  0.40935223 -0.03494253]\n",
            " [-1.16816842 -2.31872822 -1.3331688 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.08742476 -1.64461579 -1.8577643 ]\n",
            " [-0.09493509 -1.79916359 -2.00641852]\n",
            " [-0.05739665 -0.18896362 -0.32502947]]\n",
            "The W2 gradient  is: \n",
            " [[6.79906864]\n",
            " [2.340338  ]\n",
            " [3.82295915]]\n",
            "The biases b gradient is:\n",
            " [0.00410215 0.06594581 0.07062696]\n",
            "The bias c gradient is: \n",
            " [0.18145571]\n",
            "\n",
            "RUN:\n",
            "  12\n",
            "The sum of the b update is\n",
            " [0.00281013 0.06092969 0.06493718]\n",
            "The b biases before the update are:\n",
            " [[-0.18470883 -0.68532172  0.03398226]]\n",
            "Updated bs are:\n",
            " [[-0.18473693 -0.68593102  0.03333289]]\n",
            "The W1 is: \n",
            " [[-0.75544699 -0.17869273  0.04795312]\n",
            " [-2.58895677  0.42635264 -0.01597842]\n",
            " [-1.16774127 -2.31715537 -1.33015354]]\n",
            "The W1 gradient is: \n",
            " [[-0.06200457 -1.55021485 -1.75240864]\n",
            " [-0.06819777 -1.70004158 -1.89641107]\n",
            " [-0.04271483 -0.15728494 -0.30152622]]\n",
            "The W2 gradient  is: \n",
            " [[6.46380209]\n",
            " [2.09833703]\n",
            " [3.51573394]]\n",
            "The biases b gradient is:\n",
            " [0.00281013 0.06092969 0.06493718]\n",
            "The bias c gradient is: \n",
            " [0.16700644]\n",
            "\n",
            "RUN:\n",
            "  13\n",
            "The sum of the b update is\n",
            " [0.00174936 0.05629885 0.05967765]\n",
            "The b biases before the update are:\n",
            " [[-0.18473693 -0.68593102  0.03333289]]\n",
            "Updated bs are:\n",
            " [[-0.18475442 -0.68649401  0.03273611]]\n",
            "The W1 is: \n",
            " [[-7.55045470e-01 -1.64064081e-01  6.44950173e-02]\n",
            " [-2.58850904e+00  4.42435652e-01  1.95849665e-03]\n",
            " [-1.16745095e+00 -2.31588343e+00 -1.32736249e+00]]\n",
            "The W1 gradient is: \n",
            " [[-0.04015222 -1.46286542 -1.65419009]\n",
            " [-0.04477254 -1.60830099 -1.79369188]\n",
            " [-0.02903256 -0.12719376 -0.27910466]]\n",
            "The W2 gradient  is: \n",
            " [[6.13751836]\n",
            " [1.86710199]\n",
            " [3.22174188]]\n",
            "The biases b gradient is:\n",
            " [0.00174936 0.05629885 0.05967765]\n",
            "The bias c gradient is: \n",
            " [0.15297338]\n",
            "\n",
            "RUN:\n",
            "  14\n",
            "The sum of the b update is\n",
            " [0.00089833 0.05204312 0.05484468]\n",
            "The b biases before the update are:\n",
            " [[-0.18475442 -0.68649401  0.03273611]]\n",
            "Updated bs are:\n",
            " [[-0.18476341 -0.68701444  0.03218767]]\n",
            "The W1 is: \n",
            " [[-0.75482981 -0.15024063  0.08012651]\n",
            " [-2.58826502  0.45767302  0.01894208]\n",
            " [-1.1672872  -2.3148952  -1.32478238]]\n",
            "The W1 gradient is: \n",
            " [[-0.02156595 -1.38234539 -1.56314919]\n",
            " [-0.0244028  -1.52373725 -1.69835825]\n",
            " [-0.01637428 -0.09882331 -0.25801148]]\n",
            "The W2 gradient  is: \n",
            " [[5.8224636 ]\n",
            " [1.64755021]\n",
            " [2.9422337 ]]\n",
            "The biases b gradient is:\n",
            " [0.00089833 0.05204312 0.05484468]\n",
            "The bias c gradient is: \n",
            " [0.13945584]\n",
            "\n",
            "RUN:\n",
            "  15\n",
            "The sum of the b update is\n",
            " [0.00023459 0.04814658 0.0504254 ]\n",
            "The b biases before the update are:\n",
            " [[-0.18476341 -0.68701444  0.03218767]]\n",
            "Updated bs are:\n",
            " [[-0.18476575 -0.68749591  0.03168341]]\n",
            "The W1 is: \n",
            " [[-0.75477053 -0.13715719  0.09491819]\n",
            " [-2.58819688  0.47213347  0.03504538]\n",
            " [-1.16723991 -2.31417282 -1.32239833]]\n",
            "The W1 gradient is: \n",
            " [[-0.00592767 -1.30834415 -1.47916776]\n",
            " [-0.00681313 -1.44604505 -1.61033047]\n",
            " [-0.00472896 -0.07223742 -0.23840469]]\n",
            "The W2 gradient  is: \n",
            " [[5.52032362]\n",
            " [1.44027696]\n",
            " [2.67801313]]\n",
            "The biases b gradient is:\n",
            " [0.00023459 0.04814658 0.0504254 ]\n",
            "The bias c gradient is: \n",
            " [0.12652837]\n",
            "\n",
            "RUN:\n",
            "  16\n",
            "The sum of the b update is\n",
            " [-0.00026431  0.04458925  0.04640019]\n",
            "The b biases before the update are:\n",
            " [[-0.18476575 -0.68749591  0.03168341]]\n",
            "Updated bs are:\n",
            " [[-0.18476311 -0.6879418   0.03121941]]\n",
            "The W1 is: \n",
            " [[-0.75484136 -0.1247523   0.10893823]\n",
            " [-2.58827965  0.48588194  0.05033929]\n",
            " [-1.16729933 -2.31369838 -1.32019465]]\n",
            "The W1 gradient is: \n",
            " [[ 0.00708217 -1.24048814 -1.40200475]\n",
            " [ 0.00827659 -1.37484654 -1.52939063]\n",
            " [ 0.00594119 -0.04744368 -0.2203681 ]]\n",
            "The W2 gradient  is: \n",
            " [[5.23226039]\n",
            " [1.24558583]\n",
            " [2.4294863 ]]\n",
            "The biases b gradient is:\n",
            " [-0.00026431  0.04458925  0.04640019]\n",
            "The bias c gradient is: \n",
            " [0.1142425]\n",
            "\n",
            "RUN:\n",
            "  17\n",
            "The sum of the b update is\n",
            " [-0.00061999  0.04134859  0.04274495]\n",
            "The b biases before the update are:\n",
            " [[-0.18476311 -0.6879418   0.03121941]]\n",
            "Updated bs are:\n",
            " [[-0.18475691 -0.68835529  0.03079196]]\n",
            "The W1 is: \n",
            " [[-0.75501909 -0.11296866  0.12225154]\n",
            " [-2.58849106  0.49897911  0.06489149]\n",
            " [-1.16745625 -2.31345432 -1.31815539]]\n",
            "The W1 gradient is: \n",
            " [[ 0.01777323 -1.17836448 -1.33133065]\n",
            " [ 0.02114044 -1.3097174  -1.45522016]\n",
            " [ 0.0156927  -0.02440632 -0.20392637]]\n",
            "The W2 gradient  is: \n",
            " [[4.9589716 ]\n",
            " [1.0635291 ]\n",
            " [2.19672234]]\n",
            "The biases b gradient is:\n",
            " [-0.00061999  0.04134859  0.04274495]\n",
            "The bias c gradient is: \n",
            " [0.10262929]\n",
            "\n",
            "RUN:\n",
            "  18\n",
            "The sum of the b update is\n",
            " [-0.00085272  0.03840083  0.03943297]\n",
            "The b biases before the update are:\n",
            " [[-0.18475691 -0.68835529  0.03079196]]\n",
            "Updated bs are:\n",
            " [[-0.18474838 -0.68873929  0.03039763]]\n",
            "The W1 is: \n",
            " [[-0.75528346 -0.10175325  0.13491912]\n",
            " [-2.58881144  0.51148121  0.07876583]\n",
            " [-1.16770219 -2.31342374 -1.31626479]]\n",
            "The W1 gradient is: \n",
            " [[ 0.02643732 -1.12154125 -1.26675828]\n",
            " [ 0.03203868 -1.25020927 -1.38743338]\n",
            " [ 0.02459378 -0.00305811 -0.18905931]]\n",
            "The W2 gradient  is: \n",
            " [[4.70076176]\n",
            " [0.89395237]\n",
            " [1.97951732]]\n",
            "The biases b gradient is:\n",
            " [-0.00085272  0.03840083  0.03943297]\n",
            "The bias c gradient is: \n",
            " [0.09170251]\n",
            "\n",
            "RUN:\n",
            "  19\n",
            "The sum of the b update is\n",
            " [-0.00098112  0.03572191  0.03643645]\n",
            "The b biases before the update are:\n",
            " [[-0.18474838 -0.68873929  0.03039763]]\n",
            "Updated bs are:\n",
            " [[-0.18473857 -0.68909651  0.03003327]]\n",
            "The W1 is: \n",
            " [[-0.7556169  -0.09105741  0.14699781]\n",
            " [-2.58922357  0.52343989  0.09202188]\n",
            " [-1.16802938 -2.31359064 -1.31450765]]\n",
            "The W1 gradient is: \n",
            " [[ 0.03334343 -1.06958381 -1.20786831]\n",
            " [ 0.04121282 -1.19586787 -1.32560563]\n",
            " [ 0.03271867  0.01668945 -0.1757145 ]]\n",
            "The W2 gradient  is: \n",
            " [[4.45761602]\n",
            " [0.73653873]\n",
            " [1.77745603]]\n",
            "The biases b gradient is:\n",
            " [-0.00098112  0.03572191  0.03643645]\n",
            "The bias c gradient is: \n",
            " [0.0814618]\n",
            "\n",
            "RUN:\n",
            "  20\n",
            "The sum of the b update is\n",
            " [-0.00102194  0.03328825  0.03372762]\n",
            "The b biases before the update are:\n",
            " [[-0.18473857 -0.68909651  0.03003327]]\n",
            "Updated bs are:\n",
            " [[-0.18472835 -0.6894294   0.02969599]]\n",
            "The W1 is: \n",
            " [[-0.75600425 -0.08083674  0.1585401 ]\n",
            " [-2.5897124   0.53490235  0.10471484]\n",
            " [-1.16843081 -2.31394001 -1.31286947]]\n",
            "The W1 gradient is: \n",
            " [[ 0.03873518 -1.02206717 -1.15422953]\n",
            " [ 0.04888297 -1.14624677 -1.26929549]\n",
            " [ 0.04014326  0.03493775 -0.16381785]]\n",
            "The W2 gradient  is: \n",
            " [[4.22927061]\n",
            " [0.59084972]\n",
            " [1.58996779]]\n",
            "The biases b gradient is:\n",
            " [-0.00102194  0.03328825  0.03372762]\n",
            "The bias c gradient is: \n",
            " [0.07189571]\n",
            "\n",
            "RUN:\n",
            "  21\n",
            "The sum of the b update is\n",
            " [-0.00099005  0.03107729  0.03127956]\n",
            "The b biases before the update are:\n",
            " [[-0.18472835 -0.6894294   0.02969599]]\n",
            "Updated bs are:\n",
            " [[-0.18471845 -0.68974017  0.02938319]]\n",
            "The W1 is: \n",
            " [[-0.75643255 -0.07105089  0.16959424]\n",
            " [-2.59026487  0.54591153  0.11689545]\n",
            " [-1.16890023 -2.31445796 -1.31133665]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04283011 -0.9785847  -1.10541393]\n",
            " [ 0.05524684 -1.10091724 -1.21806165]\n",
            " [ 0.04694195  0.05179447 -0.15328216]]\n",
            "The W2 gradient  is: \n",
            " [[4.01527596]\n",
            " [0.4563612 ]\n",
            " [1.41637457]]\n",
            "The biases b gradient is:\n",
            " [-0.00099005  0.03107729  0.03127956]\n",
            "The bias c gradient is: \n",
            " [0.06298447]\n",
            "\n",
            "RUN:\n",
            "  22\n",
            "The sum of the b update is\n",
            " [-0.0008985   0.02906779  0.02906675]\n",
            "The b biases before the update are:\n",
            " [[-0.18471845 -0.68974017  0.02938319]]\n",
            "Updated bs are:\n",
            " [[-0.18470947 -0.69003085  0.02909253]]\n",
            "The W1 is: \n",
            " [[-0.75689075 -0.06166335  0.18020432]\n",
            " [-2.59086967  0.55650627  0.1286102 ]\n",
            " [-1.16943208 -2.31513164 -1.30989651]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04582023 -0.93875388 -1.0610075 ]\n",
            " [ 0.06048    -1.05947469 -1.17147483]\n",
            " [ 0.05318547  0.06736866 -0.14401362]]\n",
            "The W2 gradient  is: \n",
            " [[3.81505093]\n",
            " [0.33249357]\n",
            " [1.25593077]]\n",
            "The biases b gradient is:\n",
            " [-0.0008985   0.02906779  0.02906675]\n",
            "The bias c gradient is: \n",
            " [0.05470234]\n",
            "\n",
            "RUN:\n",
            "  23\n",
            "The sum of the b update is\n",
            " [-0.00075857  0.02724005  0.02706538]\n",
            "The b biases before the update are:\n",
            " [[-0.18470947 -0.69003085  0.02909253]]\n",
            "Updated bs are:\n",
            " [[-0.18470188 -0.69030325  0.02882187]]\n",
            "The W1 is: \n",
            " [[-0.75736949 -0.05264116  0.19041049]\n",
            " [-2.59151704  0.5667217   0.13990146]\n",
            " [-1.17002148 -2.31594932 -1.30853735]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04787352 -0.90221951 -1.0206173 ]\n",
            " [ 0.06473698 -1.02154253 -1.12912595]\n",
            " [ 0.05893958  0.08176719 -0.13591662]]\n",
            "The W2 gradient  is: \n",
            " [[3.62792751]\n",
            " [0.21863629]\n",
            " [1.1078551 ]]\n",
            "The biases b gradient is:\n",
            " [-0.00075857  0.02724005  0.02706538]\n",
            "The bias c gradient is: \n",
            " [0.04701958]\n",
            "\n",
            "RUN:\n",
            "  24\n",
            "The sum of the b update is\n",
            " [-0.00057997  0.02557598  0.0252535 ]\n",
            "The b biases before the update are:\n",
            " [[-0.18470188 -0.69030325  0.02882187]]\n",
            "Updated bs are:\n",
            " [[-0.18469608 -0.69055901  0.02856934]]\n",
            "The W1 is: \n",
            " [[-0.75786084 -0.0439546   0.20024925]\n",
            " [-2.59219857  0.57658944  0.15080777]\n",
            " [-1.17066412 -2.31690024 -1.30724837]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04913575 -0.86865519 -0.98387576]\n",
            " [ 0.06815283 -0.98677393 -1.09063101]\n",
            " [ 0.06426437  0.09509241 -0.12889722]]\n",
            "The W2 gradient  is: \n",
            " [[3.45318667]\n",
            " [0.11416715]\n",
            " [0.97135521]]\n",
            "The biases b gradient is:\n",
            " [-0.00057997  0.02557598  0.0252535 ]\n",
            "The bias c gradient is: \n",
            " [0.03990401]\n",
            "\n",
            "RUN:\n",
            "  25\n",
            "The sum of the b update is\n",
            " [-0.00037099  0.02405909  0.02361113]\n",
            "The b biases before the update are:\n",
            " [[-0.18469608 -0.69055901  0.02856934]]\n",
            "Updated bs are:\n",
            " [[-0.18469237 -0.6907996   0.02833323]]\n",
            "The W1 is: \n",
            " [[-0.75835817 -0.03557697  0.20975368]\n",
            " [-2.59290702  0.58613796  0.16136411]\n",
            " [-1.17135626 -2.31797465 -1.30601972]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04973273 -0.83776335 -0.95044281]\n",
            " [ 0.07084491 -0.95485212 -1.05563381]\n",
            " [ 0.06921399  0.10744058 -0.12286537]]\n",
            "The W2 gradient  is: \n",
            " [[3.29008616]\n",
            " [0.01846688]\n",
            " [0.84564606]]\n",
            "The biases b gradient is:\n",
            " [-0.00037099  0.02405909  0.02361113]\n",
            "The bias c gradient is: \n",
            " [0.03332225]\n",
            "\n",
            "RUN:\n",
            "  26\n",
            "The sum of the b update is\n",
            " [-0.00013862  0.02267448  0.02212014]\n",
            "The b biases before the update are:\n",
            " [[-0.18469237 -0.6907996   0.02833323]]\n",
            "Updated bs are:\n",
            " [[-0.18469099 -0.69102634  0.02811202]]\n",
            "The W1 is: \n",
            " [[-0.75885589 -0.02748423  0.21895374]\n",
            " [-2.59363616  0.59539285  0.17160218]\n",
            " [-1.17209463 -2.31916366 -1.30484236]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04977244 -0.80927445 -0.92000651]\n",
            " [ 0.07291478 -0.92548967 -1.02380678]\n",
            " [ 0.0738367   0.11890111 -0.11773633]]\n",
            "The W2 gradient  is: \n",
            " [[ 3.13788149]\n",
            " [-0.06907007]\n",
            " [ 0.72996329]]\n",
            "The biases b gradient is:\n",
            " [-0.00013862  0.02267448  0.02212014]\n",
            "The bias c gradient is: \n",
            " [0.0272407]\n",
            "\n",
            "RUN:\n",
            "  27\n",
            "The sum of the b update is\n",
            " [0.00011124 0.0214087  0.02076424]\n",
            "The b biases before the update are:\n",
            " [[-0.18469099 -0.69102634  0.02811202]]\n",
            "Updated bs are:\n",
            " [[-0.1846921  -0.69124043  0.02790438]]\n",
            "The W1 is: \n",
            " [[-0.75934937 -0.01965477  0.22787657]\n",
            " [-2.59438066  0.60437713  0.18155068]\n",
            " [-1.17287638 -2.32045922 -1.30370804]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04934723 -0.7829455  -0.89228257]\n",
            " [ 0.07445006 -0.89842705 -0.9948508 ]\n",
            " [ 0.07817516  0.12955622 -0.11343149]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.99584128]\n",
            " [-0.14902789]\n",
            " [ 0.62357241]]\n",
            "The biases b gradient is:\n",
            " [0.00011124 0.0214087  0.02076424]\n",
            "The bias c gradient is: \n",
            " [0.02162617]\n",
            "\n",
            "RUN:\n",
            "  28\n",
            "The sum of the b update is\n",
            " [0.00037367 0.02024968 0.01952882]\n",
            "The b biases before the update are:\n",
            " [[-0.1846921  -0.69124043  0.02790438]]\n",
            "Updated bs are:\n",
            " [[-0.18469583 -0.69144293  0.02770909]]\n",
            "The W1 is: \n",
            " [[-0.75983473 -0.01206919  0.2365467 ]\n",
            " [-2.59513593  0.61311143  0.19123563]\n",
            " [-1.17369905 -2.32185403 -1.30260925]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04853583 -0.75855828 -0.86701322]\n",
            " [ 0.07552615 -0.87343087 -0.96849413]\n",
            " [ 0.08226678  0.13948093 -0.10987864]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.86325801]\n",
            " [-0.22196441]\n",
            " [ 0.52577471]]\n",
            "The biases b gradient is:\n",
            " [0.00037367 0.02024968 0.01952882]\n",
            "The bias c gradient is: \n",
            " [0.01644644]\n",
            "\n",
            "RUN:\n",
            "  29\n",
            "The sum of the b update is\n",
            " [0.00064457 0.01918664 0.01840083]\n",
            "The b biases before the update are:\n",
            " [[-0.18469583 -0.69144293  0.02770909]]\n",
            "Updated bs are:\n",
            " [[-0.18470228 -0.69163479  0.02752509]]\n",
            "The W1 is: \n",
            " [[-0.76030878 -0.00471001  0.24498635]\n",
            " [-2.595898    0.62161435  0.20068054]\n",
            " [-1.17456049 -2.32334146 -1.30153913]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04740514 -0.73591737 -0.84396559]\n",
            " [ 0.07620784 -0.8502918  -0.94449089]\n",
            " [ 0.08614421  0.14874333 -0.107012  ]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.73945531]\n",
            " [-0.28840792]\n",
            " [ 0.4359108 ]]\n",
            "The biases b gradient is:\n",
            " [0.00064457 0.01918664 0.01840083]\n",
            "The bias c gradient is: \n",
            " [0.01167058]\n",
            "\n",
            "RUN:\n",
            "  30\n",
            "The sum of the b update is\n",
            " [0.00092057 0.0182099  0.01736863]\n",
            "The b biases before the update are:\n",
            " [[-0.18470228 -0.69163479  0.02752509]]\n",
            "Updated bs are:\n",
            " [[-0.18471149 -0.69181689  0.0273514 ]]\n",
            "The W1 is: \n",
            " [[-7.60768896e-01  2.43846719e-03  2.53215653e-01]\n",
            " [-2.59666351e+00  6.29902577e-01  2.09906727e-01]\n",
            " [-1.17545885e+00 -2.32491551e+00 -1.30049142e+00]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04601192 -0.71484812 -0.82292992]\n",
            " [ 0.07655074 -0.82882254 -0.92261922]\n",
            " [ 0.08983578  0.15740495 -0.10477195]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.62379236]\n",
            " [-0.34885559]\n",
            " [ 0.35336218]]\n",
            "The biases b gradient is:\n",
            " [0.00092057 0.0182099  0.01736863]\n",
            "The bias c gradient is: \n",
            " [0.00726913]\n",
            "\n",
            "RUN:\n",
            "  31\n",
            "The sum of the b update is\n",
            " [0.0011989  0.01731086 0.01642187]\n",
            "The b biases before the update are:\n",
            " [[-0.18471149 -0.69181689  0.0273514 ]]\n",
            "Updated bs are:\n",
            " [[-0.18472347 -0.69199     0.02718718]]\n",
            "The W1 is: \n",
            " [[-0.76121294  0.00939041  0.26125283]\n",
            " [-2.59742954  0.63799113  0.21893352]\n",
            " [-1.17639251 -2.32657072 -1.29946037]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04440423 -0.6951947  -0.80371766]\n",
            " [ 0.07660257 -0.80885572 -0.90267942]\n",
            " [ 0.09336596  0.16552124 -0.10310476]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.51566639]\n",
            " [-0.4037729 ]\n",
            " [ 0.27755159]]\n",
            "The biases b gradient is:\n",
            " [0.0011989  0.01731086 0.01642187]\n",
            "The bias c gradient is: \n",
            " [0.00321432]\n",
            "\n",
            "RUN:\n",
            "  32\n",
            "The sum of the b update is\n",
            " [0.00147729 0.01648181 0.01555134]\n",
            "The b biases before the update are:\n",
            " [[-0.18472347 -0.69199     0.02718718]]\n",
            "Updated bs are:\n",
            " [[-0.18473825 -0.69215482  0.02703167]]\n",
            "The W1 is: \n",
            " [[-0.76163917  0.0161586   0.26911442]\n",
            " [-2.59819358  0.64589355  0.22777844]\n",
            " [-1.17736007 -2.32830214 -1.29844075]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04262267 -0.67681815 -0.78615952]\n",
            " [ 0.07640426 -0.79024197 -0.88449195]\n",
            " [ 0.09675584  0.17314206 -0.10196211]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.41451348]\n",
            " [-0.4535939 ]\n",
            " [ 0.20794226]]\n",
            "The biases b gradient is:\n",
            " [0.00147729 0.01648181 0.01555134]\n",
            "The bias c gradient is: \n",
            " [-0.00051996]\n",
            "\n",
            "RUN:\n",
            "  33\n",
            "The sum of the b update is\n",
            " [0.00175392 0.0157159  0.01474885]\n",
            "The b biases before the update are:\n",
            " [[-0.18473825 -0.69215482  0.02703167]]\n",
            "Updated bs are:\n",
            " [[-0.18475579 -0.69231198  0.02688418]]\n",
            "The W1 is: \n",
            " [[-0.76204618  0.02275454  0.27681546]\n",
            " [-2.59895349  0.65362203  0.2364574 ]\n",
            " [-1.1783603  -2.33010527 -1.29742774]]\n",
            "The W1 gradient is: \n",
            " [[ 0.04070152 -0.65959468 -0.7701037 ]\n",
            " [ 0.0759909  -0.77284801 -0.86789559]\n",
            " [ 0.10002353  0.1803122  -0.10130066]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.3198084 ]\n",
            " [-0.49872209]\n",
            " [ 0.14403662]]\n",
            "The biases b gradient is:\n",
            " [0.00175392 0.0157159  0.01474885]\n",
            "The bias c gradient is: \n",
            " [-0.00395812]\n",
            "\n",
            "RUN:\n",
            "  34\n",
            "The sum of the b update is\n",
            " [0.00202732 0.01500698 0.01400712]\n",
            "The b biases before the update are:\n",
            " [[-0.18475579 -0.69231198  0.02688418]]\n",
            "Updated bs are:\n",
            " [[-0.18477606 -0.69246205  0.02674411]]\n",
            "The W1 is: \n",
            " [[-0.76243288  0.02918868  0.2843696 ]\n",
            " [-2.59970741  0.66118758  0.24498485]\n",
            " [-1.17939215 -2.33197598 -1.29641692]]\n",
            "The W1 gradient is: \n",
            " [[ 0.0386697  -0.64341401 -0.75541411]\n",
            " [ 0.07539264 -0.75655501 -0.85274562]\n",
            " [ 0.10318454  0.18707186 -0.1010816 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.23106365]\n",
            " [-0.53953158]\n",
            " [ 0.0853745 ]]\n",
            "The biases b gradient is:\n",
            " [0.00202732 0.01500698 0.01400712]\n",
            "The bias c gradient is: \n",
            " [-0.00712288]\n",
            "\n",
            "RUN:\n",
            "  35\n",
            "The sum of the b update is\n",
            " [0.00229634 0.0143496  0.01331968]\n",
            "The b biases before the update are:\n",
            " [[-0.18477606 -0.69246205  0.02674411]]\n",
            "Updated bs are:\n",
            " [[-0.18479902 -0.69260554  0.02661091]]\n",
            "The W1 is: \n",
            " [[-0.76279839  0.03547046  0.29178929]\n",
            " [-2.60045377  0.66860015  0.25337398]\n",
            " [-1.18045467 -2.33391056 -1.29540422]]\n",
            "The W1 gradient is: \n",
            " [[ 0.03655151 -0.62817788 -0.7419688 ]\n",
            " [ 0.07463536 -0.74125696 -0.83891219]\n",
            " [ 0.1062521   0.19345715 -0.1012702 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.1478279 ]\n",
            " [-0.57636854]\n",
            " [ 0.03153109]]\n",
            "The biases b gradient is:\n",
            " [0.00229634 0.0143496  0.01331968]\n",
            "The bias c gradient is: \n",
            " [-0.01003535]\n",
            "\n",
            "RUN:\n",
            "  36\n",
            "The sum of the b update is\n",
            " [0.00256006 0.01373885 0.01268077]\n",
            "The b biases before the update are:\n",
            " [[-0.18479902 -0.69260554  0.02661091]]\n",
            "Updated bs are:\n",
            " [[-0.18482462 -0.69274293  0.0264841 ]]\n",
            "The W1 is: \n",
            " [[-0.76314207  0.04160845  0.29908588]\n",
            " [-2.60119118  0.67586875  0.26163676]\n",
            " [-1.18154705 -2.33590556 -1.29438587]]\n",
            "The W1 gradient is: \n",
            " [[ 0.03436741 -0.61379873 -0.72965842]\n",
            " [ 0.0737413  -0.72685931 -0.82627877]\n",
            " [ 0.1092375   0.19950046 -0.10183537]]\n",
            "The W2 gradient  is: \n",
            " [[ 2.06968422]\n",
            " [-0.60955282]\n",
            " [-0.01788517]]\n",
            "The biases b gradient is:\n",
            " [0.00256006 0.01373885 0.01268077]\n",
            "The bias c gradient is: \n",
            " [-0.01271509]\n",
            "\n",
            "RUN:\n",
            "  37\n",
            "The sum of the b update is\n",
            " [0.0028178  0.01317038 0.01208527]\n",
            "The b biases before the update are:\n",
            " [[-0.18482462 -0.69274293  0.0264841 ]]\n",
            "Updated bs are:\n",
            " [[-0.1848528  -0.69287463  0.02636325]]\n",
            "The W1 is: \n",
            " [[-0.76346341  0.04761043  0.30626972]\n",
            " [-2.60191848  0.68300152  0.26978417]\n",
            " [-1.18266855 -2.33795787 -1.29335837]]\n",
            "The W1 gradient is: \n",
            " [[ 0.03213458 -0.60019848 -0.71838497]\n",
            " [ 0.0727296  -0.71327768 -0.81474074]\n",
            " [ 0.11215033  0.20523094 -0.10274931]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.99624807]\n",
            " [-0.63937952]\n",
            " [-0.06323487]]\n",
            "The biases b gradient is:\n",
            " [0.0028178  0.01317038 0.01208527]\n",
            "The bias c gradient is: \n",
            " [-0.0151802]\n",
            "\n",
            "RUN:\n",
            "  38\n",
            "The sum of the b update is\n",
            " [0.00306904 0.01264025 0.0115286 ]\n",
            "The b biases before the update are:\n",
            " [[-0.1848528  -0.69287463  0.02636325]]\n",
            "Updated bs are:\n",
            " [[-0.18488349 -0.69300104  0.02624796]]\n",
            "The W1 is: \n",
            " [[-0.76376209  0.05348351  0.31335033]\n",
            " [-2.60263464  0.69000589  0.27782621]\n",
            " [-1.18381854 -2.34006462 -1.2923185 ]]\n",
            "The W1 gradient is: \n",
            " [[ 0.02986739 -0.58730747 -0.70806048]\n",
            " [ 0.07161674 -0.7004367  -0.80420417]\n",
            " [ 0.11499874  0.21067478 -0.10398712]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.9271652 ]\n",
            " [-0.66612072]\n",
            " [-0.10484977]]\n",
            "The biases b gradient is:\n",
            " [0.00306904 0.01264025 0.0115286 ]\n",
            "The bias c gradient is: \n",
            " [-0.01744738]\n",
            "\n",
            "RUN:\n",
            "  39\n",
            "The sum of the b update is\n",
            " [0.00331339 0.01214496 0.01100669]\n",
            "The b biases before the update are:\n",
            " [[-0.18488349 -0.69300104  0.02624796]]\n",
            "Updated bs are:\n",
            " [[-0.18491663 -0.69312249  0.0261379 ]]\n",
            "The W1 is: \n",
            " [[-0.76403787  0.05923414  0.32033639]\n",
            " [-2.60333881  0.69688858  0.28577206]\n",
            " [-1.18499643 -2.34222317 -1.29126324]]\n",
            "The W1 gradient is: \n",
            " [[ 0.02757788 -0.57506347 -0.69860599]\n",
            " [ 0.07041695 -0.68826902 -0.79458461]\n",
            " [ 0.1177896   0.21585559 -0.10552648]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.86210956]\n",
            " [-0.69002705]\n",
            " [-0.14303495]]\n",
            "The biases b gradient is:\n",
            " [0.00331339 0.01214496 0.01100669]\n",
            "The bias c gradient is: \n",
            " [-0.01953207]\n",
            "\n",
            "RUN:\n",
            "  40\n",
            "The sum of the b update is\n",
            " [0.00355062 0.01168136 0.01051589]\n",
            "The b biases before the update are:\n",
            " [[-0.18491663 -0.69312249  0.0261379 ]]\n",
            "Updated bs are:\n",
            " [[-0.18495213 -0.6932393   0.02603274]]\n",
            "The W1 is: \n",
            " [[-0.76429063  0.06486825  0.3272359 ]\n",
            " [-2.60403024  0.70365573  0.29363012]\n",
            " [-1.18620172 -2.34443112 -1.29018977]]\n",
            "The W1 gradient is: \n",
            " [[ 0.02527611 -0.56341087 -0.68995056]\n",
            " [ 0.06914248 -0.67671443 -0.78580611]\n",
            " [ 0.12052873  0.22079466 -0.10734737]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.80078125]\n",
            " [-0.71132924]\n",
            " [-0.17807083]]\n",
            "The biases b gradient is:\n",
            " [0.00355062 0.01168136 0.01051589]\n",
            "The bias c gradient is: \n",
            " [-0.02144846]\n",
            "\n",
            "RUN:\n",
            "  41\n",
            "The sum of the b update is\n",
            " [0.00378055 0.01124662 0.01005293]\n",
            "The b biases before the update are:\n",
            " [[-0.18495213 -0.6932393   0.02603274]]\n",
            "Updated bs are:\n",
            " [[-0.18498994 -0.69335177  0.02593221]]\n",
            "The W1 is: \n",
            " [[-0.76452033  0.07039125  0.3340562 ]\n",
            " [-2.60470828  0.71031292  0.30140812]\n",
            " [-1.18743393 -2.34668623 -1.28909545]]\n",
            "The W1 gradient is: \n",
            " [[ 0.02297043 -0.55229991 -0.68203038]\n",
            " [ 0.06780395 -0.66571899 -0.77780032]\n",
            " [ 0.12322103  0.22551121 -0.1094318 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.74290449]\n",
            " [-0.73023966]\n",
            " [-0.2102151 ]]\n",
            "The biases b gradient is:\n",
            " [0.00378055 0.01124662 0.01005293]\n",
            "The bias c gradient is: \n",
            " [-0.02320964]\n",
            "\n",
            "RUN:\n",
            "  42\n",
            "The sum of the b update is\n",
            " [0.00400311 0.0108382  0.0096149 ]\n",
            "The b biases before the update are:\n",
            " [[-0.18498994 -0.69335177  0.02593221]]\n",
            "Updated bs are:\n",
            " [[-0.18502997 -0.69346015  0.02583606]]\n",
            "The W1 is: \n",
            " [[-0.76472701  0.07580811  0.34080408]\n",
            " [-2.60537238  0.71686526  0.30911318]\n",
            " [-1.18869264 -2.34898646 -1.28797781]]\n",
            "The W1 gradient is: \n",
            " [[ 0.0206678  -0.54168601 -0.67478797]\n",
            " [ 0.06641055 -0.65523439 -0.77050562]\n",
            " [ 0.12587062  0.23002263 -0.11176356]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.68822579]\n",
            " [-0.74695372]\n",
            " [-0.23970453]]\n",
            "The biases b gradient is:\n",
            " [0.00400311 0.0108382  0.0096149 ]\n",
            "The bias c gradient is: \n",
            " [-0.02482767]\n",
            "\n",
            "RUN:\n",
            "  43\n",
            "The sum of the b update is\n",
            " [0.00421829 0.01045379 0.00919918]\n",
            "The b biases before the update are:\n",
            " [[-0.18502997 -0.69346015  0.02583606]]\n",
            "Updated bs are:\n",
            " [[-0.18507215 -0.69356469  0.02574407]]\n",
            "The W1 is: \n",
            " [[-0.76491075  0.0811234   0.34748579]\n",
            " [-2.60602209  0.72331743  0.31675184]\n",
            " [-1.18997745 -2.35132991 -1.28683453]]\n",
            "The W1 gradient is: \n",
            " [[ 0.01837396 -0.53152917 -0.66817153]\n",
            " [ 0.06497023 -0.64521729 -0.76386642]\n",
            " [ 0.12848094  0.23434469 -0.11432804]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.63651216]\n",
            " [-0.76165114]\n",
            " [-0.26675668]]\n",
            "The biases b gradient is:\n",
            " [0.00421829 0.01045379 0.00919918]\n",
            "The bias c gradient is: \n",
            " [-0.02631363]\n",
            "\n",
            "RUN:\n",
            "  44\n",
            "The sum of the b update is\n",
            " [0.00442612 0.01009134 0.00880342]\n",
            "The b biases before the update are:\n",
            " [[-0.18507215 -0.69356469  0.02574407]]\n",
            "Updated bs are:\n",
            " [[-0.18511641 -0.6936656   0.02565603]]\n",
            "The W1 is: \n",
            " [[-0.76507168  0.08634134  0.35410714]\n",
            " [-2.60665699  0.72967372  0.32433017]\n",
            " [-1.19128799 -2.35371482 -1.28566341]]\n",
            "The W1 gradient is: \n",
            " [[ 0.01609365 -0.52179347 -0.66213432]\n",
            " [ 0.06348991 -0.63562874 -0.75783251]\n",
            " [ 0.13105487  0.2384917  -0.11711201]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.58754938]\n",
            " [-0.77449725]\n",
            " [-0.29157143]]\n",
            "The biases b gradient is:\n",
            " [0.00442612 0.01009134 0.00880342]\n",
            "The bias c gradient is: \n",
            " [-0.02767773]\n",
            "\n",
            "RUN:\n",
            "  45\n",
            "The sum of the b update is\n",
            " [0.00462669 0.00974898 0.00842549]\n",
            "The b biases before the update are:\n",
            " [[-0.18511641 -0.6936656   0.02565603]]\n",
            "Updated bs are:\n",
            " [[-0.18516268 -0.69376309  0.02557178]]\n",
            "The W1 is: \n",
            " [[-0.76520999  0.0914658   0.36067348]\n",
            " [-2.60727674  0.73593806  0.33185375]\n",
            " [-1.19262394 -2.35613959 -1.28446238]]\n",
            "The W1 gradient is: \n",
            " [[ 0.01383074 -0.51244661 -0.65663404]\n",
            " [ 0.06197559 -0.62643376 -0.75235849]\n",
            " [ 0.1335948   0.24247666 -0.1201035 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.54114054]\n",
            " [-0.7856441 ]\n",
            " [-0.31433245]]\n",
            "The biases b gradient is:\n",
            " [0.00462669 0.00974898 0.00842549]\n",
            "The bias c gradient is: \n",
            " [-0.02892934]\n",
            "\n",
            "RUN:\n",
            "  46\n",
            "The sum of the b update is\n",
            " [0.00482011 0.00942501 0.0080635 ]\n",
            "The b biases before the update are:\n",
            " [[-0.18516268 -0.69376309  0.02557178]]\n",
            "Updated bs are:\n",
            " [[-0.18521088 -0.69385734  0.02549114]]\n",
            "The W1 is: \n",
            " [[-0.76532588  0.0965004   0.3671898 ]\n",
            " [-2.60788107  0.74211407  0.33932778]\n",
            " [-1.19398497 -2.3586027  -1.28322946]]\n",
            "The W1 gradient is: \n",
            " [[ 0.01158838 -0.50345949 -0.65163243]\n",
            " [ 0.06043251 -0.61760083 -0.74740319]\n",
            " [ 0.13610271  0.24631141 -0.1232916 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.49710455]\n",
            " [-0.79523156]\n",
            " [-0.33520853]]\n",
            "The biases b gradient is:\n",
            " [0.00482011 0.00942501 0.0080635 ]\n",
            "The bias c gradient is: \n",
            " [-0.03007709]\n",
            "\n",
            "RUN:\n",
            "  47\n",
            "The sum of the b update is\n",
            " [0.0050065  0.00911792 0.00771572]\n",
            "The b biases before the update are:\n",
            " [[-0.18521088 -0.69385734  0.02549114]]\n",
            "Updated bs are:\n",
            " [[-0.18526095 -0.69394852  0.02541399]]\n",
            "The W1 is: \n",
            " [[-0.76541957  0.10144846  0.37366075]\n",
            " [-2.60846972  0.74820508  0.34675708]\n",
            " [-1.19537077 -2.36110277 -1.2819628 ]]\n",
            "The W1 gradient is: \n",
            " [[ 0.00936913 -0.49480587 -0.64709478]\n",
            " [ 0.05886523 -0.60910155 -0.7429293 ]\n",
            " [ 0.13858025  0.25000676 -0.12666635]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.45527483]\n",
            " [-0.80338825]\n",
            " [-0.35435481]]\n",
            "The biases b gradient is:\n",
            " [0.0050065  0.00911792 0.00771572]\n",
            "The bias c gradient is: \n",
            " [-0.03112893]\n",
            "\n",
            "RUN:\n",
            "  48\n",
            "The sum of the b update is\n",
            " [0.00518603 0.00882633 0.00738061]\n",
            "The b biases before the update are:\n",
            " [[-0.18526095 -0.69394852  0.02541399]]\n",
            "Updated bs are:\n",
            " [[-0.18531281 -0.69403678  0.02534018]]\n",
            "The W1 is: \n",
            " [[-0.76549132  0.10631308  0.38009065]\n",
            " [-2.6090425   0.75421418  0.35414611]\n",
            " [-1.19678106 -2.3636385  -1.28066061]]\n",
            "The W1 gradient is: \n",
            " [[ 0.00717501 -0.48646203 -0.64298955]\n",
            " [ 0.05727773 -0.60091029 -0.7389029 ]\n",
            " [ 0.14102875  0.25357257 -0.13021864]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.4154981 ]\n",
            " [-0.8102325 ]\n",
            " [-0.37191394]]\n",
            "The biases b gradient is:\n",
            " [0.00518603 0.00882633 0.00738061]\n",
            "The bias c gradient is: \n",
            " [-0.03209214]\n",
            "\n",
            "RUN:\n",
            "  49\n",
            "The sum of the b update is\n",
            " [0.00535887 0.00854896 0.00705678]\n",
            "The b biases before the update are:\n",
            " [[-0.18531281 -0.69403678  0.02534018]]\n",
            "Updated bs are:\n",
            " [[-0.1853664  -0.69412227  0.02526961]]\n",
            "The W1 is: \n",
            " [[-0.76554139  0.11109714  0.38648353]\n",
            " [-2.60959923  0.76014422  0.36149904]\n",
            " [-1.19821555 -2.36620868 -1.27932121]]\n",
            "The W1 gradient is: \n",
            " [[ 0.00500763 -0.47840652 -0.63928802]\n",
            " [ 0.0556735  -0.59300387 -0.73529308]\n",
            " [ 0.1434493   0.25701788 -0.13394005]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.37763324]\n",
            " [-0.81587314]\n",
            " [-0.38801706]]\n",
            "The biases b gradient is:\n",
            " [0.00535887 0.00854896 0.00705678]\n",
            "The bias c gradient is: \n",
            " [-0.03297343]\n",
            "\n",
            "RUN:\n",
            "  50\n",
            "The sum of the b update is\n",
            " [0.00552519 0.0082847  0.00674294]\n",
            "The b biases before the update are:\n",
            " [[-0.1853664  -0.69412227  0.02526961]]\n",
            "Updated bs are:\n",
            " [[-0.18542165 -0.69420512  0.02520218]]\n",
            "The W1 is: \n",
            " [[-0.76557008  0.11580334  0.39284317]\n",
            " [-2.61013979  0.76599784  0.36881975]\n",
            " [-1.19967398 -2.36881219 -1.27794298]]\n",
            "The W1 gradient is: \n",
            " [[ 0.00286823 -0.47061988 -0.635964  ]\n",
            " [ 0.05405558 -0.58536134 -0.73207166]\n",
            " [ 0.1458428   0.26035094 -0.13782282]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.34155028]\n",
            " [-0.82041031]\n",
            " [-0.40278477]]\n",
            "The biases b gradient is:\n",
            " [0.00552519 0.0082847  0.00674294]\n",
            "The bias c gradient is: \n",
            " [-0.03377898]\n",
            "\n",
            "RUN:\n",
            "  51\n",
            "The sum of the b update is\n",
            " [0.00568519 0.0080325  0.00643797]\n",
            "The b biases before the update are:\n",
            " [[-0.18542165 -0.69420512  0.02520218]]\n",
            "Updated bs are:\n",
            " [[-0.1854785  -0.69428544  0.0251378 ]]\n",
            "The W1 is: \n",
            " [[-0.76557765  0.12043419  0.3991731 ]\n",
            " [-2.61066405  0.77177747  0.37611188]\n",
            " [-1.20115608 -2.37144798 -1.27652438]]\n",
            "The W1 gradient is: \n",
            " [[ 0.00075775 -0.46308447 -0.63299352]\n",
            " [ 0.05242665 -0.5779637  -0.72921288]\n",
            " [ 0.14820996  0.26357934 -0.14185971]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.30712947]\n",
            " [-0.82393614]\n",
            " [-0.41632804]]\n",
            "The biases b gradient is:\n",
            " [0.00568519 0.0080325  0.00643797]\n",
            "The bias c gradient is: \n",
            " [-0.03451445]\n",
            "\n",
            "RUN:\n",
            "  52\n",
            "The sum of the b update is\n",
            " [0.00583904 0.00779143 0.00614083]\n",
            "The b biases before the update are:\n",
            " [[-0.1854785  -0.69428544  0.0251378 ]]\n",
            "Updated bs are:\n",
            " [[-0.18553689 -0.69436336  0.0250764 ]]\n",
            "The W1 is: \n",
            " [[-0.76556442  0.12499203  0.40547665]\n",
            " [-2.61117194  0.77748541  0.38337881]\n",
            " [-1.20266159 -2.37411508 -1.27506395]]\n",
            "The W1 gradient is: \n",
            " [[-0.00132314 -0.45578422 -0.63035463]\n",
            " [ 0.05078906 -0.57079372 -0.72669309]\n",
            " [ 0.15055134  0.26671007 -0.14604392]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.27426041]\n",
            " [-0.82653539]\n",
            " [-0.42874893]]\n",
            "The biases b gradient is:\n",
            " [0.00583904 0.00779143 0.00614083]\n",
            "The bias c gradient is: \n",
            " [-0.03518506]\n",
            "\n",
            "RUN:\n",
            "  53\n",
            "The sum of the b update is\n",
            " [0.00598695 0.00756063 0.00585057]\n",
            "The b biases before the update are:\n",
            " [[-0.18553689 -0.69436336  0.0250764 ]]\n",
            "Updated bs are:\n",
            " [[-0.18559676 -0.69443896  0.02501789]]\n",
            "The W1 is: \n",
            " [[-0.76553068  0.12947907  0.41175692]\n",
            " [-2.61166339  0.78312377  0.39062372]\n",
            " [-1.20419027 -2.37681257 -1.27356025]]\n",
            "The W1 gradient is: \n",
            " [[-0.00337396 -0.44870452 -0.62802712]\n",
            " [ 0.04914488 -0.56383572 -0.72449058]\n",
            " [ 0.15286739  0.26974952 -0.15036906]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.24284125]\n",
            " [-0.82828609]\n",
            " [-0.4401414 ]]\n",
            "The biases b gradient is:\n",
            " [0.00598695 0.00756063 0.00585057]\n",
            "The bias c gradient is: \n",
            " [-0.03579561]\n",
            "\n",
            "RUN:\n",
            "  54\n",
            "The sum of the b update is\n",
            " [0.0061291  0.00733933 0.00556636]\n",
            "The b biases before the update are:\n",
            " [[-0.18559676 -0.69443896  0.02501789]]\n",
            "Updated bs are:\n",
            " [[-0.18565805 -0.69451236  0.02496223]]\n",
            "The W1 is: \n",
            " [[-0.76547674  0.13389739  0.41801684]\n",
            " [-2.61213835  0.78869452  0.39784957]\n",
            " [-1.20574185 -2.37953961 -1.27201196]]\n",
            "The W1 gradient is: \n",
            " [[-0.00539443 -0.44183202 -0.62599236]\n",
            " [ 0.04749593 -0.55707546 -0.72258533]\n",
            " [ 0.15515847  0.2727036  -0.15482905]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.21277802]\n",
            " [-0.82926004]\n",
            " [-0.45059188]]\n",
            "The biases b gradient is:\n",
            " [0.0061291  0.00733933 0.00556636]\n",
            "The bias c gradient is: \n",
            " [-0.03635051]\n",
            "\n",
            "RUN:\n",
            "  55\n",
            "The sum of the b update is\n",
            " [0.00626568 0.0071268  0.00528742]\n",
            "The b biases before the update are:\n",
            " [[-0.18565805 -0.69451236  0.02496223]]\n",
            "Updated bs are:\n",
            " [[-0.18572071 -0.69458363  0.02490935]]\n",
            "The W1 is: \n",
            " [[-0.76540289  0.13824894  0.42425917]\n",
            " [-2.61259679  0.79419952  0.40505916]\n",
            " [-1.2073161  -2.38229539 -1.27041778]]\n",
            "The W1 gradient is: \n",
            " [[-0.0073844  -0.43515453 -0.62423311]\n",
            " [ 0.04584382 -0.55049994 -0.72095882]\n",
            " [ 0.15742484  0.27557776 -0.15941802]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.18398391]\n",
            " [-0.82952332]\n",
            " [-0.46017996]]\n",
            "The biases b gradient is:\n",
            " [0.00626568 0.0071268  0.00528742]\n",
            "The bias c gradient is: \n",
            " [-0.03685383]\n",
            "\n",
            "RUN:\n",
            "  56\n",
            "The sum of the b update is\n",
            " [0.00639687 0.00692242 0.00501306]\n",
            "The b biases before the update are:\n",
            " [[-0.18572071 -0.69458363  0.02490935]]\n",
            "Updated bs are:\n",
            " [[-0.18578468 -0.69465285  0.02485922]]\n",
            "The W1 is: \n",
            " [[-0.76530946  0.14253555  0.43048651]\n",
            " [-2.61303869  0.79964049  0.4122551 ]\n",
            " [-1.20891277 -2.38507916 -1.26877648]]\n",
            "The W1 gradient is: \n",
            " [[-0.00934386 -0.42866086 -0.62273335]\n",
            " [ 0.04418997 -0.54409731 -0.71959384]\n",
            " [ 0.15966669  0.27837703 -0.16413033]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.15637874]\n",
            " [-0.82913678]\n",
            " [-0.4689789 ]]\n",
            "The biases b gradient is:\n",
            " [0.00639687 0.00692242 0.00501306]\n",
            "The bias c gradient is: \n",
            " [-0.03730929]\n",
            "\n",
            "RUN:\n",
            "  57\n",
            "The sum of the b update is\n",
            " [0.00652287 0.00672558 0.00474266]\n",
            "The b biases before the update are:\n",
            " [[-0.18578468 -0.69465285  0.02485922]]\n",
            "Updated bs are:\n",
            " [[-0.1858499  -0.69472011  0.0248118 ]]\n",
            "The W1 is: \n",
            " [[-0.76519673  0.14675896  0.43670129]\n",
            " [-2.61346405  0.80501906  0.41943984]\n",
            " [-1.21053161 -2.38789022 -1.26708688]]\n",
            "The W1 gradient is: \n",
            " [[-0.01127287 -0.42234077 -0.62147813]\n",
            " [ 0.04253564 -0.53785674 -0.71847439]\n",
            " [ 0.16188419  0.28110603 -0.16896044]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.12988837]\n",
            " [-0.82815643]\n",
            " [-0.47705616]]\n",
            "The biases b gradient is:\n",
            " [0.00652287 0.00672558 0.00474266]\n",
            "The bias c gradient is: \n",
            " [-0.03772033]\n",
            "\n",
            "RUN:\n",
            "  58\n",
            "The sum of the b update is\n",
            " [0.00664385 0.00653575 0.00447564]\n",
            "The b biases before the update are:\n",
            " [[-0.1858499  -0.69472011  0.0248118 ]]\n",
            "Updated bs are:\n",
            " [[-0.18591634 -0.69478546  0.02476704]]\n",
            "The W1 is: \n",
            " [[-0.76506501  0.1509208   0.44290582]\n",
            " [-2.61387287  0.81033675  0.4266157 ]\n",
            " [-1.21217238 -2.39072791 -1.26534785]]\n",
            "The W1 gradient is: \n",
            " [[-0.01317161 -0.41618486 -0.62045346]\n",
            " [ 0.04088195 -0.53176831 -0.71758546]\n",
            " [ 0.16407744  0.28376908 -0.1739029 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.10444422]\n",
            " [-0.82663384]\n",
            " [-0.48447383]]\n",
            "The biases b gradient is:\n",
            " [0.00664385 0.00653575 0.00447564]\n",
            "The bias c gradient is: \n",
            " [-0.03809011]\n",
            "\n",
            "RUN:\n",
            "  59\n",
            "The sum of the b update is\n",
            " [0.00675998 0.00635244 0.00421151]\n",
            "The b biases before the update are:\n",
            " [[-0.18591634 -0.69478546  0.02476704]]\n",
            "Updated bs are:\n",
            " [[-0.18598394 -0.69484899  0.02472492]]\n",
            "The W1 is: \n",
            " [[-0.76491461  0.15502265  0.44910228]\n",
            " [-2.61426516  0.81559497  0.43378483]\n",
            " [-1.21383485 -2.39359161 -1.26355832]]\n",
            "The W1 gradient is: \n",
            " [[-0.01504029 -0.41018445 -0.61964616]\n",
            " [ 0.03922987 -0.52582293 -0.71691295]\n",
            " [ 0.1662465   0.28637014 -0.17895229]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.07998281]\n",
            " [-0.82461649]\n",
            " [-0.49128908]]\n",
            "The biases b gradient is:\n",
            " [0.00675998 0.00635244 0.00421151]\n",
            "The bias c gradient is: \n",
            " [-0.03842153]\n",
            "\n",
            "RUN:\n",
            "  60\n",
            "The sum of the b update is\n",
            " [0.00687143 0.0061752  0.00394979]\n",
            "The b biases before the update are:\n",
            " [[-0.18598394 -0.69484899  0.02472492]]\n",
            "Updated bs are:\n",
            " [[-0.18605266 -0.69491074  0.02468543]]\n",
            "The W1 is: \n",
            " [[-0.76474582  0.15906596  0.45529272]\n",
            " [-2.61464097  0.8207951   0.44094926]\n",
            " [-1.21551876 -2.39648074 -1.26171729]]\n",
            "The W1 gradient is: \n",
            " [[-0.01687921 -0.40433154 -0.61904377]\n",
            " [ 0.0375803  -0.52001226 -0.71644354]\n",
            " [ 0.16839144  0.28891289 -0.18410313]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.05644534]\n",
            " [-0.82214812]\n",
            " [-0.49755453]]\n",
            "The biases b gradient is:\n",
            " [0.00687143 0.0061752  0.00394979]\n",
            "The bias c gradient is: \n",
            " [-0.03871727]\n",
            "\n",
            "RUN:\n",
            "  61\n",
            "The sum of the b update is\n",
            " [0.00697836 0.00600361 0.00369009]\n",
            "The b biases before the update are:\n",
            " [[-0.18605266 -0.69491074  0.02468543]]\n",
            "Updated bs are:\n",
            " [[-0.18612244 -0.69497078  0.02464852]]\n",
            "The W1 is: \n",
            " [[-0.76455893  0.16305215  0.46147907]\n",
            " [-2.61500031  0.82593838  0.44811091]\n",
            " [-1.21722389 -2.39939475 -1.25982379]]\n",
            "The W1 gradient is: \n",
            " [[-0.01868868 -0.39861876 -0.61863442]\n",
            " [ 0.03593402 -0.51432863 -0.71616458]\n",
            " [ 0.17051227  0.29140077 -0.18934991]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.03377733]\n",
            " [-0.81926899]\n",
            " [-0.50331862]]\n",
            "The biases b gradient is:\n",
            " [0.00697836 0.00600361 0.00369009]\n",
            "The bias c gradient is: \n",
            " [-0.0389798]\n",
            "\n",
            "RUN:\n",
            "  62\n",
            "The sum of the b update is\n",
            " [0.00708093 0.00583731 0.00343203]\n",
            "The b biases before the update are:\n",
            " [[-0.18612244 -0.69497078  0.02464852]]\n",
            "Updated bs are:\n",
            " [[-0.18619325 -0.69502915  0.0246142 ]]\n",
            "The W1 is: \n",
            " [[-0.76435424  0.16698254  0.46766313]\n",
            " [-2.61534323  0.83102603  0.45527155]\n",
            " [-1.21894998 -2.40233312 -1.25787692]]\n",
            "The W1 gradient is: \n",
            " [[-0.02046906 -0.39303927 -0.61840678]\n",
            " [ 0.03429172 -0.508765   -0.71606397]\n",
            " [ 0.17260903  0.29383693 -0.19468696]]\n",
            "The W2 gradient  is: \n",
            " [[ 1.01192827]\n",
            " [-0.81601619]\n",
            " [-0.50862591]]\n",
            "The biases b gradient is:\n",
            " [0.00708093 0.00583731 0.00343203]\n",
            "The bias c gradient is: \n",
            " [-0.03921136]\n",
            "\n",
            "RUN:\n",
            "  63\n",
            "The sum of the b update is\n",
            " [0.00717928 0.00567596 0.0031753 ]\n",
            "The b biases before the update are:\n",
            " [[-0.18619325 -0.69502915  0.0246142 ]]\n",
            "Updated bs are:\n",
            " [[-0.18626504 -0.69508591  0.02458245]]\n",
            "The W1 is: \n",
            " [[-0.76413203  0.17085841  0.47384663]\n",
            " [-2.61566977  0.83605918  0.46243285]\n",
            " [-1.22069679 -2.40529536 -1.25587584]]\n",
            "The W1 gradient is: \n",
            " [[-0.02222073 -0.38758674 -0.61834994]\n",
            " [ 0.03265403 -0.50331485 -0.71613011]\n",
            " [ 0.17468172  0.29622432 -0.20010846]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.99085129]\n",
            " [-0.81242388]\n",
            " [-0.51351738]]\n",
            "The biases b gradient is:\n",
            " [0.00717928 0.00567596 0.0031753 ]\n",
            "The bias c gradient is: \n",
            " [-0.03941405]\n",
            "\n",
            "RUN:\n",
            "  64\n",
            "The sum of the b update is\n",
            " [0.00727358 0.00551923 0.00291961]\n",
            "The b biases before the update are:\n",
            " [[-0.18626504 -0.69508591  0.02458245]]\n",
            "Updated bs are:\n",
            " [[-0.18633778 -0.6951411   0.02455326]]\n",
            "The W1 is: \n",
            " [[-0.76389259  0.17468096  0.48003117]\n",
            " [-2.61597998  0.8410389   0.46959637]\n",
            " [-1.2224641  -2.40828102 -1.25381976]]\n",
            "The W1 gradient is: \n",
            " [[-0.0239441  -0.3822553  -0.61845333]\n",
            " [ 0.03102151 -0.49797218 -0.71635176]\n",
            " [ 0.17673034  0.29856568 -0.20560839]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.97050286]\n",
            " [-0.80852352]\n",
            " [-0.51803071]]\n",
            "The biases b gradient is:\n",
            " [0.00727358 0.00551923 0.00291961]\n",
            "The bias c gradient is: \n",
            " [-0.03958978]\n",
            "\n",
            "RUN:\n",
            "  65\n",
            "The sum of the b update is\n",
            " [0.00736394 0.00536684 0.00266471]\n",
            "The b biases before the update are:\n",
            " [[-0.18633778 -0.6951411   0.02455326]]\n",
            "Updated bs are:\n",
            " [[-0.18641142 -0.69519477  0.02452661]]\n",
            "The W1 is: \n",
            " [[-0.76363619  0.17845136  0.48621823]\n",
            " [-2.61627393  0.84596622  0.47676355]\n",
            " [-1.22425165 -2.41128965 -1.25170795]]\n",
            "The W1 gradient is: \n",
            " [[-0.02563958 -0.37703948 -0.61870667]\n",
            " [ 0.02939466 -0.49273145 -0.71671803]\n",
            " [ 0.17875491  0.30086355 -0.21118046]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.95084257]\n",
            " [-0.80434407]\n",
            " [-0.52220048]]\n",
            "The biases b gradient is:\n",
            " [0.00736394 0.00536684 0.00266471]\n",
            "The bias c gradient is: \n",
            " [-0.03974031]\n",
            "\n",
            "RUN:\n",
            "  66\n",
            "The sum of the b update is\n",
            " [0.00745052 0.00521854 0.00241038]\n",
            "The b biases before the update are:\n",
            " [[-0.18641142 -0.69519477  0.02452661]]\n",
            "Updated bs are:\n",
            " [[-0.18648592 -0.69524695  0.0245025 ]]\n",
            "The W1 is: \n",
            " [[-0.76336312  0.1821707   0.49240923]\n",
            " [-2.61655167  0.85084209  0.48393573]\n",
            " [-1.2260592  -2.41432086 -1.24953977]]\n",
            "The W1 gradient is: \n",
            " [[-0.0273076  -0.3719342  -0.6190999 ]\n",
            " [ 0.02777394 -0.48758752 -0.71721823]\n",
            " [ 0.18075542  0.30312031 -0.2168181 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.93183286]\n",
            " [-0.79991224]\n",
            " [-0.52605847]]\n",
            "The biases b gradient is:\n",
            " [0.00745052 0.00521854 0.00241038]\n",
            "The bias c gradient is: \n",
            " [-0.03986727]\n",
            "\n",
            "RUN:\n",
            "  67\n",
            "The sum of the b update is\n",
            " [0.00753342 0.00507408 0.00215646]\n",
            "The b biases before the update are:\n",
            " [[-0.18648592 -0.69524695  0.0245025 ]]\n",
            "Updated bs are:\n",
            " [[-0.18656126 -0.6952977   0.02448094]]\n",
            "The W1 is: \n",
            " [[-0.76307363  0.18584005  0.49860546]\n",
            " [-2.61681326  0.85566745  0.49111415]\n",
            " [-1.22788652 -2.41737424 -1.24731463]]\n",
            "The W1 gradient is: \n",
            " [[-0.02894858 -0.36693471 -0.61962309]\n",
            " [ 0.02615974 -0.48253565 -0.71784188]\n",
            " [ 0.18273189  0.30533815 -0.22251439]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.9134388 ]\n",
            " [-0.79525258]\n",
            " [-0.52963378]]\n",
            "The biases b gradient is:\n",
            " [0.00753342 0.00507408 0.00215646]\n",
            "The bias c gradient is: \n",
            " [-0.03997214]\n",
            "\n",
            "RUN:\n",
            "  68\n",
            "The sum of the b update is\n",
            " [0.00761279 0.00493324 0.00190278]\n",
            "The b biases before the update are:\n",
            " [[-0.18656126 -0.6952977   0.02448094]]\n",
            "Updated bs are:\n",
            " [[-0.18663738 -0.69534703  0.02446191]]\n",
            "The W1 is: \n",
            " [[-0.762768    0.18946041  0.50480813]\n",
            " [-2.61705879  0.86044316  0.49829993]\n",
            " [-1.22973336 -2.42044943 -1.24503201]]\n",
            "The W1 gradient is: \n",
            " [[-0.03056295 -0.36203657 -0.62026642]\n",
            " [ 0.02455244 -0.47757143 -0.71857859]\n",
            " [ 0.18468434  0.30751915 -0.22826207]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.89562788]\n",
            " [-0.79038775]\n",
            " [-0.53295307]]\n",
            "The biases b gradient is:\n",
            " [0.00761279 0.00493324 0.00190278]\n",
            "The bias c gradient is: \n",
            " [-0.0400563]\n",
            "\n",
            "RUN:\n",
            "  69\n",
            "The sum of the b update is\n",
            " [0.00768873 0.00479582 0.00164924]\n",
            "The b biases before the update are:\n",
            " [[-0.18663738 -0.69534703  0.02446191]]\n",
            "Updated bs are:\n",
            " [[-0.18671427 -0.69539499  0.02444542]]\n",
            "The W1 is: \n",
            " [[-0.76244649  0.19303277  0.51101833]\n",
            " [-2.61728831  0.86517007  0.50549411]\n",
            " [-1.23159949 -2.42354608 -1.24269147]]\n",
            "The W1 gradient is: \n",
            " [[-0.03215115 -0.35723567 -0.62102011]\n",
            " [ 0.02295236 -0.47269076 -0.71941804]\n",
            " [ 0.18661278  0.3096652  -0.23405346]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.87836987]\n",
            " [-0.78533858]\n",
            " [-0.53604068]]\n",
            "The biases b gradient is:\n",
            " [0.00768873 0.00479582 0.00164924]\n",
            "The bias c gradient is: \n",
            " [-0.040121]\n",
            "\n",
            "RUN:\n",
            "  70\n",
            "The sum of the b update is\n",
            " [0.00776137 0.00466165 0.00139573]\n",
            "The b biases before the update are:\n",
            " [[-0.18671427 -0.69539499  0.02444542]]\n",
            "Updated bs are:\n",
            " [[-0.18679189 -0.6954416   0.02443146]]\n",
            "The W1 is: \n",
            " [[-0.76210936  0.19655805  0.51723707]\n",
            " [-2.61750191  0.86984897  0.51269761]\n",
            " [-1.23348466 -2.42666386 -1.24029267]]\n",
            "The W1 gradient is: \n",
            " [[-0.03371359 -0.35252811 -0.62187436]\n",
            " [ 0.02135981 -0.46788986 -0.7203499 ]\n",
            " [ 0.18851725  0.31177809 -0.23988044]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.86163658]\n",
            " [-0.78012429]\n",
            " [-0.53891884]]\n",
            "The biases b gradient is:\n",
            " [0.00776137 0.00466165 0.00139573]\n",
            "The bias c gradient is: \n",
            " [-0.04016741]\n",
            "\n",
            "RUN:\n",
            "  71\n",
            "The sum of the b update is\n",
            " [0.00783079 0.00453054 0.0011422 ]\n",
            "The b biases before the update are:\n",
            " [[-0.18679189 -0.6954416   0.02443146]]\n",
            "Updated bs are:\n",
            " [[-0.18687019 -0.69548691  0.02442004]]\n",
            "The W1 is: \n",
            " [[-0.76175685  0.20003715  0.52346527]\n",
            " [-2.61769966  0.87448062  0.51991125]\n",
            " [-1.23538864 -2.42980246 -1.23783532]]\n",
            "The W1 gradient is: \n",
            " [[-0.0352507  -0.34791028 -0.62281932]\n",
            " [ 0.01977505 -0.4631652  -0.72136382]\n",
            " [ 0.1903978   0.31385949 -0.24573442]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.84540177]\n",
            " [-0.77476254]\n",
            " [-0.54160776]]\n",
            "The biases b gradient is:\n",
            " [0.00783079 0.00453054 0.0011422 ]\n",
            "The bias c gradient is: \n",
            " [-0.04019659]\n",
            "\n",
            "RUN:\n",
            "  72\n",
            "The sum of the b update is\n",
            " [0.00789712 0.00440236 0.00088861]\n",
            "The b biases before the update are:\n",
            " [[-0.18687019 -0.69548691  0.02442004]]\n",
            "Updated bs are:\n",
            " [[-0.18694916 -0.69553093  0.02441115]]\n",
            "The W1 is: \n",
            " [[-0.76138922  0.20347094  0.52970372]\n",
            " [-2.61788164  0.87906576  0.52713575]\n",
            " [-1.23731118 -2.43296157 -1.23531926]]\n",
            "The W1 gradient is: \n",
            " [[-0.0367629  -0.34337876 -0.62384509]\n",
            " [ 0.01819834 -0.45851347 -0.72244935]\n",
            " [ 0.19225446  0.31591094 -0.25160633]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.82964096]\n",
            " [-0.76926963]\n",
            " [-0.54412578]]\n",
            "The biases b gradient is:\n",
            " [0.00789712 0.00440236 0.00088861]\n",
            "The bias c gradient is: \n",
            " [-0.04020953]\n",
            "\n",
            "RUN:\n",
            "  73\n",
            "The sum of the b update is\n",
            " [0.00796044 0.00427696 0.00063495]\n",
            "The b biases before the update are:\n",
            " [[-0.18694916 -0.69553093  0.02441115]]\n",
            "Updated bs are:\n",
            " [[-0.18702877 -0.6955737   0.0244048 ]]\n",
            "The W1 is: \n",
            " [[-0.76100671  0.20686025  0.53595313]\n",
            " [-2.61804794  0.88360507  0.5343717 ]\n",
            " [-1.23925206 -2.4361409  -1.23274439]]\n",
            "The W1 gradient is: \n",
            " [[-0.03825059 -0.33893037 -0.6249416 ]\n",
            " [ 0.01662991 -0.45393164 -0.72359595]\n",
            " [ 0.19408729  0.31793389 -0.25748657]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.81433135]\n",
            " [-0.76366053]\n",
            " [-0.54648948]]\n",
            "The biases b gradient is:\n",
            " [0.00796044 0.00427696 0.00063495]\n",
            "The bias c gradient is: \n",
            " [-0.04020713]\n",
            "\n",
            "RUN:\n",
            "  74\n",
            "The sum of the b update is\n",
            " [0.00802085 0.00415422 0.00038123]\n",
            "The b biases before the update are:\n",
            " [[-0.18702877 -0.6955737   0.0244048 ]]\n",
            "Updated bs are:\n",
            " [[-0.18710898 -0.69561524  0.02440099]]\n",
            "The W1 is: \n",
            " [[-0.76060957  0.21020587  0.54221412]\n",
            " [-2.61819864  0.88809924  0.54161963]\n",
            " [-1.24121102 -2.4393402  -1.23011074]]\n",
            "The W1 gradient is: \n",
            " [[-0.03971417 -0.33456211 -0.62609865]\n",
            " [ 0.01506995 -0.44941686 -0.72479291]\n",
            " [ 0.19589638  0.31992968 -0.26336501]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.79945165]\n",
            " [-0.75794905]\n",
            " [-0.54871379]]\n",
            "The biases b gradient is:\n",
            " [0.00802085 0.00415422 0.00038123]\n",
            "The bias c gradient is: \n",
            " [-0.04019022]\n",
            "\n",
            "RUN:\n",
            "  75\n",
            "The sum of the b update is\n",
            " [0.00807845 0.00403402 0.00012749]\n",
            "The b biases before the update are:\n",
            " [[-0.18710898 -0.69561524  0.02440099]]\n",
            "Updated bs are:\n",
            " [[-0.18718976 -0.69565558  0.02439972]]\n",
            "The W1 is: \n",
            " [[-0.76019803  0.21350858  0.54848718]\n",
            " [-2.61833383  0.89254891  0.54887993]\n",
            " [-1.24318784 -2.4425592  -1.22741843]]\n",
            "The W1 gradient is: \n",
            " [[-0.04115403 -0.33027116 -0.62730587]\n",
            " [ 0.01351868 -0.44496648 -0.72602935]\n",
            " [ 0.19768179  0.32189957 -0.26923095]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.78498199]\n",
            " [-0.7521479 ]\n",
            " [-0.55081206]]\n",
            "The biases b gradient is:\n",
            " [0.00807845 0.00403402 0.00012749]\n",
            "The bias c gradient is: \n",
            " [-0.04015957]\n",
            "\n",
            "RUN:\n",
            "  76\n",
            "The sum of the b update is\n",
            " [ 0.00813331  0.00391625 -0.0001262 ]\n",
            "The b biases before the update are:\n",
            " [[-0.18718976 -0.69565558  0.02439972]]\n",
            "Updated bs are:\n",
            " [[-0.1872711  -0.69569475  0.02440098]]\n",
            "The W1 is: \n",
            " [[-0.75977233  0.21676913  0.5547727 ]\n",
            " [-2.61845359  0.89695469  0.55615287]\n",
            " [-1.24518228 -2.44579764 -1.2246677 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.04257055 -0.32605488 -0.62855269]\n",
            " [ 0.01197626 -0.44057802 -0.7272942 ]\n",
            " [ 0.19944363  0.32384472 -0.27507315]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.77090385]\n",
            " [-0.74626876]\n",
            " [-0.55279621]]\n",
            "The biases b gradient is:\n",
            " [ 0.00813331  0.00391625 -0.0001262 ]\n",
            "The bias c gradient is: \n",
            " [-0.04011588]\n",
            "\n",
            "RUN:\n",
            "  77\n",
            "The sum of the b update is\n",
            " [ 0.00818551  0.00380081 -0.00037977]\n",
            "The b biases before the update are:\n",
            " [[-0.1872711  -0.69569475  0.02440098]]\n",
            "Updated bs are:\n",
            " [[-0.18735295 -0.69573275  0.02440478]]\n",
            "The W1 is: \n",
            " [[-0.75933268  0.21998824  0.56107099]\n",
            " [-2.61855802  0.90131718  0.56343863]\n",
            " [-1.2471941  -2.44905531 -1.2218589 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.04396409 -0.32191078 -0.62982833]\n",
            " [ 0.01044286 -0.43624921 -0.72857619]\n",
            " [ 0.20118198  0.3257662  -0.2808798 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.7571999 ]\n",
            " [-0.7403224 ]\n",
            " [-0.55467671]]\n",
            "The biases b gradient is:\n",
            " [ 0.00818551  0.00380081 -0.00037977]\n",
            "The bias c gradient is: \n",
            " [-0.0400598]\n",
            "\n",
            "RUN:\n",
            "  78\n",
            "The sum of the b update is\n",
            " [ 0.00823515  0.00368763 -0.00063311]\n",
            "The b biases before the update are:\n",
            " [[-0.18735295 -0.69573275  0.02440478]]\n",
            "Updated bs are:\n",
            " [[-0.1874353  -0.69576963  0.02441111]]\n",
            "The W1 is: \n",
            " [[-0.75887933  0.2231666   0.56738221]\n",
            " [-2.61864721  0.90563696  0.57073727]\n",
            " [-1.24922307 -2.45233196 -1.21899252]]\n",
            "The W1 gradient is: \n",
            " [[-0.04533502 -0.31783653 -0.6311218 ]\n",
            " [ 0.00891864 -0.4319779  -0.72986381]\n",
            " [ 0.20289697  0.32766503 -0.2866385 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.743854  ]\n",
            " [-0.73431872]\n",
            " [-0.55646278]]\n",
            "The biases b gradient is:\n",
            " [ 0.00823515  0.00368763 -0.00063311]\n",
            "The bias c gradient is: \n",
            " [-0.03999193]\n",
            "\n",
            "RUN:\n",
            "  79\n",
            "The sum of the b update is\n",
            " [ 0.00828229  0.00357662 -0.00088608]\n",
            "The b biases before the update are:\n",
            " [[-0.1874353  -0.69576963  0.02441111]]\n",
            "Updated bs are:\n",
            " [[-0.18751812 -0.6958054   0.02441997]]\n",
            "The W1 is: \n",
            " [[-0.7584125   0.2263049   0.57370642]\n",
            " [-2.61872124  0.90991458  0.57804872]\n",
            " [-1.25126895 -2.45562738 -1.21606916]]\n",
            "The W1 gradient is: \n",
            " [[-0.04668367 -0.31382992 -0.63242187]\n",
            " [ 0.00740375 -0.4277621  -0.73114536]\n",
            " [ 0.20458872  0.32954213 -0.29233633]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.73085105]\n",
            " [-0.72826683]\n",
            " [-0.55816233]]\n",
            "The biases b gradient is:\n",
            " [ 0.00828229  0.00357662 -0.00088608]\n",
            "The bias c gradient is: \n",
            " [-0.03991283]\n",
            "\n",
            "RUN:\n",
            "  80\n",
            "The sum of the b update is\n",
            " [ 0.008327    0.00346772 -0.00113855]\n",
            "The b biases before the update are:\n",
            " [[-0.18751812 -0.6958054   0.02441997]]\n",
            "Updated bs are:\n",
            " [[-0.18760139 -0.69584007  0.02443135]]\n",
            "The W1 is: \n",
            " [[-0.75793239  0.22940379  0.5800436 ]\n",
            " [-2.61878023  0.91415058  0.58537281]\n",
            " [-1.25333153 -2.45894136 -1.21308956]]\n",
            "The W1 gradient is: \n",
            " [[-0.0480104  -0.30988889 -0.63371713]\n",
            " [ 0.00589832 -0.42359999 -0.73240891]\n",
            " [ 0.20625736  0.33139836 -0.29795982]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.71817694]\n",
            " [-0.72217511]\n",
            " [-0.55978213]]\n",
            "The biases b gradient is:\n",
            " [ 0.008327    0.00346772 -0.00113855]\n",
            "The bias c gradient is: \n",
            " [-0.039823]\n",
            "\n",
            "RUN:\n",
            "  81\n",
            "The sum of the b update is\n",
            " [ 0.00836935  0.00336084 -0.00139035]\n",
            "The b biases before the update are:\n",
            " [[-0.18760139 -0.69584007  0.02443135]]\n",
            "Updated bs are:\n",
            " [[-0.18768509 -0.69587368  0.02444526]]\n",
            "The W1 is: \n",
            " [[-0.75743924  0.2324639   0.58639355]\n",
            " [-2.61882425  0.91834548  0.59270924]\n",
            " [-1.25541056 -2.46227371 -1.21005461]]\n",
            "The W1 gradient is: \n",
            " [[-0.04931552 -0.30601151 -0.63499594]\n",
            " [ 0.00440249 -0.41948984 -0.73364233]\n",
            " [ 0.20790303  0.3332345  -0.30349498]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.70581851]\n",
            " [-0.71605128]\n",
            " [-0.56132782]]\n",
            "The biases b gradient is:\n",
            " [ 0.00836935  0.00336084 -0.00139035]\n",
            "The bias c gradient is: \n",
            " [-0.03972293]\n",
            "\n",
            "RUN:\n",
            "  82\n",
            "The sum of the b update is\n",
            " [ 0.00840941  0.00325594 -0.00164128]\n",
            "The b biases before the update are:\n",
            " [[-0.18768509 -0.69587368  0.02444526]]\n",
            "Updated bs are:\n",
            " [[-0.18776918 -0.69590624  0.02446167]]\n",
            "The W1 is: \n",
            " [[-0.75693325  0.23548586  0.59275602]\n",
            " [-2.61885342  0.92249978  0.60005757]\n",
            " [-1.25750582 -2.46562422 -1.20696533]]\n",
            "The W1 gradient is: \n",
            " [[-0.05059934 -0.30219596 -0.63624647]\n",
            " [ 0.00291639 -0.41543008 -0.73483331]\n",
            " [ 0.2095259   0.33505128 -0.30892736]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.69376347]\n",
            " [-0.70990243]\n",
            " [-0.56280396]]\n",
            "The biases b gradient is:\n",
            " [ 0.00840941  0.00325594 -0.00164128]\n",
            "The bias c gradient is: \n",
            " [-0.03961306]\n",
            "\n",
            "RUN:\n",
            "  83\n",
            "The sum of the b update is\n",
            " [ 0.00844725  0.00315297 -0.00189115]\n",
            "The b biases before the update are:\n",
            " [[-0.18776918 -0.69590624  0.02446167]]\n",
            "Updated bs are:\n",
            " [[-0.18785365 -0.69593777  0.02448058]]\n",
            "The W1 is: \n",
            " [[-0.75641462  0.23847027  0.59913059]\n",
            " [-2.61886782  0.92661397  0.60741726]\n",
            " [-1.25961708 -2.46899271 -1.20382291]]\n",
            "The W1 gradient is: \n",
            " [[-0.05186218 -0.29844054 -0.63745676]\n",
            " [ 0.00144012 -0.41141924 -0.73596939]\n",
            " [ 0.21112612  0.33684936 -0.31424207]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.68200031]\n",
            " [-0.70373508]\n",
            " [-0.56421411]]\n",
            "The biases b gradient is:\n",
            " [ 0.00844725  0.00315297 -0.00189115]\n",
            "The bias c gradient is: \n",
            " [-0.03949379]\n",
            "\n",
            "RUN:\n",
            "  84\n",
            "The sum of the b update is\n",
            " [ 0.00848291  0.00305187 -0.00213975]\n",
            "The b biases before the update are:\n",
            " [[-0.18785365 -0.69593777  0.02448058]]\n",
            "Updated bs are:\n",
            " [[-0.18793848 -0.69596829  0.02450198]]\n",
            "The W1 is: \n",
            " [[-0.75588358  0.24141771  0.60551673]\n",
            " [-2.61886756  0.93068853  0.61478764]\n",
            " [-1.26174412 -2.47237901 -1.20062868]]\n",
            "The W1 gradient is: \n",
            " [[-5.31043136e-02 -2.94743647e-01 -6.38614675e-01]\n",
            " [-2.61703461e-05 -4.07455994e-01 -7.37037976e-01]\n",
            " [ 2.12703871e-01  3.38629335e-01 -3.19423842e-01]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.6705183 ]\n",
            " [-0.69755522]\n",
            " [-0.56556088]]\n",
            "The biases b gradient is:\n",
            " [ 0.00848291  0.00305187 -0.00213975]\n",
            "The bias c gradient is: \n",
            " [-0.03936551]\n",
            "\n",
            "RUN:\n",
            "  85\n",
            "The sum of the b update is\n",
            " [ 0.00851647  0.00295261 -0.00238683]\n",
            "The b biases before the update are:\n",
            " [[-0.18793848 -0.69596829  0.02450198]]\n",
            "Updated bs are:\n",
            " [[-0.18802365 -0.69599782  0.02452585]]\n",
            "The W1 is: \n",
            " [[-0.75534032  0.24432874  0.61191381]\n",
            " [-2.61885273  0.93472392  0.62216791]\n",
            " [-1.26388671 -2.47578292 -1.1973841 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.05432604 -0.2911038  -0.63970803]\n",
            " [-0.00148238 -0.40353909 -0.73802641]\n",
            " [ 0.21425934  0.34039175 -0.3244571 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.65930743]\n",
            " [-0.69136837]\n",
            " [-0.56684598]]\n",
            "The biases b gradient is:\n",
            " [ 0.00851647  0.00295261 -0.00238683]\n",
            "The bias c gradient is: \n",
            " [-0.03922858]\n",
            "\n",
            "RUN:\n",
            "  86\n",
            "The sum of the b update is\n",
            " [ 0.00854797  0.00285513 -0.00263216]\n",
            "The b biases before the update are:\n",
            " [[-0.18802365 -0.69599782  0.02452585]]\n",
            "Updated bs are:\n",
            " [[-0.18810913 -0.69602637  0.02455217]]\n",
            "The W1 is: \n",
            " [[-0.75478504  0.24720394  0.61832106]\n",
            " [-2.61882345  0.9387206   0.62955713]\n",
            " [-1.26604464 -2.47920429 -1.19409084]]\n",
            "The W1 gradient is: \n",
            " [[-0.05552762 -0.28751962 -0.64072456]\n",
            " [-0.0029284  -0.3996674  -0.73892199]\n",
            " [ 0.21579271  0.34213709 -0.32932603]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.64835833]\n",
            " [-0.68517961]\n",
            " [-0.56807025]]\n",
            "The biases b gradient is:\n",
            " [ 0.00854797  0.00285513 -0.00263216]\n",
            "The bias c gradient is: \n",
            " [-0.03908334]\n",
            "\n",
            "RUN:\n",
            "  87\n",
            "The sum of the b update is\n",
            " [ 0.00857748  0.00275942 -0.00287547]\n",
            "The b biases before the update are:\n",
            " [[-0.18810913 -0.69602637  0.02455217]]\n",
            "Updated bs are:\n",
            " [[-0.1881949  -0.69605396  0.02458092]]\n",
            "The W1 is: \n",
            " [[-0.75421795  0.25004384  0.62473758]\n",
            " [-2.61877981  0.94267899  0.63695425]\n",
            " [-1.26821768 -2.48264295 -1.1907507 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.05670932 -0.28398979 -0.64165203]\n",
            " [-0.00436412 -0.3958399  -0.73971205]\n",
            " [ 0.21730419  0.34386577 -0.33401466]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.63766226]\n",
            " [-0.67899358]\n",
            " [-0.56923376]]\n",
            "The biases b gradient is:\n",
            " [ 0.00857748  0.00275942 -0.00287547]\n",
            "The bias c gradient is: \n",
            " [-0.03893012]\n",
            "\n",
            "RUN:\n",
            "  88\n",
            "The sum of the b update is\n",
            " [ 0.00860503  0.00266543 -0.0031165 ]\n",
            "The b biases before the update are:\n",
            " [[-0.1881949  -0.69605396  0.02458092]]\n",
            "Updated bs are:\n",
            " [[-0.18828095 -0.69608062  0.02461209]]\n",
            "The W1 is: \n",
            " [[-0.75363924  0.25284897  0.63116236]\n",
            " [-2.61872191  0.94659955  0.64435809]\n",
            " [-1.27040562 -2.48609873 -1.18736563]]\n",
            "The W1 gradient is: \n",
            " [[-0.05787139 -0.28051312 -0.64247827]\n",
            " [-0.00578942 -0.39205565 -0.74038401]\n",
            " [ 0.218794    0.34557818 -0.33850695]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.62721107]\n",
            " [-0.67281458]\n",
            " [-0.57033582]]\n",
            "The biases b gradient is:\n",
            " [ 0.00860503  0.00266543 -0.0031165 ]\n",
            "The bias c gradient is: \n",
            " [-0.03876921]\n",
            "\n",
            "RUN:\n",
            "  89\n",
            "The sum of the b update is\n",
            " [ 0.00863069  0.00257315 -0.00335497]\n",
            "The b biases before the update are:\n",
            " [[-0.18828095 -0.69608062  0.02461209]]\n",
            "Updated bs are:\n",
            " [[-0.18836726 -0.69610635  0.02464564]]\n",
            "The W1 is: \n",
            " [[-0.7530491   0.25561985  0.63759428]\n",
            " [-2.61864987  0.95048269  0.65176734]\n",
            " [-1.27260824 -2.48957148 -1.18393776]]\n",
            "The W1 gradient is: \n",
            " [[-0.05901408 -0.27708849 -0.64319124]\n",
            " [-0.00720419 -0.3883138  -0.74092545]\n",
            " [ 0.22026235  0.34727464 -0.34278691]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.61699713]\n",
            " [-0.66664654]\n",
            " [-0.57137507]]\n",
            "The biases b gradient is:\n",
            " [ 0.00863069  0.00257315 -0.00335497]\n",
            "The bias c gradient is: \n",
            " [-0.03860092]\n",
            "\n",
            "RUN:\n",
            "  90\n",
            "The sum of the b update is\n",
            " [ 0.0086545   0.00248254 -0.00359061]\n",
            "The b biases before the update are:\n",
            " [[-0.18836726 -0.69610635  0.02464564]]\n",
            "Updated bs are:\n",
            " [[-0.18845381 -0.69613117  0.02468155]]\n",
            "The W1 is: \n",
            " [[-0.75244772  0.258357    0.64403207]\n",
            " [-2.61856379  0.95432882  0.65918058]\n",
            " [-1.27482534 -2.49306103 -1.18046937]]\n",
            "The W1 gradient is: \n",
            " [[-0.06013763 -0.27371488 -0.64377909]\n",
            " [-0.00860833 -0.3846136  -0.74132418]\n",
            " [ 0.22170947  0.34895541 -0.34683871]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.60701333]\n",
            " [-0.6604931 ]\n",
            " [-0.5723495 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.0086545   0.00248254 -0.00359061]\n",
            "The bias c gradient is: \n",
            " [-0.03842552]\n",
            "\n",
            "RUN:\n",
            "  91\n",
            "The sum of the b update is\n",
            " [ 0.0086765   0.00239359 -0.00382312]\n",
            "The b biases before the update are:\n",
            " [[-0.18845381 -0.69613117  0.02468155]]\n",
            "Updated bs are:\n",
            " [[-0.18854057 -0.69615511  0.02471978]]\n",
            "The W1 is: \n",
            " [[-0.7518353   0.26106092  0.65047437]\n",
            " [-2.61846377  0.95813837  0.66659627]\n",
            " [-1.27705669 -2.49656724 -1.1769629 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.06124225 -0.27039133 -0.64423027]\n",
            " [-0.01000173 -0.38095438 -0.74156835]\n",
            " [ 0.22313559  0.35062072 -0.35064677]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.59725304]\n",
            " [-0.65435757]\n",
            " [-0.57325654]]\n",
            "The biases b gradient is:\n",
            " [ 0.0086765   0.00239359 -0.00382312]\n",
            "The bias c gradient is: \n",
            " [-0.03824329]\n",
            "\n",
            "RUN:\n",
            "  92\n",
            "The sum of the b update is\n",
            " [ 0.00869675  0.00230627 -0.00405223]\n",
            "The b biases before the update are:\n",
            " [[-0.18854057 -0.69615511  0.02471978]]\n",
            "Updated bs are:\n",
            " [[-0.18862754 -0.69617817  0.0247603 ]]\n",
            "The W1 is: \n",
            " [[-0.75121202  0.26373209  0.6569197 ]\n",
            " [-2.61834993  0.96191172  0.67401273]\n",
            " [-1.2793021  -2.50008995 -1.17342095]]\n",
            "The W1 gradient is: \n",
            " [[-0.06232817 -0.26711697 -0.64453359]\n",
            " [-0.01138428 -0.37733554 -0.74164648]\n",
            " [ 0.22454097  0.35227074 -0.35419591]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.58771005]\n",
            " [-0.64824304]\n",
            " [-0.5740931 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00869675  0.00230627 -0.00405223]\n",
            "The bias c gradient is: \n",
            " [-0.03805449]\n",
            "\n",
            "RUN:\n",
            "  93\n",
            "The sum of the b update is\n",
            " [ 0.00871528  0.00222057 -0.00427764]\n",
            "The b biases before the update are:\n",
            " [[-0.18862754 -0.69617817  0.0247603 ]]\n",
            "Updated bs are:\n",
            " [[-0.18871469 -0.69620038  0.02480308]]\n",
            "The W1 is: \n",
            " [[-0.75057806  0.26637099  0.66336649]\n",
            " [-2.61822237  0.96564929  0.68142821]\n",
            " [-1.28156136 -2.503629   -1.16984623]]\n",
            "The W1 gradient is: \n",
            " [[-0.06339561 -0.26389098 -0.6446783 ]\n",
            " [-0.01275588 -0.37375657 -0.7415476 ]\n",
            " [ 0.22592584  0.3539056  -0.35747147]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.57837857]\n",
            " [-0.64215231]\n",
            " [-0.57485566]]\n",
            "The biases b gradient is:\n",
            " [ 0.00871528  0.00222057 -0.00427764]\n",
            "The bias c gradient is: \n",
            " [-0.03785938]\n",
            "\n",
            "RUN:\n",
            "  94\n",
            "The sum of the b update is\n",
            " [ 0.00873214  0.00213647 -0.00449909]\n",
            "The b biases before the update are:\n",
            " [[-0.18871469 -0.69620038  0.02480308]]\n",
            "Updated bs are:\n",
            " [[-0.18880201 -0.69622174  0.02484807]]\n",
            "The W1 is: \n",
            " [[-0.74993361  0.26897812  0.66981303]\n",
            " [-2.6180812   0.96935146  0.68884082]\n",
            " [-1.28383426 -2.50718426 -1.16624164]]\n",
            "The W1 gradient is: \n",
            " [[-0.06444476 -0.26071265 -0.64465419]\n",
            " [-0.01411641 -0.37021703 -0.74126133]\n",
            " [ 0.22729047  0.35552538 -0.36045945]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.56925321]\n",
            " [-0.63608798]\n",
            " [-0.57554029]]\n",
            "The biases b gradient is:\n",
            " [ 0.00873214  0.00213647 -0.00449909]\n",
            "The bias c gradient is: \n",
            " [-0.03765823]\n",
            "\n",
            "RUN:\n",
            "  95\n",
            "The sum of the b update is\n",
            " [ 0.00874737  0.00205396 -0.00471628]\n",
            "The b biases before the update are:\n",
            " [[-0.18880201 -0.69622174  0.02484807]]\n",
            "Updated bs are:\n",
            " [[-0.18888949 -0.69624228  0.02489523]]\n",
            "The W1 is: \n",
            " [[-0.74927885  0.27155393  0.67625755]\n",
            " [-2.61792655  0.97301863  0.6962486 ]\n",
            " [-1.28612062 -2.51075556 -1.16261017]]\n",
            "The W1 gradient is: \n",
            " [[-0.06547584 -0.25758131 -0.64445165]\n",
            " [-0.01546578 -0.36671652 -0.74077793]\n",
            " [ 0.22863513  0.35713012 -0.36314662]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.56032888]\n",
            " [-0.63005245]\n",
            " [-0.57614275]]\n",
            "The biases b gradient is:\n",
            " [ 0.00874737  0.00205396 -0.00471628]\n",
            "The bias c gradient is: \n",
            " [-0.03745127]\n",
            "\n",
            "RUN:\n",
            "  96\n",
            "The sum of the b update is\n",
            " [ 0.00876101  0.00197302 -0.00492895]\n",
            "The b biases before the update are:\n",
            " [[-0.18888949 -0.69624228  0.02489523]]\n",
            "Updated bs are:\n",
            " [[-0.1889771  -0.69626201  0.02494452]]\n",
            "The W1 is: \n",
            " [[-0.74861396  0.2740989   0.68269816]\n",
            " [-2.61775851  0.97665117  0.70364948]\n",
            " [-1.28842022 -2.51434276 -1.15895496]]\n",
            "The W1 gradient is: \n",
            " [[-0.06648902 -0.25449634 -0.64406177]\n",
            " [-0.01680387 -0.36325474 -0.74008843]\n",
            " [ 0.22996007  0.35871982 -0.36552066]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.55160087]\n",
            " [-0.62404793]\n",
            " [-0.57665854]]\n",
            "The biases b gradient is:\n",
            " [ 0.00876101  0.00197302 -0.00492895]\n",
            "The bias c gradient is: \n",
            " [-0.03723878]\n",
            "\n",
            "RUN:\n",
            "  97\n",
            "The sum of the b update is\n",
            " [ 0.00877309  0.00189365 -0.00513686]\n",
            "The b biases before the update are:\n",
            " [[-0.1889771  -0.69626201  0.02494452]]\n",
            "Updated bs are:\n",
            " [[-0.18906483 -0.69628095  0.02499589]]\n",
            "The W1 is: \n",
            " [[-0.74793912  0.27661347  0.68913293]\n",
            " [-2.6175772   0.98024949  0.71104133]\n",
            " [-1.29073287 -2.5179457  -1.15527926]]\n",
            "The W1 gradient is: \n",
            " [[-0.06748452 -0.25145719 -0.64347643]\n",
            " [-0.01813058 -0.35983144 -0.73918469]\n",
            " [ 0.23126558  0.36029443 -0.36757029]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.54306472]\n",
            " [-0.61807644]\n",
            " [-0.57708299]]\n",
            "The biases b gradient is:\n",
            " [ 0.00877309  0.00189365 -0.00513686]\n",
            "The bias c gradient is: \n",
            " [-0.03702099]\n",
            "\n",
            "RUN:\n",
            "  98\n",
            "The sum of the b update is\n",
            " [ 0.00878366  0.00181584 -0.00533974]\n",
            "The b biases before the update are:\n",
            " [[-0.18906483 -0.69628095  0.02499589]]\n",
            "Updated bs are:\n",
            " [[-0.18915266 -0.69629911  0.02504928]]\n",
            "The W1 is: \n",
            " [[-0.74725449  0.2790981   0.69555981]\n",
            " [-2.61738274  0.98381395  0.71842193]\n",
            " [-1.29305839 -2.52156424 -1.15158641]]\n",
            "The W1 gradient is: \n",
            " [[-0.0684625  -0.24846338 -0.64268835]\n",
            " [-0.01944581 -0.3564464  -0.7380595 ]\n",
            " [ 0.23255194  0.36185388 -0.36928537]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.53471628]\n",
            " [-0.61213986]\n",
            " [-0.5774113 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00878366  0.00181584 -0.00533974]\n",
            "The bias c gradient is: \n",
            " [-0.03679817]\n",
            "\n",
            "RUN:\n",
            "  99\n",
            "The sum of the b update is\n",
            " [ 0.00879275  0.00173957 -0.00553738]\n",
            "The b biases before the update are:\n",
            " [[-0.18915266 -0.69629911  0.02504928]]\n",
            "Updated bs are:\n",
            " [[-0.18924059 -0.6963165   0.02510466]]\n",
            "The W1 is: \n",
            " [[-0.74656026  0.28155325  0.70197672]\n",
            " [-2.61717525  0.98734495  0.72578899]\n",
            " [-1.29539659 -2.52519822 -1.14787984]]\n",
            "The W1 gradient is: \n",
            " [[-0.06942315 -0.24551445 -0.64169119]\n",
            " [-0.02074946 -0.35309948 -0.73670664]\n",
            " [ 0.23381942  0.36339806 -0.37065702]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.52655162]\n",
            " [-0.60623994]\n",
            " [-0.57763862]]\n",
            "The biases b gradient is:\n",
            " [ 0.00879275  0.00173957 -0.00553738]\n",
            "The bias c gradient is: \n",
            " [-0.03657056]\n",
            "\n",
            "RUN:\n",
            "  100\n",
            "The sum of the b update is\n",
            " [ 0.0088004   0.00166484 -0.00572956]\n",
            "The b biases before the update are:\n",
            " [[-0.18924059 -0.6963165   0.02510466]]\n",
            "Updated bs are:\n",
            " [[-0.18932859 -0.69633315  0.02516195]]\n",
            "The W1 is: \n",
            " [[-0.7458566   0.28397935  0.70838152]\n",
            " [-2.61695484  0.99084285  0.7331402 ]\n",
            " [-1.29774727 -2.52884749 -1.14416306]]\n",
            "The W1 gradient is: \n",
            " [[-0.07036666 -0.24261    -0.64047959]\n",
            " [-0.02204143 -0.34979058 -0.73512091]\n",
            " [ 0.23506832  0.36492682 -0.37167773]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.51856705]\n",
            " [-0.60037826]\n",
            " [-0.57776012]]\n",
            "The biases b gradient is:\n",
            " [ 0.0088004   0.00166484 -0.00572956]\n",
            "The bias c gradient is: \n",
            " [-0.03633842]\n",
            "\n",
            "RUN:\n",
            "  101\n",
            "The sum of the b update is\n",
            " [ 0.00880665  0.00159164 -0.00591608]\n",
            "The b biases before the update are:\n",
            " [[-0.18932859 -0.69633315  0.02516195]]\n",
            "Updated bs are:\n",
            " [[-0.18941666 -0.69634907  0.02522111]]\n",
            "The W1 is: \n",
            " [[-0.74514366  0.28637684  0.71477201]\n",
            " [-2.61672162  0.99430805  0.74047318]\n",
            " [-1.30011026 -2.53251189 -1.14043964]]\n",
            "The W1 gradient is: \n",
            " [[-0.0712932  -0.23974967 -0.63904922]\n",
            " [-0.02332162 -0.34651962 -0.73329826]\n",
            " [ 0.23629892  0.36643998 -0.37234144]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.51075907]\n",
            " [-0.59455632]\n",
            " [-0.57777106]]\n",
            "The biases b gradient is:\n",
            " [ 0.00880665  0.00159164 -0.00591608]\n",
            "The bias c gradient is: \n",
            " [-0.03610202]\n",
            "\n",
            "RUN:\n",
            "  102\n",
            "The sum of the b update is\n",
            " [ 0.00881153  0.00151996 -0.00609678]\n",
            "The b biases before the update are:\n",
            " [[-0.18941666 -0.69634907  0.02522111]]\n",
            "Updated bs are:\n",
            " [[-0.18950478 -0.69636427  0.02528208]]\n",
            "The W1 is: \n",
            " [[-0.74442163  0.28874618  0.72114598]\n",
            " [-2.61647572  0.99774091  0.74778554]\n",
            " [-1.30248537 -2.53619126 -1.13671321]]\n",
            "The W1 gradient is: \n",
            " [[-0.07220295 -0.23693312 -0.63739685]\n",
            " [-0.02458993 -0.34328657 -0.73123575]\n",
            " [ 0.23751152  0.36793736 -0.37264358]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.50312438]\n",
            " [-0.5887755 ]\n",
            " [-0.57766685]]\n",
            "The biases b gradient is:\n",
            " [ 0.00881153  0.00151996 -0.00609678]\n",
            "The bias c gradient is: \n",
            " [-0.0358616]\n",
            "\n",
            "RUN:\n",
            "  103\n",
            "The sum of the b update is\n",
            " [ 0.00881507  0.00144979 -0.00627151]\n",
            "The b biases before the update are:\n",
            " [[-0.18950478 -0.69636427  0.02528208]]\n",
            "Updated bs are:\n",
            " [[-0.18959293 -0.69637876  0.0253448 ]]\n",
            "The W1 is: \n",
            " [[-0.74369067  0.29108778  0.72750118]\n",
            " [-2.61621726  1.00114183  0.75507486]\n",
            " [-1.30487244 -2.53988545 -1.1329874 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.07309609 -0.23416007 -0.63552036]\n",
            " [-0.02584629 -0.34009144 -0.72893166]\n",
            " [ 0.23870641  0.36941872 -0.37258117]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.49565981]\n",
            " [-0.58303707]\n",
            " [-0.57744309]]\n",
            "The biases b gradient is:\n",
            " [ 0.00881507  0.00144979 -0.00627151]\n",
            "The bias c gradient is: \n",
            " [-0.03561744]\n",
            "\n",
            "RUN:\n",
            "  104\n",
            "The sum of the b update is\n",
            " [ 0.0088173   0.00138113 -0.00644013]\n",
            "The b biases before the update are:\n",
            " [[-0.18959293 -0.69637876  0.0253448 ]]\n",
            "Updated bs are:\n",
            " [[-0.1896811  -0.69639258  0.0254092 ]]\n",
            "The W1 is: \n",
            " [[-0.74295094  0.29340208  0.73383537]\n",
            " [-2.61594635  1.00451117  0.76233871]\n",
            " [-1.30727128 -2.54359429 -1.12926587]]\n",
            "The W1 gradient is: \n",
            " [[-0.07397278 -0.23143024 -0.63341875]\n",
            " [-0.02709058 -0.33693425 -0.72638542]\n",
            " [ 0.23988388  0.37088383 -0.37215282]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.48836234]\n",
            " [-0.57734222]\n",
            " [-0.57709567]]\n",
            "The biases b gradient is:\n",
            " [ 0.0088173   0.00138113 -0.00644013]\n",
            "The bias c gradient is: \n",
            " [-0.03536979]\n",
            "\n",
            "RUN:\n",
            "  105\n",
            "The sum of the b update is\n",
            " [ 0.00881827  0.00131397 -0.00660254]\n",
            "The b biases before the update are:\n",
            " [[-0.1896811  -0.69639258  0.0254092 ]]\n",
            "Updated bs are:\n",
            " [[-0.18976928 -0.69640572  0.02547522]]\n",
            "The W1 is: \n",
            " [[-0.74220261  0.29568951  0.74014629]\n",
            " [-2.61566312  1.00784932  0.76957469]\n",
            " [-1.30968172 -2.54731761 -1.12555228]]\n",
            "The W1 gradient is: \n",
            " [[-0.07483321 -0.22874338 -0.63109218]\n",
            " [-0.02832275 -0.33381504 -0.7235977 ]\n",
            " [ 0.24104424  0.37233243 -0.37135876]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.48122909]\n",
            " [-0.57169204]\n",
            " [-0.57662079]]\n",
            "The biases b gradient is:\n",
            " [ 0.00881827  0.00131397 -0.00660254]\n",
            "The bias c gradient is: \n",
            " [-0.03511892]\n",
            "\n",
            "RUN:\n",
            "  106\n",
            "The sum of the b update is\n",
            " [ 0.00881801  0.00124829 -0.00675868]\n",
            "The b biases before the update are:\n",
            " [[-0.18976928 -0.69640572  0.02547522]]\n",
            "Updated bs are:\n",
            " [[-0.18985746 -0.6964182   0.02554281]]\n",
            "The W1 is: \n",
            " [[-0.74144584  0.29795051  0.74643171]\n",
            " [-2.6153677   1.01115666  0.77678039]\n",
            " [-1.3121036  -2.55105526 -1.12185027]]\n",
            "The W1 gradient is: \n",
            " [[-0.07567756 -0.22609927 -0.62854193]\n",
            " [-0.02954271 -0.33073388 -0.72057034]\n",
            " [ 0.24218778  0.37376424 -0.37020087]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.47425726]\n",
            " [-0.56608758]\n",
            " [-0.57601501]]\n",
            "The biases b gradient is:\n",
            " [ 0.00881801  0.00124829 -0.00675868]\n",
            "The bias c gradient is: \n",
            " [-0.0348651]\n",
            "\n",
            "RUN:\n",
            "  107\n",
            "The sum of the b update is\n",
            " [ 0.00881654  0.00118409 -0.00690847]\n",
            "The b biases before the update are:\n",
            " [[-0.18985746 -0.6964182   0.02554281]]\n",
            "Updated bs are:\n",
            " [[-0.18994563 -0.69643004  0.0256119 ]]\n",
            "The W1 is: \n",
            " [[-0.74068078  0.30018548  0.75268942]\n",
            " [-2.61506019  1.01443357  0.78395346]\n",
            " [-1.31453674 -2.55480705 -1.11816345]]\n",
            "The W1 gradient is: \n",
            " [[-0.076506   -0.22349768 -0.6257704 ]\n",
            " [-0.03075038 -0.32769084 -0.71730637]\n",
            " [ 0.24331479  0.37517899 -0.36868259]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.46744414]\n",
            " [-0.56052979]\n",
            " [-0.5752753 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00881654  0.00118409 -0.00690847]\n",
            "The bias c gradient is: \n",
            " [-0.0346086]\n",
            "\n",
            "RUN:\n",
            "  108\n",
            "The sum of the b update is\n",
            " [ 0.00881389  0.00112136 -0.00705189]\n",
            "The b biases before the update are:\n",
            " [[-0.18994563 -0.69643004  0.0256119 ]]\n",
            "Updated bs are:\n",
            " [[-0.19003377 -0.69644125  0.02568241]]\n",
            "The W1 is: \n",
            " [[-0.73990759  0.30239487  0.75891723]\n",
            " [-2.61474074  1.01768043  0.79109156]\n",
            " [-1.316981   -2.55857281 -1.11449536]]\n",
            "The W1 gradient is: \n",
            " [[-0.07731871 -0.22093842 -0.62278108]\n",
            " [-0.03194571 -0.32468599 -0.71380992]\n",
            " [ 0.24442556  0.37657638 -0.36680893]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.46078709]\n",
            " [-0.55501955]\n",
            " [-0.57439908]]\n",
            "The biases b gradient is:\n",
            " [ 0.00881389  0.00112136 -0.00705189]\n",
            "The bias c gradient is: \n",
            " [-0.03434968]\n",
            "\n",
            "RUN:\n",
            "  109\n",
            "The sum of the b update is\n",
            " [ 0.00881011  0.0010601  -0.00718895]\n",
            "The b biases before the update are:\n",
            " [[-0.19003377 -0.69644125  0.02568241]]\n",
            "Updated bs are:\n",
            " [[-0.19012187 -0.69645185  0.0257543 ]]\n",
            "The W1 is: \n",
            " [[-0.73912643  0.30457908  0.76511301]\n",
            " [-2.61440945  1.02089762  0.79819242]\n",
            " [-1.3194362  -2.56235237 -1.11084949]]\n",
            "The W1 gradient is: \n",
            " [[-0.07811587 -0.21842126 -0.6195785 ]\n",
            " [-0.03312862 -0.32171942 -0.71008623]\n",
            " [ 0.24552039  0.37795613 -0.36458643]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.45428354]\n",
            " [-0.5495577 ]\n",
            " [-0.57338423]]\n",
            "The biases b gradient is:\n",
            " [ 0.00881011  0.0010601  -0.00718895]\n",
            "The bias c gradient is: \n",
            " [-0.03408861]\n",
            "\n",
            "RUN:\n",
            "  110\n",
            "The sum of the b update is\n",
            " [ 0.00880522  0.00100028 -0.00731965]\n",
            "The b biases before the update are:\n",
            " [[-0.19012187 -0.69645185  0.0257543 ]]\n",
            "Updated bs are:\n",
            " [[-0.19020992 -0.69646186  0.0258275 ]]\n",
            "The W1 is: \n",
            " [[-0.73833745  0.30673854  0.77127469]\n",
            " [-2.61406646  1.02408553  0.80525383]\n",
            " [-1.3219022  -2.56614555 -1.10722926]]\n",
            "The W1 gradient is: \n",
            " [[-0.07889768 -0.21594602 -0.61616816]\n",
            " [-0.03429908 -0.3187912  -0.70614155]\n",
            " [ 0.24659957  0.37931794 -0.36202303]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.44793096]\n",
            " [-0.54414501]\n",
            " [-0.57222916]]\n",
            "The biases b gradient is:\n",
            " [ 0.00880522  0.00100028 -0.00731965]\n",
            "The bias c gradient is: \n",
            " [-0.03382565]\n",
            "\n",
            "RUN:\n",
            "  111\n",
            "The sum of the b update is\n",
            " [ 0.00879926  0.00094189 -0.00744405]\n",
            "The b biases before the update are:\n",
            " [[-0.19020992 -0.69646186  0.0258275 ]]\n",
            "Updated bs are:\n",
            " [[-0.19029791 -0.69647128  0.02590194]]\n",
            "The W1 is: \n",
            " [[-0.73754081  0.30887366  0.77740026]\n",
            " [-2.61371189  1.02724455  0.81227366]\n",
            " [-1.32437883 -2.56995217 -1.10363798]]\n",
            "The W1 gradient is: \n",
            " [[-0.07966431 -0.21351249 -0.6125565 ]\n",
            " [-0.03545703 -0.3159014  -0.70198309]\n",
            " [ 0.24766337  0.38066152 -0.35912801]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.44172683]\n",
            " [-0.5387822 ]\n",
            " [-0.57093274]]\n",
            "The biases b gradient is:\n",
            " [ 0.00879926  0.00094189 -0.00744405]\n",
            "The bias c gradient is: \n",
            " [-0.03356108]\n",
            "\n",
            "RUN:\n",
            "  112\n",
            "The sum of the b update is\n",
            " [ 0.00879225  0.00088494 -0.00756221]\n",
            "The b biases before the update are:\n",
            " [[-0.19029791 -0.69647128  0.02590194]]\n",
            "Updated bs are:\n",
            " [[-0.19038584 -0.69648013  0.02597756]]\n",
            "The W1 is: \n",
            " [[-0.73673665  0.31098487  0.78348777]\n",
            " [-2.61334586  1.03037505  0.81924985]\n",
            " [-1.32686595 -2.57377203 -1.10007886]]\n",
            "The W1 gradient is: \n",
            " [[-0.08041595 -0.21112045 -0.6087508 ]\n",
            " [-0.03660244 -0.31305009 -0.69761894]\n",
            " [ 0.24871209  0.3819866  -0.35591191]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.4356687 ]\n",
            " [-0.53346996]\n",
            " [-0.56949441]]\n",
            "The biases b gradient is:\n",
            " [ 0.00879225  0.00088494 -0.00756221]\n",
            "The bias c gradient is: \n",
            " [-0.03329514]\n",
            "\n",
            "RUN:\n",
            "  113\n",
            "The sum of the b update is\n",
            " [ 0.00878422  0.00082939 -0.00767421]\n",
            "The b biases before the update are:\n",
            " [[-0.19038584 -0.69648013  0.02597756]]\n",
            "Updated bs are:\n",
            " [[-0.19047368 -0.69648842  0.02605431]]\n",
            "The W1 is: \n",
            " [[-0.73592512  0.31307257  0.78953536]\n",
            " [-2.61296851  1.03347742  0.82618043]\n",
            " [-1.32936341 -2.57760496 -1.096555  ]]\n",
            "The W1 gradient is: \n",
            " [[-0.08115281 -0.2087697  -0.60475909]\n",
            " [-0.03773527 -0.3102373  -0.69305796]\n",
            " [ 0.24974599  0.3832929  -0.35238639]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.42975408]\n",
            " [-0.52820889]\n",
            " [-0.5679141 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00878422  0.00082939 -0.00767421]\n",
            "The bias c gradient is: \n",
            " [-0.0330281]\n",
            "\n",
            "RUN:\n",
            "  114\n",
            "The sum of the b update is\n",
            " [ 0.0087752   0.00077524 -0.00778017]\n",
            "The b biases before the update are:\n",
            " [[-0.19047368 -0.69648842  0.02605431]]\n",
            "Updated bs are:\n",
            " [[-0.19056143 -0.69649617  0.02613211]]\n",
            "The W1 is: \n",
            " [[-0.73510637  0.31513717  0.79554126]\n",
            " [-2.61257996  1.03655205  0.83306353]\n",
            " [-1.33187107 -2.58145076 -1.09306936]]\n",
            "The W1 gradient is: \n",
            " [[-0.08187507 -0.20645999 -0.60059012]\n",
            " [-0.0388555  -0.30746306 -0.6883097 ]\n",
            " [ 0.25076535  0.38458015 -0.34856409]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.42398053]\n",
            " [-0.52299959]\n",
            " [-0.56619227]]\n",
            "The biases b gradient is:\n",
            " [ 0.0087752   0.00077524 -0.00778017]\n",
            "The bias c gradient is: \n",
            " [-0.03276021]\n",
            "\n",
            "RUN:\n",
            "  115\n",
            "The sum of the b update is\n",
            " [ 0.00876523  0.00072247 -0.0078802 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19056143 -0.69649617  0.02613211]]\n",
            "Updated bs are:\n",
            " [[-0.19064908 -0.6965034   0.02621091]]\n",
            "The W1 is: \n",
            " [[-0.73428054  0.31717908  0.80150379]\n",
            " [-2.61218033  1.03959933  0.83989737]\n",
            " [-1.33438877 -2.58530924 -1.08962477]]\n",
            "The W1 gradient is: \n",
            " [[-0.08258294 -0.20419109 -0.59625319]\n",
            " [-0.03996312 -0.30472739 -0.68338433]\n",
            " [ 0.25177043  0.38584812 -0.34445855]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.4183456 ]\n",
            " [-0.51784258]\n",
            " [-0.5643299 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00876523  0.00072247 -0.0078802 ]\n",
            "The bias c gradient is: \n",
            " [-0.03249172]\n",
            "\n",
            "RUN:\n",
            "  116\n",
            "The sum of the b update is\n",
            " [ 0.00875433  0.00067107 -0.00797444]\n",
            "The b biases before the update are:\n",
            " [[-0.19064908 -0.6965034   0.02621091]]\n",
            "Updated bs are:\n",
            " [[-0.19073663 -0.69651011  0.02629065]]\n",
            "The W1 is: \n",
            " [[-0.73344778  0.3191987   0.80742137]\n",
            " [-2.61176974  1.04261963  0.8466803 ]\n",
            " [-1.33691639 -2.58918021 -1.08622393]]\n",
            "The W1 gradient is: \n",
            " [[-0.08327662 -0.20196273 -0.59175811]\n",
            " [-0.04105812 -0.30203028 -0.6782925 ]\n",
            " [ 0.2527615   0.38709656 -0.34008406]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.41284682]\n",
            " [-0.51273836]\n",
            " [-0.56232844]]\n",
            "The biases b gradient is:\n",
            " [ 0.00875433  0.00067107 -0.00797444]\n",
            "The bias c gradient is: \n",
            " [-0.03222287]\n",
            "\n",
            "RUN:\n",
            "  117\n",
            "The sum of the b update is\n",
            " [ 0.00874253  0.00062102 -0.00806306]\n",
            "The b biases before the update are:\n",
            " [[-0.19073663 -0.69651011  0.02629065]]\n",
            "Updated bs are:\n",
            " [[-0.19082405 -0.69651632  0.02637128]]\n",
            "The W1 is: \n",
            " [[-0.73260821  0.32119645  0.81329252]\n",
            " [-2.61134834  1.04561335  0.85341075]\n",
            " [-1.33945377 -2.59306346 -1.08286938]]\n",
            "The W1 gradient is: \n",
            " [[-0.08395631 -0.19977464 -0.58711511]\n",
            " [-0.0421405  -0.29937167 -0.67304527]\n",
            " [ 0.2537388   0.38832527 -0.3354555 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.40748173]\n",
            " [-0.50768738]\n",
            " [-0.56018984]]\n",
            "The biases b gradient is:\n",
            " [ 0.00874253  0.00062102 -0.00806306]\n",
            "The bias c gradient is: \n",
            " [-0.03195388]\n",
            "\n",
            "RUN:\n",
            "  118\n",
            "The sum of the b update is\n",
            " [ 0.00872986  0.00057229 -0.00814621]\n",
            "The b biases before the update are:\n",
            " [[-0.19082405 -0.69651632  0.02637128]]\n",
            "Updated bs are:\n",
            " [[-0.19091135 -0.69652204  0.02645275]]\n",
            "The W1 is: \n",
            " [[-0.73176199  0.32317272  0.81911587]\n",
            " [-2.61091624  1.04858086  0.86008729]\n",
            " [-1.3420008  -2.5969588  -1.0795635 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.08462223 -0.19762653 -0.58233471]\n",
            " [-0.04321027 -0.29675152 -0.66765399]\n",
            " [ 0.2547026   0.38953405 -0.33058825]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.40224786]\n",
            " [-0.50269007]\n",
            " [-0.55791648]]\n",
            "The biases b gradient is:\n",
            " [ 0.00872986  0.00057229 -0.00814621]\n",
            "The bias c gradient is: \n",
            " [-0.031685]\n",
            "\n",
            "RUN:\n",
            "  119\n",
            "The sum of the b update is\n",
            " [ 0.00871635  0.00052488 -0.00822408]\n",
            "The b biases before the update are:\n",
            " [[-0.19091135 -0.69652204  0.02645275]]\n",
            "Updated bs are:\n",
            " [[-0.19099851 -0.69652729  0.02653499]]\n",
            "The W1 is: \n",
            " [[-0.73090925  0.3251279   0.82489015]\n",
            " [-2.61047356  1.05152256  0.86670859]\n",
            " [-1.34455733 -2.60086603 -1.07630852]]\n",
            "The W1 gradient is: \n",
            " [[-0.08527457 -0.19551807 -0.57742765]\n",
            " [-0.04426745 -0.29416973 -0.66213023]\n",
            " [ 0.25565311  0.39072273 -0.32549801]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.39714271]\n",
            " [-0.49774678]\n",
            " [-0.55551117]]\n",
            "The biases b gradient is:\n",
            " [ 0.00871635  0.00052488 -0.00822408]\n",
            "The bias c gradient is: \n",
            " [-0.03141644]\n",
            "\n",
            "RUN:\n",
            "  120\n",
            "The sum of the b update is\n",
            " [ 0.00870202  0.00047877 -0.00829685]\n",
            "The b biases before the update are:\n",
            " [[-0.19099851 -0.69652729  0.02653499]]\n",
            "Updated bs are:\n",
            " [[-0.19108553 -0.69653208  0.02661796]]\n",
            "The W1 is: \n",
            " [[-0.73005011  0.32706239  0.83061419]\n",
            " [-2.61002044  1.05443882  0.87327345]\n",
            " [-1.34712324 -2.60478494 -1.07310651]]\n",
            "The W1 gradient is: \n",
            " [[-0.08591356 -0.19344894 -0.57240481]\n",
            " [-0.04531206 -0.29162618 -0.65648566]\n",
            " [ 0.25659059  0.39189114 -0.32020073]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.39216379]\n",
            " [-0.49285785]\n",
            " [-0.55297711]]\n",
            "The biases b gradient is:\n",
            " [ 0.00870202  0.00047877 -0.00829685]\n",
            "The bias c gradient is: \n",
            " [-0.0311484]\n",
            "\n",
            "RUN:\n",
            "  121\n",
            "The sum of the b update is\n",
            " [ 0.0086869   0.00043393 -0.00836472]\n",
            "The b biases before the update are:\n",
            " [[-0.19108553 -0.69653208  0.02661796]]\n",
            "Updated bs are:\n",
            " [[-0.1911724  -0.69653642  0.0267016 ]]\n",
            "The W1 is: \n",
            " [[-0.72918472  0.32897657  0.83628697]\n",
            " [-2.609557    1.05733003  0.87978077]\n",
            " [-1.34969839 -2.60871533 -1.06995938]]\n",
            "The W1 gradient is: \n",
            " [[-0.0865394  -0.19141877 -0.56727712]\n",
            " [-0.04634414 -0.28912073 -0.65073198]\n",
            " [ 0.25751526  0.39303918 -0.31471243]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.3873086 ]\n",
            " [-0.48802359]\n",
            " [-0.55031786]]\n",
            "The biases b gradient is:\n",
            " [ 0.0086869   0.00043393 -0.00836472]\n",
            "The bias c gradient is: \n",
            " [-0.0308811]\n",
            "\n",
            "RUN:\n",
            "  122\n",
            "The sum of the b update is\n",
            " [ 0.00867103  0.00039034 -0.00842788]\n",
            "The b biases before the update are:\n",
            " [[-0.1911724  -0.69653642  0.0267016 ]]\n",
            "Updated bs are:\n",
            " [[-0.19125911 -0.69654032  0.02678588]]\n",
            "The W1 is: \n",
            " [[-0.72831319  0.33087085  0.84190752]\n",
            " [-2.60908336  1.06019656  0.88622958]\n",
            " [-1.35228266 -2.612657   -1.06686889]]\n",
            "The W1 gradient is: \n",
            " [[-0.08715233 -0.18942719 -0.56205547]\n",
            " [-0.04736372 -0.28665321 -0.64488082]\n",
            " [ 0.25842734  0.39416672 -0.30904913]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.38257459]\n",
            " [-0.48324426]\n",
            " [-0.5475373 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00867103  0.00039034 -0.00842788]\n",
            "The bias c gradient is: \n",
            " [-0.03061472]\n",
            "\n",
            "RUN:\n",
            "  123\n",
            "The sum of the b update is\n",
            " [ 0.00865442  0.00034798 -0.00848654]\n",
            "The b biases before the update are:\n",
            " [[-0.19125911 -0.69654032  0.02678588]]\n",
            "Updated bs are:\n",
            " [[-0.19134566 -0.6965438   0.02687075]]\n",
            "The W1 is: \n",
            " [[-0.72743567  0.33274558  0.84747503]\n",
            " [-2.60859965  1.06303879  0.89261902]\n",
            " [-1.35487593 -2.61660974 -1.06383662]]\n",
            "The W1 gradient is: \n",
            " [[-0.08775254 -0.18747381 -0.55675066]\n",
            " [-0.04837085 -0.28422341 -0.63894372]\n",
            " [ 0.25932704  0.39527368 -0.30322675]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.37795926]\n",
            " [-0.47852006]\n",
            " [-0.54463957]]\n",
            "The biases b gradient is:\n",
            " [ 0.00865442  0.00034798 -0.00848654]\n",
            "The bias c gradient is: \n",
            " [-0.03034945]\n",
            "\n",
            "RUN:\n",
            "  124\n",
            "The sum of the b update is\n",
            " [ 0.00863709  0.00030683 -0.00854089]\n",
            "The b biases before the update are:\n",
            " [[-0.19134566 -0.6965438   0.02687075]]\n",
            "Updated bs are:\n",
            " [[-0.19143203 -0.69654687  0.02695616]]\n",
            "The W1 is: \n",
            " [[-0.72655227  0.33460117  0.85298876]\n",
            " [-2.608106    1.06585711  0.89894834]\n",
            " [-1.35747808 -2.62057334 -1.06086402]]\n",
            "The W1 gradient is: \n",
            " [[-0.08834026 -0.1855582  -0.5513733 ]\n",
            " [-0.04936559 -0.28183111 -0.63293196]\n",
            " [ 0.26021457  0.39636    -0.29726094]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.37346004]\n",
            " [-0.47385119]\n",
            " [-0.54162909]]\n",
            "The biases b gradient is:\n",
            " [ 0.00863709  0.00030683 -0.00854089]\n",
            "The bias c gradient is: \n",
            " [-0.03008547]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################-output and vis----------------------    \n",
        "#print(\"Total Loss List:\", TotalLoss) \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig1 = plt.figure()\n",
        "ax = plt.axes()\n",
        "x = np.linspace(0, 10, Epochs)\n",
        "ax.plot(x, TotalLoss)    \n",
        "\n",
        "print(confusion_matrix(output, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "ISxTf4b7XRzB",
        "outputId": "acf42075-d17b-467a-e3d5-97b469640fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13  4]\n",
            " [ 1 11]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqqklEQVR4nO3df3DU9b3v8df+SDY/TDYkUWAhv/RYFUS0Bb0VRmFkSnMoaj21tUM9GTn32N7CQcwZquhB61hModZDtQwU74zYc4qtcy0c7Ll6yqUK9SpKxNh6S/lRIEQpIL+y+blJdr/3j2Q3RALku/vd73d/PB8zmWF/v2eHzb7y/vxyGYZhCAAAwCZupwsAAADZhfABAABsRfgAAAC2InwAAABbET4AAICtCB8AAMBWhA8AAGArwgcAALCV1+kCPisSiejIkSMqKiqSy+VyuhwAADAChmGora1NgUBAbveFexspFz6OHDmiiooKp8sAAABxaGlp0fjx4y94n5QLH0VFRZL6iy8uLna4GgAAMBLBYFAVFRWx7/ELSbnwER1qKS4uJnwAAJBmRjJlggmnAADAVoQPAABgK8IHAACwFeEDAADYivABAABsRfgAAAC2InwAAABbET4AAICtCB8AAMBWpsPH9u3bNXfuXAUCAblcLm3atGnI7e3t7Vq4cKHGjx+v/Px8TZgwQWvXrrWqXgAAkOZMh4+Ojg5NnjxZq1evHvb2+vp6vf766/r3f/937d69W4sXL9bChQu1efPmhIsFAADpz/TZLrW1taqtrT3v7W+//bbq6uo0Y8YMSdL999+vn/3sZ3rvvfd0++23x10oAADIDJYfLHfzzTdr8+bNmj9/vgKBgN58803t3btX//qv/zrs/UOhkEKhUOxyMBi0uqSU1XyyQxvePayecCSux9/yuUs186rLLK4KAIDksjx8PPfcc7r//vs1fvx4eb1eud1uPf/887rllluGvX9DQ4OeeOIJq8tIC0//dq9e/fBI3I9/eWeL/vD92fK4L36CIAAAqSIp4WPHjh3avHmzqqqqtH37di1YsECBQECzZs065/5Lly5VfX197HIwGFRFRYXVZaWkfcfaJEl3Xh/QuFH5ph67bvsBdfSE9dfWLo0fVZCM8gAASApLw0dXV5ceeeQRbdy4UXPmzJEkXXfddWpqatLTTz89bPjw+Xzy+XxWlpEWDMNQ88lOSdIDsz6nmvJCU49/7aOjOvBph5pPdhI+AABpxdJ9Pnp7e9Xb2yu3e+jTejweRSLxzWvIVJ+2hdTVG5bH7dK4EnNdD0mqLusPK4dOdlhdGgAASWW689He3q79+/fHLh88eFBNTU0qLS1VZWWlbr31Vi1ZskT5+fmqqqrStm3b9POf/1zPPPOMpYWnu0MDXY9xJfnK9ZrPgFVl/d2OaPcEAIB0YTp8NDY2aubMmbHL0fkadXV1Wr9+vX75y19q6dKlmjdvnk6dOqWqqiotX75c3/nOd6yrOgNEOxbREGFWrPNxgs4HACC9mA4fM2bMkGEY5719zJgxeuGFFxIqKhs0D4SPaIgwi84HACBdcbaLQ6LDLol2PppPdSgSOX8YBAAg1RA+HJJo52PcqHx53C5190Z0vC108QcAAJAiCB8OMAxDzSf6Ox/V5fF1PnI8bo0f2BuEFS8AgHRC+HDAqY4etYX65HIpoT06qqJDL4QPAEAaIXw4IDrfI+DPV16OJ+7nqR6YL3KISacAgDRC+HBAc4LLbKPofAAA0hHhwwGDK13im2waFet8nKDzAQBIH4QPBwyudLGu83GhvVcAAEglhA8HWNX5qCjNl8sldfSEdaK9x4rSAABIOsKHA2KdjziX2Ub5vB4F/PlDnhMAgFRH+LDZmc4enenslSRVliYWPqTBAMOKFwBAuiB82Cx6FsvoYp8Kck0frXMOVrwAANIN4cNmg6fZJjbfI4q9PgAA6YbwYbNo5yPRlS5RdD4AAOmG8GEz6zsf/c9z8ATLbQEA6YHwYbPBzoc14SM6abWtuy82kRUAgFRG+LCZVVurR+XnejTWnyeJ020BAOmB8GGjtu7e2GZgVoWPs5+rmUmnAIA0kPhazzTRG47oH15sdLSGrp4+SVL5Jbkqysux7Hmrywq148ApPbt1n379wSfn3O6SdNfnx+mO68dZ9poAAMQra8KHYUjb937qdBmSpAkBv6XPN3GcX9rZogMnOnTgxPBDL//vSJDwAQBICVkTPjxul35892Sny5DH7dL0K8stfc57plZodJFPbd1959zWF4nooVf+qBPtIbV191racQEAIB5ZFT7+7gvjnS4jKXI8bn1p4pjz3r7y9T062dGj5pOdunactV0XAADMYsJpFmBCKgAglRA+skB0TxGW4gIAUgHhIwuwBTsAIJUQPrJAdTmHzwEAUgfhIwvQ+QAApBLCRxaoGQgfx4IhdfacuxwXAAA7ET6ygL8gRyUF/ft7HD7F0AsAwFmEjywRHXo5dILwAQBwFuEjS1TH9vpg3gcAwFmEjywR63yw4gUA4DDCR5ag8wEASBWEjywxOOeD8AEAcBbhI0tEOx9HWrvV3Rt2uBoAQDYjfGSJ0sJcFfn6DzFuYbktAMBBhI8s4XK5VMU26wCAFED4yCJssw4ASAWEjywSnfdxiPABAHAQ4SOLDHY+GHYBADiH8JFFqmMbjdH5AAA4x3T42L59u+bOnatAICCXy6VNmzadc5/du3fr9ttvl9/vV2FhoaZOnarDhw9bUS8SEB12+eR0l3r6Ig5XAwDIVqbDR0dHhyZPnqzVq1cPe/tf/vIXTZ8+XVdffbXefPNN/eEPf9CyZcuUl5eXcLFIzKVFPuXneBQxpI9PM/QCAHCG1+wDamtrVVtbe97bH330Uf3t3/6tVq5cGbvuiiuuiK86WMrlcqmqrEB/Ptqm5pOduvzSS5wuCQCQhSyd8xGJRPSf//mf+tznPqfZs2frsssu00033TTs0ExUKBRSMBgc8oPkic77qH+5SdNX/E7TV/xO//3FRoUjhsOVAQCyhaXh4/jx42pvb9cPf/hDffnLX9Zvf/tbffWrX9Vdd92lbdu2DfuYhoYG+f3+2E9FRYWVJeEzptaUSpJOd/bq49Nd+vh0l/7P7mPad7zN4coAANnC9LDLhUQi/ZMY77jjDj344IOSpOuvv15vv/221q5dq1tvvfWcxyxdulT19fWxy8FgkACSRPOnVWv635Sra+B8l4Ubdunj010609nrcGUAgGxhafgoLy+X1+vVhAkThlx/zTXX6K233hr2MT6fTz6fz8oycAEul0tXjSmKXb6syEf4AADYytJhl9zcXE2dOlV79uwZcv3evXtVVVVl5UvBIiUFuZKk1q4ehysBAGQL052P9vZ27d+/P3b54MGDampqUmlpqSorK7VkyRJ94xvf0C233KKZM2fq9ddf16uvvqo333zTyrphkZL8HEmi8wEAsI3p8NHY2KiZM2fGLkfna9TV1Wn9+vX66le/qrVr16qhoUGLFi3SVVddpVdeeUXTp0+3rmpYxl8wED66CB8AAHuYDh8zZsyQYVx4Web8+fM1f/78uIuCfUry+4dd6HwAAOzC2S5ZrmSg88GcDwCAXQgfWS4aPuh8AADsQvjIcn4mnAIAbEb4yHKDS20JHwAAexA+stzgUlvmfAAA7EH4yHLROR8dPWH19EUcrgYAkA0IH1muKC9HLlf/vxl6AQDYgfCR5Txul4rzWG4LALAP4QMstwUA2IrwAc53AQDYivAB+QeW23K+CwDADoQPsNwWAGArwgfOOt+FzgcAIPkIH2DOBwDAVoQPMOcDAGArwgeY8wEAsBXhA8z5AADYivABNhkDANiK8AH58wfmfDDsAgCwAeEDsc5HsLtP4YjhcDUAgExH+ID8AxNOJSnIvA8AQJIRPqAcj1uX+LySWG4LAEg+wgckDXY/mPcBAEg2wgcknbXihc4HACDJCB+QdNZeHyy3BQAkGeEDkqQSltsCAGxC+IAkyc+wCwDAJoQPSOJkWwCAfQgfkMT5LgAA+xA+IIk5HwAA+xA+IIk5HwAA+xA+IGlwzgdLbQEAyUb4gCSppGBg2IXOBwAgyQgfkHTWDqedPYpwsi0AIIkIH5A0eLZLxJDae/ocrgYAkMkIH5Ak5eV4lJ/jkcS8DwBAchE+EDM49EL4AAAkD+EDMdGhlzNd7PUBAEgewgdi6HwAAOxA+EBMbJdTltsCAJKI8IGY2PkubLEOAEgi0+Fj+/btmjt3rgKBgFwulzZt2nTe+37nO9+Ry+XSqlWrEigRdvEz7AIAsIHp8NHR0aHJkydr9erVF7zfxo0btWPHDgUCgbiLg70YdgEA2MFr9gG1tbWqra294H0++eQT/dM//ZP+67/+S3PmzIm7ONgrOuzyyeku7f5rcNj7VJYWqNBn+r8NAAAxln+LRCIR3XvvvVqyZIkmTpx40fuHQiGFQqHY5WBw+C89JF/0cLl3DpxU7U9+P+x9Av48bf/eTHk9TBcCAMTH8m+QFStWyOv1atGiRSO6f0NDg/x+f+ynoqLC6pIwQv/t8jJdN96vS4t8w/5I0pHWbp1mTggAIAGWdj7ef/99/eQnP9GuXbvkcrlG9JilS5eqvr4+djkYDBJAHDKqMFebF04/7+0TH3tdHT1hdfb0SfLZVxgAIKNY2vn4/e9/r+PHj6uyslJer1der1fNzc3653/+Z1VXVw/7GJ/Pp+Li4iE/SE0FA3M9OkJhhysBAKQzSzsf9957r2bNmjXkutmzZ+vee+/VfffdZ+VLwQGFuR59Kg10PgAAiI/p8NHe3q79+/fHLh88eFBNTU0qLS1VZWWlysrKhtw/JydHY8aM0VVXXZV4tXBUQe5A56OHzgcAIH6mw0djY6NmzpwZuxydr1FXV6f169dbVhhST6HPI0nqDNH5AADEz3T4mDFjhgzDGPH9Dx06ZPYlkKLofAAArMBmDRixWOeDOR8AgAQQPjBisc4Hq10AAAkgfGDECnPpfAAAEkf4wIixzwcAwAqED4wYnQ8AgBUIHxgxVrsAAKxA+MCIsc8HAMAKhA+M2GDng/ABAIgf4QMjNrjPB8MuAID4ET4wYoP7fND5AADEj/CBESscCB90PgAAiSB8YMQKBoZd6HwAABJB+MCInd35MHO4IAAAZyN8YMSinY++iKGecMThagAA6YrwgREryPHE/t3JFusAgDgRPjBiXo9bPm//fxn2+gAAxIvwAVMKfax4AQAkhvABUwpyWfECAEgM4QOmsNcHACBRhA+Ywl4fAIBEET5gCp0PAECiCB8wJTbng9UuAIA4ET5gSmy1C/t8AADiRPiAKXQ+AACJInzAFPb5AAAkivABU9jnAwCQKMIHTGG1CwAgUYQPmMI+HwCARBE+YAqdDwBAoggfMIXVLgCARBE+YAr7fAAAEkX4gCl0PgAAiSJ8wBT2+QAAJIrwAVPY5wMAkCjCB0yJrnYJ9UXUF444XA0AIB0RPmBKdJ8PSersZegFAGAe4QOm5Hrc8rpdkljxAgCID+EDprhcLla8AAASQviAaez1AQBIBOEDptH5AAAkwnT42L59u+bOnatAICCXy6VNmzbFbuvt7dVDDz2kSZMmqbCwUIFAQH//93+vI0eOWFkzHDa41wfhAwBgnunw0dHRocmTJ2v16tXn3NbZ2aldu3Zp2bJl2rVrl379619rz549uv322y0pFqlhcK8Phl0AAOZ5zT6gtrZWtbW1w97m9/u1ZcuWIdf99Kc/1Y033qjDhw+rsrIyviqRUgZPtqXzAQAwL+lzPlpbW+VyuVRSUpLsl4JNCgaGXeh8AADiYbrzYUZ3d7ceeughffOb31RxcfGw9wmFQgqFQrHLwWAwmSXBAoUDwy50PgAA8Uha56O3t1df//rXZRiG1qxZc977NTQ0yO/3x34qKiqSVRIsUjAw7NLB4XIAgDgkJXxEg0dzc7O2bNly3q6HJC1dulStra2xn5aWlmSUBAsVDmyx3snhcgCAOFg+7BINHvv27dMbb7yhsrKyC97f5/PJ5/NZXQaSiM4HACARpsNHe3u79u/fH7t88OBBNTU1qbS0VGPHjtXXvvY17dq1S7/5zW8UDod19OhRSVJpaalyc3OtqxyOiXU+mPMBAIiD6fDR2NiomTNnxi7X19dLkurq6vT9739fmzdvliRdf/31Qx73xhtvaMaMGfFXipQR63yw2gUAEAfT4WPGjBkyDOO8t1/oNmQGVrsAABLB2S4wjX0+AACJIHzANDofAIBEED5gGqtdAACJIHzANPb5AAAkgvAB06Kdj87esCIRJhgDAMwhfMC0aOfDMKTuPoZeAADmED5gWp7XI5er/9+seAEAmEX4gGlut0sFOax4AQDEh/CBuLDXBwAgXoQPxIW9PgAA8SJ8IC7s9QEAiBfhA3Fhrw8AQLwIH4gLnQ8AQLwIH4hLrPPBnA8AgEmED8Ql1vlgtQsAwCTCB+LCahcAQLwIH4gL+3wAAOJF+EBc6HwAAOJF+EBcWO0CAIgX4QNxuWRg2KW9u9fhSgAA6YbwgbgU5+dIklq7CB8AAHMIH4hLSUF/+DhD+AAAmET4QFyi4aO1k/ABADCH8IG4lOTnSurvfBiG4XA1AIB0QvhAXKKdj3DEUDuHywEATCB8IC55OR75vP3/fc4w9AIAMIHwgbjF5n0w6RQAYALhA3GLzfug8wEAMIHwgbj5Y8ttexyuBACQTggfiFvJwEZjdD4AAGYQPhA35nwAAOJB+EDcSgqicz4YdgEAjBzhA3HzM+wCAIgD4QNx43wXAEA8CB+I2+BSW4ZdAAAjR/hA3GKdD4ZdAAAmED4Qt9icD4ZdAAAmED4Qt9hS205OtgUAjBzhA3GLLrXtCUfU1Rt2uBoAQLogfCBuhbkeed0uScz7AACMHOEDcXO5XEw6BQCYZjp8bN++XXPnzlUgEJDL5dKmTZuG3G4Yhh577DGNHTtW+fn5mjVrlvbt22dVvUgxg5NOWW4LABgZ0+Gjo6NDkydP1urVq4e9feXKlXr22We1du1avfvuuyosLNTs2bPV3d2dcLFIPdF5H610PgAAI+Q1+4Da2lrV1tYOe5thGFq1apX+5V/+RXfccYck6ec//7lGjx6tTZs26Z577kmsWqScEpbbAgBMsnTOx8GDB3X06FHNmjUrdp3f79dNN92kd955Z9jHhEIhBYPBIT9IH4OHyxE+AAAjY2n4OHr0qCRp9OjRQ64fPXp07LbPamhokN/vj/1UVFRYWRKSbPB8F+Z8AABGxvHVLkuXLlVra2vsp6WlxemSYEJ02IU5HwCAkbI0fIwZM0aSdOzYsSHXHzt2LHbbZ/l8PhUXFw/5QfpgqS0AwCxLw0dNTY3GjBmjrVu3xq4LBoN699139cUvftHKl0KK8EfnfDDsAgAYIdOrXdrb27V///7Y5YMHD6qpqUmlpaWqrKzU4sWL9YMf/EBXXnmlampqtGzZMgUCAd15551W1o0UEVvtQucDADBCpsNHY2OjZs6cGbtcX18vSaqrq9P69ev1ve99Tx0dHbr//vt15swZTZ8+Xa+//rry8vKsqxopI3a4HEttAQAj5DJS7DjSYDAov9+v1tZW5n+kgcMnO3XLj95Qfo5Hu5/8stPlAAAcYub72/HVLkhv/oHOR1dvWN2cbAsAGAHCBxJS5PNq4GBbBRl6AQCMAOEDCXG7XWcdLkf4AABcHOEDCWOLdQCAGYQPJCzW+ehkrw8AwMURPpCwwfNd6HwAAC6O8IGEcb4LAMAMwgcSVsIW6wAAEwgfSJifLdYBACYQPpAw5nwAAMwgfCBhsfNd6HwAAEaA8IGEleQz5wMAMHKEDyQser4Lcz4AACNB+EDCWGoLADCD8IGERZfatoX61BuOOFwNACDVET6QsOI8b+zfnGwLALgYwgcS5vW4VTQQQFhuCwC4GMIHLFHCpFMAwAgRPmCJ2HJbTrYFAFwE4QOWKL+kP3wcC4YcrgQAkOoIH7BEVVmhJKn5ZIfDlQAAUh3hA5aoLiuQJB0ifAAALoLwAUtUlUc7H50OVwIASHWED1iiemDY5dDJDhmG4XA1AIBURviAJcaV5Mvjdqm7N6LjbUw6BQCcH+EDlsj1ujWuJF+SdOgE8z4AAOdH+IBlqgYmnTLvAwBwIYQPWObseR8AAJwP4QOWofMBABgJwgcsQ+cDADAShA9Yprp8sPPBclsAwPkQPmCZ8aMK5HJJ7aE+nezggDkAwPAIH7BMXo5HAX//clvOeAEAnA/hA5aKTjo9dIJJpwCA4RE+YClOtwUAXAzhA5YaPN2WzgcAYHiED1iKzgcA4GIIH7BUdLktnQ8AwPkQPmCpytL+8NHa1asznSy3BQCci/ABSxXkejW62CeJ7gcAYHiED1iOeR8AgAuxPHyEw2EtW7ZMNTU1ys/P1xVXXKEnn3yS7bazSDV7fQAALsBr9ROuWLFCa9as0YsvvqiJEyeqsbFR9913n/x+vxYtWmT1yyEF0fkAAFyI5eHj7bff1h133KE5c+ZIkqqrq/XSSy/pvffes/qlkKI43RYAcCGWD7vcfPPN2rp1q/bu3StJ+vDDD/XWW2+ptrZ22PuHQiEFg8EhP0hvVWw0BgC4AMs7Hw8//LCCwaCuvvpqeTwehcNhLV++XPPmzRv2/g0NDXriiSesLgMOqi7v73yc6uhRsLtXxXk5DlcEAEgllnc+Xn75Zf3iF7/Qhg0btGvXLr344ot6+umn9eKLLw57/6VLl6q1tTX209LSYnVJsNklPq/KL8mVJB2m+wEA+AzLOx9LlizRww8/rHvuuUeSNGnSJDU3N6uhoUF1dXXn3N/n88nn81ldBhxWVVaoE+09OnSyQ9eO8ztdDgAghVje+ejs7JTbPfRpPR6PIpGI1S+FFBad99FM5wMA8BmWdz7mzp2r5cuXq7KyUhMnTtQHH3ygZ555RvPnz7f6pZDCaqIrXk6w4gUAMJTl4eO5557TsmXL9N3vflfHjx9XIBDQt7/9bT322GNWvxRSWFV5dK8POh8AgKEsDx9FRUVatWqVVq1aZfVTI43Edjllrw8AwGdwtguSoqq0v/NxvC2kzp4+h6sBAKQSwgeSwl+Qo1EF/ft7MPQCADgb4QNJwxkvAIDhED6QNNVssw4AGAbhA0lD5wMAMBzCB5Kmunyg83GCzgcAYBDhA0lD5wMAMBzCB5KmeiB8HGntVndv2OFqAACpgvCBpBlVkKOivP597FpOMfQCAOhH+EDSuFyuWPfjIGe8AAAGED6QVJxuCwD4LMIHkira+eCMFwBAFOEDSUXnAwDwWYQPJFV1OZ0PAMBQhA8kVbTzceRMl0J9LLcFABA+kGSXXuJTQa5HEUP6+HSX0+UAAFIA4QNJ5XK52OkUADCE1+kCkPmqywq0+69Bbd97Qnlez7l3cEmTxvlVlJdjf3FpqCPUpw8/PiMZTleCbOHL8ej6ihJ53C6nS0GGIHwg6aKdj/VvH9L6tw8Ne58pVaP0v/7HzTZWlb6+/W/v6639J5wuA1nmwVmf0wOzrnS6DGQIwgeS7u8+P047D51SW3fvObeFI4b+8mmHPvz4jMIRg7+sLsIwDO06fFqSdHl5obwe3i8kV1t3n/7a2q0PWk47XQoyCOEDSXfl6CK9cp6uRiRi6OrHXldPX0RHznSporTA5urSy6ftIXX2hOV2Sa8vvkW5XqZtIbne+ctJffP5HTrEEQmwEL+54Ci326XKgcDBXiAXd+hE/2Zt40blEzxgi+ry/s/nx6e71BuOOFwNMgW/veC46rJo+GAX1IuJBrTotvVAso0uypPP61ZfxNCRMyyXhzUIH3BcbCkubd2Lii5Xjm7eBiSb2+2K/X/jDwRYhfABx9H5GLnoe0TnA3Zirx5YjfABx/GLbeQGOx+ED9gn9gfCCf5AgDUIH3Bc9K/45lOdikTYOet8DMNQ84lo54NhF9iHPxBgNcIHHBcoyZPX7VJPX0RHg91Ol5OyTnX0qC3UJ5dLLEmGraJ/ILAiDVYhfMBxXo879mXKL7fzi873GFucp7ycYbapB5IkOuG05VSXwnQnYQHCB1JC9JdbM5NOz4v5HnBKoCRfOR6XesIR/bWV5bZIHOEDKYG27sXFVrqUM+QCe3ncrlh3kj8QYAXCB1JCrPPBbPrzovMBJ/EHAqxE+EBK4BfbxQ3u8UHnA/ZjaBRWInwgJZz9i80wmNA2HDofcFLsDwR2IoYFCB9ICeNHFcjtkrp6w/q0LeR0OSnnTGePznT2SmJrdTiDzgesRPhASsj1ujVuVL4ktlkfTvQX/mVFPhXkeh2uBtlocDPADjYDRMIIH0gZzPs4P06zhdPGjcqXx+1Sd29Ex+lOIkGED6SMwbYu4eOzop0PhlzglByPW+Nj3Uk+o0gM4QMpY7DzwbDLZ8U6H+V0PuAczniBVQgfSBn8Yjs/Oh9IBbHTbfkDAQlKSvj45JNP9K1vfUtlZWXKz8/XpEmT1NjYmIyXQgapPmujMZbbDtXMnA+kAP5AgFUsnzZ/+vRpTZs2TTNnztRrr72mSy+9VPv27dOoUaOsfilkmIrSArlcUluoT6c6elR2ic/pklJCW3evTrT3SJIq6XzAQbHOBzsRI0GWh48VK1aooqJCL7zwQuy6mpoaq18GGSgvx6OxxXk60tqtQyc7CR8DokMuZYW5Ks7LcbgaZLOzOx+GYcjlcjlcEdKV5eFj8+bNmj17tu6++25t27ZN48aN03e/+1394z/+o9UvhQxUVVaoI63denlni/7016DT5STMn5+j2mvHKMcT/wgn8z2QKipK8+VySR09Yf3P3x9UXq4noeez4vOB9GR5+Dhw4IDWrFmj+vp6PfLII9q5c6cWLVqk3Nxc1dXVnXP/UCikUGhwzXgwmP5fOIjf5ZcW6p0DJ/Wrxhb9qrHF6XIs8fTdk/W1L4yP+/Hs8YFU4fN6VDGqQIdPdWr5/95tyXMm+vlAerI8fEQiEU2ZMkVPPfWUJOmGG27QRx99pLVr1w4bPhoaGvTEE09YXQbS1D9Mr1FXT1hdvWGnS0nY3mNt+sunHdqdYAenmWW2SCGPz52gV3Z9rETnhFv1+UB6sjx8jB07VhMmTBhy3TXXXKNXXnll2PsvXbpU9fX1scvBYFAVFRVWl4U0cfmll+iZb1zvdBmW+LcdzVq26aOEVwYcYtgFKeS2a0brtmtGJ/w8Vn0+kJ4sDx/Tpk3Tnj17hly3d+9eVVVVDXt/n88nn4+Jhcg8Vu2JwDJbZCL2DMluls/yefDBB7Vjxw499dRT2r9/vzZs2KB169ZpwYIFVr8UkNKiYeHwyU6F4zyIq7OnT8eCoSHPB2QCKz4fSF+Wh4+pU6dq48aNeumll3TttdfqySef1KpVqzRv3jyrXwpIaWP9ecrxuNQTjuhosDuu5zh8qv+vwpKCHPkLWGaLzGHF5wPpKylnc3/lK1/RV77ylWQ8NZA2vB63KkYV6MCJDjWf6NC4knzTzxHdzKmKrgcyjBWfD6QvFlcDSVSV4Lj24HwPJpsi8yT6+UD6InwASZToWRiDK13ofCDzcFZM9iJ8AEk0OKM/vl+udD6QyRL9fCB9ET6AJKoqj/5lF++wC50PZK5EPx9IX4QPIImiywkPDRzEZUZ3b1hHWrsGnofOBzJPIp8PpDfCB5BE40ry5XG71N0b0fG20MUfcJaPT3fKMKQin1elhblJqhBwTiKfD6Q3wgeQRLled2wJ4aET5sa1Y8tsyws4uhwZKZHPB9Ib4QNIsuhyQrPj2tFJeMz3QCaL9/OB9Eb4AJLs7HFtM6K/jJnvgUwW7+cD6Y3wASQZnQ/g/Oh8ZCfCB5Bk8f5ld4jTbJEF6HxkJ8IHkGTV5YN/2Y10OWFPX0SfnGaZLTJfPJ8PpD/CB5Bk40cVyOWS2kN9OtnRM6LHfHy6UxFDys/x6NIiX5IrBJwTz+cD6Y/wASRZXo5HAX//csKRnmExuLMpy2yR2eL5fCD9ET4AG8RO7zwxskl1zPdANjH7+UD6I3wANjB7emes81HOfA9kPk63zT6ED8AGg6d30vkAPsvs5wPpj/AB2CDuzgcrXZAF6HxkH6/TBQDZILqccN/xdj3x6v+76P1bTkV3N6Xzgcxn9vOBxHndLj06Z4Jzr+/YKwNZpKq0ULletzp7wnrh/x4a0WOKfF6NKc5LbmFACojn84HE5HrdhA8g0+XnerTu3i9o56FTI37M9L+5VG43y2yR+eL5fCAxHrezsy5cRoptKRcMBuX3+9Xa2qri4mKnywEAACNg5vubCacAAMBWhA8AAGArwgcAALAV4QMAANiK8AEAAGxF+AAAALYifAAAAFsRPgAAgK0IHwAAwFaEDwAAYCvCBwAAsBXhAwAA2IrwAQAAbOV1uoDPih6yGwwGHa4EAACMVPR7O/o9fiEpFz7a2tokSRUVFQ5XAgAAzGpra5Pf77/gfVzGSCKKjSKRiI4cOaKioiK5XC5LnzsYDKqiokItLS0qLi629LkxiPfZHrzP9uG9tgfvsz2S9T4bhqG2tjYFAgG53Ree1ZFynQ+3263x48cn9TWKi4v5j20D3md78D7bh/faHrzP9kjG+3yxjkcUE04BAICtCB8AAMBWWRU+fD6fHn/8cfl8PqdLyWi8z/bgfbYP77U9eJ/tkQrvc8pNOAUAAJktqzofAADAeYQPAABgK8IHAACwFeEDAADYKqvCx+rVq1VdXa28vDzddNNNeu+995wuKaM0NDRo6tSpKioq0mWXXaY777xTe/bscbqsjPfDH/5QLpdLixcvdrqUjPPJJ5/oW9/6lsrKypSfn69JkyapsbHR6bIySjgc1rJly1RTU6P8/HxdccUVevLJJ0d0PggubPv27Zo7d64CgYBcLpc2bdo05HbDMPTYY49p7Nixys/P16xZs7Rv3z5basua8PGrX/1K9fX1evzxx7Vr1y5NnjxZs2fP1vHjx50uLWNs27ZNCxYs0I4dO7Rlyxb19vbqS1/6kjo6OpwuLWPt3LlTP/vZz3Tdddc5XUrGOX36tKZNm6acnBy99tpr+tOf/qQf//jHGjVqlNOlZZQVK1ZozZo1+ulPf6rdu3drxYoVWrlypZ577jmnS0t7HR0dmjx5slavXj3s7StXrtSzzz6rtWvX6t1331VhYaFmz56t7u7u5BdnZIkbb7zRWLBgQexyOBw2AoGA0dDQ4GBVme348eOGJGPbtm1Ol5KR2trajCuvvNLYsmWLceuttxoPPPCA0yVllIceesiYPn2602VkvDlz5hjz588fct1dd91lzJs3z6GKMpMkY+PGjbHLkUjEGDNmjPGjH/0odt2ZM2cMn89nvPTSS0mvJys6Hz09PXr//fc1a9as2HVut1uzZs3SO++842Blma21tVWSVFpa6nAlmWnBggWaM2fOkP/XsM7mzZs1ZcoU3X333brssst0ww036Pnnn3e6rIxz8803a+vWrdq7d68k6cMPP9Rbb72l2tpahyvLbAcPHtTRo0eH/P7w+/266aabbPleTLmD5ZLhxIkTCofDGj169JDrR48erT//+c8OVZXZIpGIFi9erGnTpunaa691upyM88tf/lK7du3Szp07nS4lYx04cEBr1qxRfX29HnnkEe3cuVOLFi1Sbm6u6urqnC4vYzz88MMKBoO6+uqr5fF4FA6HtXz5cs2bN8/p0jLa0aNHJWnY78XobcmUFeED9luwYIE++ugjvfXWW06XknFaWlr0wAMPaMuWLcrLy3O6nIwViUQ0ZcoUPfXUU5KkG264QR999JHWrl1L+LDQyy+/rF/84hfasGGDJk6cqKamJi1evFiBQID3OYNlxbBLeXm5PB6Pjh07NuT6Y8eOacyYMQ5VlbkWLlyo3/zmN3rjjTc0fvx4p8vJOO+//76OHz+uz3/+8/J6vfJ6vdq2bZueffZZeb1ehcNhp0vMCGPHjtWECROGXHfNNdfo8OHDDlWUmZYsWaKHH35Y99xzjyZNmqR7771XDz74oBoaGpwuLaNFv/uc+l7MivCRm5urL3zhC9q6dWvsukgkoq1bt+qLX/yig5VlFsMwtHDhQm3cuFG/+93vVFNT43RJGem2227TH//4RzU1NcV+pkyZonnz5qmpqUkej8fpEjPCtGnTzlkqvnfvXlVVVTlUUWbq7OyU2z30q8jj8SgSiThUUXaoqanRmDFjhnwvBoNBvfvuu7Z8L2bNsEt9fb3q6uo0ZcoU3XjjjVq1apU6Ojp03333OV1axliwYIE2bNig//iP/1BRUVFs3NDv9ys/P9/h6jJHUVHROfNoCgsLVVZWxvwaCz344IO6+eab9dRTT+nrX/+63nvvPa1bt07r1q1zurSMMnfuXC1fvlyVlZWaOHGiPvjgAz3zzDOaP3++06Wlvfb2du3fvz92+eDBg2pqalJpaakqKyu1ePFi/eAHP9CVV16pmpoaLVu2TIFAQHfeeWfyi0v6epoU8txzzxmVlZVGbm6uceONNxo7duxwuqSMImnYnxdeeMHp0jIeS22T49VXXzWuvfZaw+fzGVdffbWxbt06p0vKOMFg0HjggQeMyspKIy8vz7j88suNRx991AiFQk6XlvbeeOONYX8n19XVGYbRv9x22bJlxujRow2fz2fcdtttxp49e2ypzWUYbCMHAADskxVzPgAAQOogfAAAAFsRPgAAgK0IHwAAwFaEDwAAYCvCBwAAsBXhAwAA2IrwAQAAbEX4AAAAtiJ8AAAAWxE+AACArQgfAADAVv8f/7F9M0zcFRcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt     \n",
        "\n",
        "##########################################################\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "levels = np.unique(y)\n",
        "levels\n",
        "\n",
        "cm = confusion_matrix(output, y)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=levels)                         \n",
        "disp.plot()\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "aLJWwNB99RFJ",
        "outputId": "b3a592a6-21a3-4e79-fc0e-adb0f634f622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clf_report = classification_report(y,\n",
        "                                   output,\n",
        "                                   labels=levels,\n",
        "                                   output_dict=True)\n",
        "\n",
        "# clf_report\n",
        "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "q1OjOQhe9uX9",
        "outputId": "42272c40-c86a-43b7-f2c7-78c8dcee210c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_epochs = 5\n",
        "for i in range(Epochs):\n",
        "    print(\"\\nRUN:\\n \", i)\n",
        "    output=MyNN.TrainNetwork(X, y)\n",
        "   \n",
        "    #print(\"The y is ...\\n\", y)\n",
        "    # print(\"The output is: \\n\", output)\n",
        "    output=np.where(output > 0.5, 1, 0)\n",
        "    # print('Prediction y^ is', output)\n",
        "    ## Using Categorical Cross Entropy...........\n",
        "    #loss = np.mean(-y * np.log(output))  ## We need y to place the \"1\" in the right place\n",
        "    loss=np.sum(np.square(output-y))\n",
        "    avgLoss=np.mean(np.square(output-y))\n",
        "    # print(\"The current average loss is\\n\", loss)\n",
        "    TotalLoss.append(loss)\n",
        "    AvgLoss.append(avgLoss)\n",
        "    \n",
        "    if i >= Epochs - last_epochs:\n",
        "        print(\"The current average loss is\\n\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaiOkJZl9unu",
        "outputId": "5b4014b0-9a75-4656-bbd5-75fa325f88fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RUN:\n",
            "  0\n",
            "The sum of the b update is\n",
            " [ 0.00861909  0.00026687 -0.00859116]\n",
            "The b biases before the update are:\n",
            " [[-0.19143203 -0.69654687  0.02695616]]\n",
            "Updated bs are:\n",
            " [[-0.19151822 -0.69654954  0.02704207]]\n",
            "The W1 is: \n",
            " [[-0.72566311  0.33643797  0.8584481 ]\n",
            " [-2.60760252  1.06865187  0.9052169 ]\n",
            " [-1.36008898 -2.62454759 -1.05795234]]\n",
            "The W1 gradient is: \n",
            " [[-0.08891571 -0.18367994 -0.54593381]\n",
            " [-0.05034799 -0.27947605 -0.62685662]\n",
            " [ 0.26109012  0.39742565 -0.29116711]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.36907442]\n",
            " [-0.4692378 ]\n",
            " [-0.53851047]]\n",
            "The biases b gradient is:\n",
            " [ 0.00861909  0.00026687 -0.00859116]\n",
            "The bias c gradient is: \n",
            " [-0.02982293]\n",
            "\n",
            "RUN:\n",
            "  1\n",
            "The sum of the b update is\n",
            " [ 0.00860042  0.00022808 -0.00863754]\n",
            "The b biases before the update are:\n",
            " [[-0.19151822 -0.69654954  0.02704207]]\n",
            "Updated bs are:\n",
            " [[-0.19160422 -0.69655182  0.02712844]]\n",
            "The W1 is: \n",
            " [[-0.72476832  0.33825635  0.86385252]\n",
            " [-2.60708934  1.07142345  0.91142419]\n",
            " [-1.36270852 -2.6285323  -1.05510274]]\n",
            "The W1 gradient is: \n",
            " [[-0.08947911 -0.18183856 -0.54044229]\n",
            " [-0.05131812 -0.27715795 -0.62072842]\n",
            " [ 0.26195388  0.39847062 -0.28496025]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.36479983]\n",
            " [-0.46468   ]\n",
            " [-0.53528852]]\n",
            "The biases b gradient is:\n",
            " [ 0.00860042  0.00022808 -0.00863754]\n",
            "The bias c gradient is: \n",
            " [-0.02956199]\n",
            "\n",
            "RUN:\n",
            "  2\n",
            "The sum of the b update is\n",
            " [ 0.00858112  0.00019043 -0.00868023]\n",
            "The b biases before the update are:\n",
            " [[-0.19160422 -0.69655182  0.02712844]]\n",
            "Updated bs are:\n",
            " [[-0.19169003 -0.69655372  0.02721525]]\n",
            "The W1 is: \n",
            " [[-0.72386801  0.34005669  0.86920161]\n",
            " [-2.60656658  1.07417221  0.91756976]\n",
            " [-1.36533658 -2.63252725 -1.05231619]]\n",
            "The W1 gradient is: \n",
            " [[-0.09003068 -0.1800336  -0.53490853]\n",
            " [-0.05227605 -0.2748765  -0.61455774]\n",
            " [ 0.26280605  0.3994949  -0.27865492]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.36063373]\n",
            " [-0.46017787]\n",
            " [-0.53196816]]\n",
            "The biases b gradient is:\n",
            " [ 0.00858112  0.00019043 -0.00868023]\n",
            "The bias c gradient is: \n",
            " [-0.02930279]\n",
            "\n",
            "RUN:\n",
            "  3\n",
            "The sum of the b update is\n",
            " [ 0.00856121  0.0001539  -0.00871944]\n",
            "The b biases before the update are:\n",
            " [[-0.19169003 -0.69655372  0.02721525]]\n",
            "Updated bs are:\n",
            " [[-0.19177565 -0.69655526  0.02730244]]\n",
            "The W1 is: \n",
            " [[-0.7229623   0.34183933  0.87449503]\n",
            " [-2.60603436  1.07689852  0.92365331]\n",
            " [-1.36797305 -2.63653223 -1.04959354]]\n",
            "The W1 gradient is: \n",
            " [[-0.09057063 -0.17826456 -0.52934197]\n",
            " [-0.05322186 -0.27263136 -0.60835457]\n",
            " [ 0.26364679  0.40049853 -0.27226516]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.3565736 ]\n",
            " [-0.45573144]\n",
            " [-0.52855442]]\n",
            "The biases b gradient is:\n",
            " [ 0.00856121  0.0001539  -0.00871944]\n",
            "The bias c gradient is: \n",
            " [-0.02904547]\n",
            "\n",
            "RUN:\n",
            "  4\n",
            "The sum of the b update is\n",
            " [ 0.0085407   0.00011846 -0.00875536]\n",
            "The b biases before the update are:\n",
            " [[-0.19177565 -0.69655526  0.02730244]]\n",
            "Updated bs are:\n",
            " [[-0.19186105 -0.69655644  0.02738999]]\n",
            "The W1 is: \n",
            " [[-0.72205131  0.34360464  0.87973254]\n",
            " [-2.6054928   1.07960275  0.92967459]\n",
            " [-1.37061781 -2.64054705 -1.0469355 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.09109917 -0.17653095 -0.52375165]\n",
            " [-0.05415562 -0.2704222  -0.60212844]\n",
            " [ 0.26447628  0.40148156 -0.26580449]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.35261689]\n",
            " [-0.45134072]\n",
            " [-0.52505243]]\n",
            "The biases b gradient is:\n",
            " [ 0.0085407   0.00011846 -0.00875536]\n",
            "The bias c gradient is: \n",
            " [-0.02879016]\n",
            "\n",
            "RUN:\n",
            "  5\n",
            "The sum of the b update is\n",
            " [ 8.51962724e-03  8.40945940e-05 -8.78817710e-03]\n",
            "The b biases before the update are:\n",
            " [[-0.19186105 -0.69655644  0.02738999]]\n",
            "Updated bs are:\n",
            " [[-0.19194625 -0.69655729  0.02747787]]\n",
            "The W1 is: \n",
            " [[-0.72113515  0.34535296  0.884914  ]\n",
            " [-2.60494203  1.08228523  0.93563348]\n",
            " [-1.37327076 -2.64457149 -1.04434264]]\n",
            "The W1 gradient is: \n",
            " [[-0.09161653 -0.17483225 -0.51814617]\n",
            " [-0.05507743 -0.26824862 -0.59588846]\n",
            " [ 0.26529468  0.40244406 -0.25928583]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.34876109]\n",
            " [-0.44700568]\n",
            " [-0.52146733]]\n",
            "The biases b gradient is:\n",
            " [ 8.51962724e-03  8.40945940e-05 -8.78817710e-03]\n",
            "The bias c gradient is: \n",
            " [-0.02853697]\n",
            "\n",
            "RUN:\n",
            "  6\n",
            "The sum of the b update is\n",
            " [ 8.49800696e-03  5.07790514e-05 -8.81808731e-03]\n",
            "The b biases before the update are:\n",
            " [[-0.19194625 -0.69655729  0.02747787]]\n",
            "Updated bs are:\n",
            " [[-0.19203123 -0.69655779  0.02756606]]\n",
            "The W1 is: \n",
            " [[-0.72021392  0.34708464  0.89003934]\n",
            " [-2.60438215  1.08494633  0.94152991]\n",
            " [-1.37593178 -2.64860535 -1.04181542]]\n",
            "The W1 gradient is: \n",
            " [[-0.09212292 -0.17316792 -0.51253373]\n",
            " [-0.05598736 -0.26611025 -0.58964324]\n",
            " [ 0.26610214  0.40338611 -0.25272147]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.34500371]\n",
            " [-0.44272627]\n",
            " [-0.51780429]]\n",
            "The biases b gradient is:\n",
            " [ 8.49800696e-03  5.07790514e-05 -8.81808731e-03]\n",
            "The bias c gradient is: \n",
            " [-0.028286]\n",
            "\n",
            "RUN:\n",
            "  7\n",
            "The sum of the b update is\n",
            " [ 8.47586062e-03  1.84883846e-05 -8.84526734e-03]\n",
            "The b biases before the update are:\n",
            " [[-0.19203123 -0.69655779  0.02756606]]\n",
            "Updated bs are:\n",
            " [[-0.19211599 -0.69655798  0.02765451]]\n",
            "The W1 is: \n",
            " [[-0.71928773  0.34880002  0.89510856]\n",
            " [-2.6038133   1.0875864   0.94736392]\n",
            " [-1.37860077 -2.65264843 -1.03935419]]\n",
            "The W1 gradient is: \n",
            " [[-0.09261854 -0.17153744 -0.50692204]\n",
            " [-0.05688552 -0.26400665 -0.58340091]\n",
            " [ 0.26689881  0.40430784 -0.24612308]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.34134225]\n",
            " [-0.43850238]\n",
            " [-0.51406846]]\n",
            "The biases b gradient is:\n",
            " [ 8.47586062e-03  1.84883846e-05 -8.84526734e-03]\n",
            "The bias c gradient is: \n",
            " [-0.02803735]\n",
            "\n",
            "RUN:\n",
            "  8\n",
            "The sum of the b update is\n",
            " [ 8.45320832e-03 -1.28010569e-05 -8.86989150e-03]\n",
            "The b biases before the update are:\n",
            " [[-0.19211599 -0.69655798  0.02765451]]\n",
            "Updated bs are:\n",
            " [[-0.19220052 -0.69655785  0.02774321]]\n",
            "The W1 is: \n",
            " [[-0.7183567   0.35049942  0.90012175]\n",
            " [-2.60323558  1.09020578  0.95313561]\n",
            " [-1.38127762 -2.65670052 -1.03695918]]\n",
            "The W1 gradient is: \n",
            " [[-0.09310361 -0.16994024 -0.50131839]\n",
            " [-0.05777199 -0.26193742 -0.57716913]\n",
            " [ 0.26768484  0.40520935 -0.23950168]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.33777427]\n",
            " [-0.43433389]\n",
            " [-0.51026497]]\n",
            "The biases b gradient is:\n",
            " [ 8.45320832e-03 -1.28010569e-05 -8.86989150e-03]\n",
            "The bias c gradient is: \n",
            " [-0.02779112]\n",
            "\n",
            "RUN:\n",
            "  9\n",
            "The sum of the b update is\n",
            " [ 8.43006952e-03 -4.31128380e-05 -8.89212747e-03]\n",
            "The b biases before the update are:\n",
            " [[-0.19220052 -0.69655785  0.02774321]]\n",
            "Updated bs are:\n",
            " [[-0.19228482 -0.69655742  0.02783213]]\n",
            "The W1 is: \n",
            " [[-0.71742091  0.35218318  0.90507904]\n",
            " [-2.60264911  1.0928048   0.95884516]\n",
            " [-1.38396222 -2.66076143 -1.0346305 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.09357833 -0.16837578 -0.49572956]\n",
            " [-0.05864687 -0.25990211 -0.57095504]\n",
            " [ 0.26846036  0.40609078 -0.23286763]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.33429733]\n",
            " [-0.43022064]\n",
            " [-0.50639889]]\n",
            "The biases b gradient is:\n",
            " [ 8.43006952e-03 -4.31128380e-05 -8.89212747e-03]\n",
            "The bias c gradient is: \n",
            " [-0.02754737]\n",
            "\n",
            "RUN:\n",
            "  10\n",
            "The sum of the b update is\n",
            " [ 8.40646299e-03 -7.24703877e-05 -8.91213602e-03]\n",
            "The b biases before the update are:\n",
            " [[-0.19228482 -0.69655742  0.02783213]]\n",
            "Updated bs are:\n",
            " [[-0.19236889 -0.69655669  0.02792125]]\n",
            "The W1 is: \n",
            " [[-0.71648048  0.35385161  0.90998066]\n",
            " [-2.60205401  1.0953838   0.96449281]\n",
            " [-1.38665447 -2.66483095 -1.03236819]]\n",
            "The W1 gradient is: \n",
            " [[-0.09404291 -0.16684349 -0.49016192]\n",
            " [-0.05951026 -0.25790025 -0.56476529]\n",
            " [ 0.2692255   0.4069523  -0.22623063]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.33090902]\n",
            " [-0.42616245]\n",
            " [-0.50247519]]\n",
            "The biases b gradient is:\n",
            " [ 8.40646299e-03 -7.24703877e-05 -8.91213602e-03]\n",
            "The bias c gradient is: \n",
            " [-0.02730619]\n",
            "\n",
            "RUN:\n",
            "  11\n",
            "The sum of the b update is\n",
            " [ 0.00838241 -0.0001009  -0.00893007]\n",
            "The b biases before the update are:\n",
            " [[-0.19236889 -0.69655669  0.02792125]]\n",
            "Updated bs are:\n",
            " [[-0.19245271 -0.69655569  0.02801055]]\n",
            "The W1 is: \n",
            " [[-0.71553551  0.35550504  0.91482687]\n",
            " [-2.60145038  1.09794311  0.97007887]\n",
            " [-1.38935428 -2.66890889 -1.0301722 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.09449753 -0.1653428  -0.48462136]\n",
            " [-0.06036226 -0.25593139 -0.55860605]\n",
            " [ 0.26998039  0.40779406 -0.21959974]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.32760699]\n",
            " [-0.42215908]\n",
            " [-0.49849877]]\n",
            "The biases b gradient is:\n",
            " [ 0.00838241 -0.0001009  -0.00893007]\n",
            "The bias c gradient is: \n",
            " [-0.02706763]\n",
            "\n",
            "RUN:\n",
            "  12\n",
            "The sum of the b update is\n",
            " [ 0.00835792 -0.00012842 -0.00894608]\n",
            "The b biases before the update are:\n",
            " [[-0.19245271 -0.69655569  0.02801055]]\n",
            "Updated bs are:\n",
            " [[-0.19253629 -0.6965544   0.02810001]]\n",
            "The W1 is: \n",
            " [[-0.71458608  0.35714377  0.91961801]\n",
            " [-2.60083836  1.10048306  0.9756037 ]\n",
            " [-1.39206153 -2.67299506 -1.02804236]]\n",
            "The W1 gradient is: \n",
            " [[-0.0949424  -0.16387314 -0.47911331]\n",
            " [-0.06120298 -0.25399504 -0.55248301]\n",
            " [ 0.27072515  0.40861625 -0.21298336]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.32438889]\n",
            " [-0.4182103 ]\n",
            " [-0.49447441]]\n",
            "The biases b gradient is:\n",
            " [ 0.00835792 -0.00012842 -0.00894608]\n",
            "The bias c gradient is: \n",
            " [-0.02683176]\n",
            "\n",
            "RUN:\n",
            "  13\n",
            "The sum of the b update is\n",
            " [ 0.00833301 -0.00015505 -0.0089603 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19253629 -0.6965544   0.02810001]]\n",
            "Updated bs are:\n",
            " [[-0.19261962 -0.69655285  0.02818961]]\n",
            "The W1 is: \n",
            " [[-0.71363231  0.35876811  0.92435443]\n",
            " [-2.60021803  1.10300397  0.98106772]\n",
            " [-1.39477613 -2.67708925 -1.02597847]]\n",
            "The W1 gradient is: \n",
            " [[-0.09537771 -0.16243393 -0.47364277]\n",
            " [-0.06203251 -0.25209072 -0.54640141]\n",
            " [ 0.27145989  0.40941906 -0.20638928]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.32125242]\n",
            " [-0.41431583]\n",
            " [-0.49040679]]\n",
            "The biases b gradient is:\n",
            " [ 0.00833301 -0.00015505 -0.0089603 ]\n",
            "The bias c gradient is: \n",
            " [-0.02659861]\n",
            "\n",
            "RUN:\n",
            "  14\n",
            "The sum of the b update is\n",
            " [ 0.00830771 -0.00018082 -0.00897286]\n",
            "The b biases before the update are:\n",
            " [[-0.19261962 -0.69655285  0.02818961]]\n",
            "Updated bs are:\n",
            " [[-0.1927027  -0.69655104  0.02827934]]\n",
            "The W1 is: \n",
            " [[-0.71267427  0.36037836  0.92903658]\n",
            " [-2.59958952  1.10550615  0.98647138]\n",
            " [-1.39749798 -2.68119127 -1.02398022]]\n",
            "The W1 gradient is: \n",
            " [[-0.09580363 -0.1610246  -0.46821433]\n",
            " [-0.06285096 -0.25021794 -0.54036601]\n",
            " [ 0.27218471  0.41020268 -0.19982468]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.31819534]\n",
            " [-0.41047537]\n",
            " [-0.48630042]]\n",
            "The biases b gradient is:\n",
            " [ 0.00830771 -0.00018082 -0.00897286]\n",
            "The bias c gradient is: \n",
            " [-0.02636824]\n",
            "\n",
            "RUN:\n",
            "  15\n",
            "The sum of the b update is\n",
            " [ 0.00828203 -0.00020575 -0.0089839 ]\n",
            "The b biases before the update are:\n",
            " [[-0.1927027  -0.69655104  0.02827934]]\n",
            "Updated bs are:\n",
            " [[-0.19278552 -0.69654898  0.02836918]]\n",
            "The W1 is: \n",
            " [[-0.71171207  0.3619748   0.9336649 ]\n",
            " [-2.59895294  1.10798991  0.99181519]\n",
            " [-1.40022697 -2.68530095 -1.02204726]]\n",
            "The W1 gradient is: \n",
            " [[-0.09622037 -0.15964458 -0.46283216]\n",
            " [-0.06365844 -0.2483762  -0.53438115]\n",
            " [ 0.27289972  0.41096732 -0.19329613]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.31521542]\n",
            " [-0.4066886 ]\n",
            " [-0.48215971]]\n",
            "The biases b gradient is:\n",
            " [ 0.00828203 -0.00020575 -0.0089839 ]\n",
            "The bias c gradient is: \n",
            " [-0.02614067]\n",
            "\n",
            "RUN:\n",
            "  16\n",
            "The sum of the b update is\n",
            " [ 0.00825597 -0.00022986 -0.00899352]\n",
            "The b biases before the update are:\n",
            " [[-0.19278552 -0.69654898  0.02836918]]\n",
            "Updated bs are:\n",
            " [[-0.19286808 -0.69654669  0.02845912]]\n",
            "The W1 is: \n",
            " [[-0.71074579  0.36355774  0.9382399 ]\n",
            " [-2.59830839  1.11045556  0.9970997 ]\n",
            " [-1.40296302 -2.68941808 -1.02017916]]\n",
            "The W1 gradient is: \n",
            " [[-0.09662809 -0.15829328 -0.45750002]\n",
            " [-0.06445504 -0.24656501 -0.52845076]\n",
            " [ 0.27360502  0.4117132  -0.18680965]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.3123105 ]\n",
            " [-0.40295517]\n",
            " [-0.4779889 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00825597 -0.00022986 -0.00899352]\n",
            "The bias c gradient is: \n",
            " [-0.02591595]\n",
            "\n",
            "RUN:\n",
            "  17\n",
            "The sum of the b update is\n",
            " [ 0.00822956 -0.00025317 -0.00900184]\n",
            "The b biases before the update are:\n",
            " [[-0.19286808 -0.69654669  0.02845912]]\n",
            "Updated bs are:\n",
            " [[-0.19295037 -0.69654415  0.02854914]]\n",
            "The W1 is: \n",
            " [[-0.70977552  0.36512744  0.94276211]\n",
            " [-2.59765598  1.1129034   1.00232548]\n",
            " [-1.40570603 -2.69354248 -1.01837546]]\n",
            "The W1 gradient is: \n",
            " [[-0.09702697 -0.15697013 -0.45222131]\n",
            " [-0.06524087 -0.24478384 -0.52257836]\n",
            " [ 0.2743007   0.41244055 -0.18037072]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.30947843]\n",
            " [-0.3992747 ]\n",
            " [-0.47379207]]\n",
            "The biases b gradient is:\n",
            " [ 0.00822956 -0.00025317 -0.00900184]\n",
            "The bias c gradient is: \n",
            " [-0.02569409]\n",
            "\n",
            "RUN:\n",
            "  18\n",
            "The sum of the b update is\n",
            " [ 0.00820281 -0.00027571 -0.00900896]\n",
            "The b biases before the update are:\n",
            " [[-0.19295037 -0.69654415  0.02854914]]\n",
            "Updated bs are:\n",
            " [[-0.1930324  -0.6965414   0.02863923]]\n",
            "The W1 is: \n",
            " [[-0.70880135  0.36668418  0.9472321 ]\n",
            " [-2.59699582  1.11533372  1.00749315]\n",
            " [-1.4084559  -2.69767398 -1.01663561]]\n",
            "The W1 gradient is: \n",
            " [[-0.09741717 -0.15567458 -0.44699906]\n",
            " [-0.06601603 -0.24303221 -0.5167671 ]\n",
            " [ 0.27498685  0.41314958 -0.17398429]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.30671716]\n",
            " [-0.3956468 ]\n",
            " [-0.46957316]]\n",
            "The biases b gradient is:\n",
            " [ 0.00820281 -0.00027571 -0.00900896]\n",
            "The bias c gradient is: \n",
            " [-0.02547511]\n",
            "\n",
            "RUN:\n",
            "  19\n",
            "The sum of the b update is\n",
            " [ 0.00817573 -0.00029749 -0.00901499]\n",
            "The b biases before the update are:\n",
            " [[-0.1930324  -0.6965414   0.02863923]]\n",
            "Updated bs are:\n",
            " [[-0.19311416 -0.69653842  0.02872937]]\n",
            "The W1 is: \n",
            " [[-0.70782336  0.36822824  0.95165046]\n",
            " [-2.59632801  1.11774682  1.01260335]\n",
            " [-1.41121253 -2.70181239 -1.01495907]]\n",
            "The W1 gradient is: \n",
            " [[-0.09779886 -0.15440604 -0.44183597]\n",
            " [-0.06678063 -0.2413096  -0.51101977]\n",
            " [ 0.27566355  0.41384054 -0.1676548 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.30402463]\n",
            " [-0.39207107]\n",
            " [-0.46533595]]\n",
            "The biases b gradient is:\n",
            " [ 0.00817573 -0.00029749 -0.00901499]\n",
            "The bias c gradient is: \n",
            " [-0.02525903]\n",
            "\n",
            "RUN:\n",
            "  20\n",
            "The sum of the b update is\n",
            " [ 0.00814833 -0.00031854 -0.00902001]\n",
            "The b biases before the update are:\n",
            " [[-0.19311416 -0.69653842  0.02872937]]\n",
            "Updated bs are:\n",
            " [[-0.19319564 -0.69653524  0.02881958]]\n",
            "The W1 is: \n",
            " [[-0.70684163  0.36975988  0.95601781]\n",
            " [-2.59565266  1.12014297  1.01765674]\n",
            " [-1.41397584 -2.70595752 -1.0133452 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.09817221 -0.15316396 -0.43673441]\n",
            " [-0.06753477 -0.2396155  -0.50533881]\n",
            " [ 0.27633088  0.41451366 -0.16138625]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.30139886]\n",
            " [-0.38854706]\n",
            " [-0.46108404]]\n",
            "The biases b gradient is:\n",
            " [ 0.00814833 -0.00031854 -0.00902001]\n",
            "The bias c gradient is: \n",
            " [-0.02504586]\n",
            "\n",
            "RUN:\n",
            "  21\n",
            "The sum of the b update is\n",
            " [ 0.00812063 -0.00033887 -0.00902411]\n",
            "The b biases before the update are:\n",
            " [[-0.19319564 -0.69653524  0.02881958]]\n",
            "Updated bs are:\n",
            " [[-0.19327685 -0.69653185  0.02890982]]\n",
            "The W1 is: \n",
            " [[-0.70585626  0.37127936  0.96033477]\n",
            " [-2.59496988  1.12252247  1.022654  ]\n",
            " [-1.41674573 -2.71010921 -1.01179338]]\n",
            "The W1 gradient is: \n",
            " [[-0.09853736 -0.15194778 -0.43169645]\n",
            " [-0.06827854 -0.23794941 -0.49972636]\n",
            " [ 0.27698892  0.41516919 -0.15518219]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.29883793]\n",
            " [-0.38507433]\n",
            " [-0.45682088]]\n",
            "The biases b gradient is:\n",
            " [ 0.00812063 -0.00033887 -0.00902411]\n",
            "The bias c gradient is: \n",
            " [-0.02483559]\n",
            "\n",
            "RUN:\n",
            "  22\n",
            "The sum of the b update is\n",
            " [ 0.00809264 -0.0003585  -0.00902737]\n",
            "The b biases before the update are:\n",
            " [[-0.19327685 -0.69653185  0.02890982]]\n",
            "Updated bs are:\n",
            " [[-0.19335777 -0.69652826  0.02900009]]\n",
            "The W1 is: \n",
            " [[-0.70486732  0.37278693  0.96460201]\n",
            " [-2.59427976  1.12488558  1.02759584]\n",
            " [-1.41952211 -2.71426729 -1.01030292]]\n",
            "The W1 gradient is: \n",
            " [[-0.09889447 -0.15075695 -0.42672388]\n",
            " [-0.06901205 -0.23631082 -0.49418425]\n",
            " [ 0.27763775  0.41580736 -0.14904575]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.29633993]\n",
            " [-0.38165242]\n",
            " [-0.45254976]]\n",
            "The biases b gradient is:\n",
            " [ 0.00809264 -0.0003585  -0.00902737]\n",
            "The bias c gradient is: \n",
            " [-0.02462824]\n",
            "\n",
            "RUN:\n",
            "  23\n",
            "The sum of the b update is\n",
            " [ 0.00806437 -0.00037745 -0.00902987]\n",
            "The b biases before the update are:\n",
            " [[-0.19335777 -0.69652826  0.02900009]]\n",
            "Updated bs are:\n",
            " [[-0.19343842 -0.69652449  0.02909039]]\n",
            "The W1 is: \n",
            " [[-0.70387488  0.37428284  0.96882019]\n",
            " [-2.5935824   1.12723257  1.03248298]\n",
            " [-1.42230488 -2.71843157 -1.00887313]]\n",
            "The W1 gradient is: \n",
            " [[-0.09924368 -0.14959093 -0.4218182 ]\n",
            " [-0.0697354  -0.23469924 -0.48871402]\n",
            " [ 0.27827741  0.41642842 -0.14297968]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.29390303]\n",
            " [-0.37828084]\n",
            " [-0.44827381]]\n",
            "The biases b gradient is:\n",
            " [ 0.00806437 -0.00037745 -0.00902987]\n",
            "The bias c gradient is: \n",
            " [-0.0244238]\n",
            "\n",
            "RUN:\n",
            "  24\n",
            "The sum of the b update is\n",
            " [ 0.00803582 -0.00039575 -0.00903167]\n",
            "The b biases before the update are:\n",
            " [[-0.19343842 -0.69652449  0.02909039]]\n",
            "Updated bs are:\n",
            " [[-0.19351877 -0.69652053  0.02918071]]\n",
            "The W1 is: \n",
            " [[-0.70287903  0.37576733  0.97299   ]\n",
            " [-2.59287792  1.12956371  1.03731615]\n",
            " [-1.42509396 -2.7226019  -1.00750326]]\n",
            "The W1 gradient is: \n",
            " [[-0.09958513 -0.14844919 -0.41698069]\n",
            " [-0.07044867 -0.23311417 -0.48331698]\n",
            " [ 0.278908    0.41703262 -0.13698637]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.29152544]\n",
            " [-0.37495909]\n",
            " [-0.44399599]]\n",
            "The biases b gradient is:\n",
            " [ 0.00803582 -0.00039575 -0.00903167]\n",
            "The bias c gradient is: \n",
            " [-0.02422226]\n",
            "\n",
            "RUN:\n",
            "  25\n",
            "The sum of the b update is\n",
            " [ 0.00800701 -0.0004134  -0.00903285]\n",
            "The b biases before the update are:\n",
            " [[-0.19351877 -0.69652053  0.02918071]]\n",
            "Updated bs are:\n",
            " [[-0.19359884 -0.6965164   0.02927103]]\n",
            "The W1 is: \n",
            " [[-0.70187984  0.37724064  0.97711212]\n",
            " [-2.5921664   1.13187926  1.0420961 ]\n",
            " [-1.42788926 -2.7267781  -1.00619259]]\n",
            "The W1 gradient is: \n",
            " [[-0.09991897 -0.14733119 -0.41221239]\n",
            " [-0.07115197 -0.23155511 -0.47799418]\n",
            " [ 0.27952955  0.4176202  -0.13106785]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.28920542]\n",
            " [-0.37168668]\n",
            " [-0.43971913]]\n",
            "The biases b gradient is:\n",
            " [ 0.00800701 -0.0004134  -0.00903285]\n",
            "The bias c gradient is: \n",
            " [-0.02402362]\n",
            "\n",
            "RUN:\n",
            "  26\n",
            "The sum of the b update is\n",
            " [ 0.00797795 -0.00043043 -0.00903346]\n",
            "The b biases before the update are:\n",
            " [[-0.19359884 -0.6965164   0.02927103]]\n",
            "Updated bs are:\n",
            " [[-0.19367862 -0.69651209  0.02936137]]\n",
            "The W1 is: \n",
            " [[-0.70087739  0.37870301  0.98118726]\n",
            " [-2.59144794  1.13417948  1.04682356]\n",
            " [-1.43069068 -2.73096001 -1.00494033]]\n",
            "The W1 gradient is: \n",
            " [[-0.10024531 -0.14623642 -0.40751413]\n",
            " [-0.07184539 -0.23002159 -0.47274645]\n",
            " [ 0.28014213  0.41819142 -0.12522585]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.28694127]\n",
            " [-0.36846307]\n",
            " [-0.43544587]]\n",
            "The biases b gradient is:\n",
            " [ 0.00797795 -0.00043043 -0.00903346]\n",
            "The bias c gradient is: \n",
            " [-0.02382786]\n",
            "\n",
            "RUN:\n",
            "  27\n",
            "The sum of the b update is\n",
            " [ 0.00794864 -0.00044685 -0.00903355]\n",
            "The b biases before the update are:\n",
            " [[-0.19367862 -0.69651209  0.02936137]]\n",
            "Updated bs are:\n",
            " [[-0.19375811 -0.69650762  0.0294517 ]]\n",
            "The W1 is: \n",
            " [[-0.69987174  0.38015465  0.98521613]\n",
            " [-2.59072265  1.13646461  1.0514993 ]\n",
            " [-1.43349814 -2.73514748 -1.00374571]]\n",
            "The W1 gradient is: \n",
            " [[-0.10056428 -0.14516436 -0.40288653]\n",
            " [-0.07252902 -0.22851311 -0.46757441]\n",
            " [ 0.2807458   0.41874652 -0.11946182]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.28473135]\n",
            " [-0.36528775]\n",
            " [-0.43117874]]\n",
            "The biases b gradient is:\n",
            " [ 0.00794864 -0.00044685 -0.00903355]\n",
            "The bias c gradient is: \n",
            " [-0.02363497]\n",
            "\n",
            "RUN:\n",
            "  28\n",
            "The sum of the b update is\n",
            " [ 0.0079191  -0.00046268 -0.00903319]\n",
            "The b biases before the update are:\n",
            " [[-0.19375811 -0.69650762  0.0294517 ]]\n",
            "Updated bs are:\n",
            " [[-0.1938373  -0.696503    0.02954204]]\n",
            "The W1 is: \n",
            " [[-0.69886298  0.3815958   0.98919943]\n",
            " [-2.58999062  1.1387349   1.05612409]\n",
            " [-1.43631154 -2.73934034 -1.00260794]]\n",
            "The W1 gradient is: \n",
            " [[-0.10087602 -0.14411452 -0.39833004]\n",
            " [-0.07320294 -0.2270292  -0.4624785 ]\n",
            " [ 0.28134061  0.41928574 -0.11377693]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.28257406]\n",
            " [-0.36216017]\n",
            " [-0.42692009]]\n",
            "The biases b gradient is:\n",
            " [ 0.0079191  -0.00046268 -0.00903319]\n",
            "The bias c gradient is: \n",
            " [-0.02344493]\n",
            "\n",
            "RUN:\n",
            "  29\n",
            "The sum of the b update is\n",
            " [ 0.00788932 -0.00047793 -0.00903242]\n",
            "The b biases before the update are:\n",
            " [[-0.1938373  -0.696503    0.02954204]]\n",
            "Updated bs are:\n",
            " [[-0.19391619 -0.69649822  0.02963236]]\n",
            "The W1 is: \n",
            " [[-0.69785118  0.38302666  0.99313788]\n",
            " [-2.58925195  1.14099059  1.06069868]\n",
            " [-1.43913081 -2.74353843 -1.00152622]]\n",
            "The W1 gradient is: \n",
            " [[-0.10118063 -0.14308639 -0.39384495]\n",
            " [-0.07386725 -0.22556939 -0.45745897]\n",
            " [ 0.2819266   0.41980934 -0.1081721 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.28046786]\n",
            " [-0.35907978]\n",
            " [-0.42267216]]\n",
            "The biases b gradient is:\n",
            " [ 0.00788932 -0.00047793 -0.00903242]\n",
            "The bias c gradient is: \n",
            " [-0.02325772]\n",
            "\n",
            "RUN:\n",
            "  30\n",
            "The sum of the b update is\n",
            " [ 0.00785933 -0.00049262 -0.00903127]\n",
            "The b biases before the update are:\n",
            " [[-0.19391619 -0.69649822  0.02963236]]\n",
            "Updated bs are:\n",
            " [[-0.19399479 -0.69649329  0.02972267]]\n",
            "The W1 is: \n",
            " [[-0.69683639  0.38444746  0.99703219]\n",
            " [-2.58850673  1.14323193  1.06522384]\n",
            " [-1.44195585 -2.74774161 -1.00049974]]\n",
            "The W1 gradient is: \n",
            " [[-0.10147823 -0.1420795  -0.38943136]\n",
            " [-0.07452203 -0.22413321 -0.45251594]\n",
            " [ 0.28250381  0.42031755 -0.10264803]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.27841124]\n",
            " [-0.35604603]\n",
            " [-0.41843705]]\n",
            "The biases b gradient is:\n",
            " [ 0.00785933 -0.00049262 -0.00903127]\n",
            "The bias c gradient is: \n",
            " [-0.02307332]\n",
            "\n",
            "RUN:\n",
            "  31\n",
            "The sum of the b update is\n",
            " [ 0.00782912 -0.00050677 -0.00902981]\n",
            "The b biases before the update are:\n",
            " [[-0.19399479 -0.69649329  0.02972267]]\n",
            "Updated bs are:\n",
            " [[-0.19407308 -0.69648822  0.02981297]]\n",
            "The W1 is: \n",
            " [[-0.6958187   0.38585839  1.00088309]\n",
            " [-2.58775506  1.14545913  1.06970033]\n",
            " [-1.44478657 -2.75194971 -0.99952769]]\n",
            "The W1 gradient is: \n",
            " [[-0.10176893 -0.14109337 -0.38508929]\n",
            " [-0.07516737 -0.22272022 -0.44764937]\n",
            " [ 0.2830723   0.42081062 -0.09720521]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.27640274]\n",
            " [-0.35305836]\n",
            " [-0.4142167 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00782912 -0.00050677 -0.00902981]\n",
            "The bias c gradient is: \n",
            " [-0.02289171]\n",
            "\n",
            "RUN:\n",
            "  32\n",
            "The sum of the b update is\n",
            " [ 0.0077987  -0.00052038 -0.00902805]\n",
            "The b biases before the update are:\n",
            " [[-0.19407308 -0.69648822  0.02981297]]\n",
            "Updated bs are:\n",
            " [[-0.19415107 -0.69648302  0.02990325]]\n",
            "The W1 is: \n",
            " [[-0.69479818  0.38725966  1.00469127]\n",
            " [-2.58699702  1.14767243  1.07412892]\n",
            " [-1.44762289 -2.7561626  -0.99860925]]\n",
            "The W1 gradient is: \n",
            " [[-0.10205284 -0.14012753 -0.38081858]\n",
            " [-0.07580334 -0.22132995 -0.44285907]\n",
            " [ 0.28363211  0.42128879 -0.09184394]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.27444094]\n",
            " [-0.35011619]\n",
            " [-0.41001295]]\n",
            "The biases b gradient is:\n",
            " [ 0.0077987  -0.00052038 -0.00902805]\n",
            "The bias c gradient is: \n",
            " [-0.02271286]\n",
            "\n",
            "RUN:\n",
            "  33\n",
            "The sum of the b update is\n",
            " [ 0.00776808 -0.00053348 -0.00902604]\n",
            "The b biases before the update are:\n",
            " [[-0.19415107 -0.69648302  0.02990325]]\n",
            "Updated bs are:\n",
            " [[-0.19422875 -0.69647769  0.02999351]]\n",
            "The W1 is: \n",
            " [[-0.69377488  0.38865148  1.00845746]\n",
            " [-2.58623272  1.14987205  1.07851037]\n",
            " [-1.45046473 -2.76038012 -0.9977436 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10233004 -0.13918153 -0.37661899]\n",
            " [-0.07643003 -0.21996197 -0.43814476]\n",
            " [ 0.28418326  0.42175229 -0.08656434]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.27252449]\n",
            " [-0.34721897]\n",
            " [-0.40582752]]\n",
            "The biases b gradient is:\n",
            " [ 0.00776808 -0.00053348 -0.00902604]\n",
            "The bias c gradient is: \n",
            " [-0.02253675]\n",
            "\n",
            "RUN:\n",
            "  34\n",
            "The sum of the b update is\n",
            " [ 0.00773726 -0.00054608 -0.00902381]\n",
            "The b biases before the update are:\n",
            " [[-0.19422875 -0.69647769  0.02999351]]\n",
            "Updated bs are:\n",
            " [[-0.19430612 -0.69647223  0.03008375]]\n",
            "The W1 is: \n",
            " [[-0.69274887  0.39003403  1.01218236]\n",
            " [-2.58546225  1.15205821  1.08284543]\n",
            " [-1.45331198 -2.76460214 -0.99692994]]\n",
            "The W1 gradient is: \n",
            " [[-0.10260065 -0.13825491 -0.37249016]\n",
            " [-0.07704751 -0.21861584 -0.43350605]\n",
            " [ 0.28472579  0.42220136 -0.08136637]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.27065206]\n",
            " [-0.3443661 ]\n",
            " [-0.401662  ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00773726 -0.00054608 -0.00902381]\n",
            "The bias c gradient is: \n",
            " [-0.02236335]\n",
            "\n",
            "RUN:\n",
            "  35\n",
            "The sum of the b update is\n",
            " [ 0.00770625 -0.00055819 -0.00902139]\n",
            "The b biases before the update are:\n",
            " [[-0.19430612 -0.69647223  0.03008375]]\n",
            "Updated bs are:\n",
            " [[-0.19438318 -0.69646664  0.03017396]]\n",
            "The W1 is: \n",
            " [[-0.69172022  0.3914075   1.01586668]\n",
            " [-2.58468569  1.15423112  1.08713486]\n",
            " [-1.45616458 -2.7688285  -0.99616744]]\n",
            "The W1 gradient is: \n",
            " [[-0.10286475 -0.13734726 -0.36843164]\n",
            " [-0.07765586 -0.21729114 -0.42894243]\n",
            " [ 0.28525974  0.42263624 -0.07624988]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.26882236]\n",
            " [-0.34155702]\n",
            " [-0.39751788]]\n",
            "The biases b gradient is:\n",
            " [ 0.00770625 -0.00055819 -0.00902139]\n",
            "The bias c gradient is: \n",
            " [-0.02219264]\n",
            "\n",
            "RUN:\n",
            "  36\n",
            "The sum of the b update is\n",
            " [ 0.00767505 -0.00056982 -0.00901881]\n",
            "The b biases before the update are:\n",
            " [[-0.19438318 -0.69646664  0.03017396]]\n",
            "Updated bs are:\n",
            " [[-0.19445993 -0.69646095  0.03026415]]\n",
            "The W1 is: \n",
            " [[-0.690689    0.39277208  1.01951111]\n",
            " [-2.58390314  1.15639099  1.09137939]\n",
            " [-1.45902243 -2.77305907 -0.9954553 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10312244 -0.13645812 -0.36444289]\n",
            " [-0.07825515 -0.21598744 -0.42445332]\n",
            " [ 0.28578514  0.42305715 -0.07121455]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.26703414]\n",
            " [-0.33879114]\n",
            " [-0.39339654]]\n",
            "The biases b gradient is:\n",
            " [ 0.00767505 -0.00056982 -0.00901881]\n",
            "The bias c gradient is: \n",
            " [-0.02202457]\n",
            "\n",
            "RUN:\n",
            "  37\n",
            "The sum of the b update is\n",
            " [ 0.00764367 -0.00058098 -0.00901608]\n",
            "The b biases before the update are:\n",
            " [[-0.19445993 -0.69646095  0.03026415]]\n",
            "Updated bs are:\n",
            " [[-0.19453637 -0.69645514  0.03035431]]\n",
            "The W1 is: \n",
            " [[-0.68965526  0.39412795  1.02311634]\n",
            " [-2.58311468  1.15853803  1.09557977]\n",
            " [-1.46188545 -2.77729371 -0.9947927 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10337379 -0.1355871  -0.36052331]\n",
            " [-0.07884545 -0.21470433 -0.42003808]\n",
            " [ 0.28630202  0.42346432 -0.06625996]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.26528621]\n",
            " [-0.33606788]\n",
            " [-0.38929925]]\n",
            "The biases b gradient is:\n",
            " [ 0.00764367 -0.00058098 -0.00901608]\n",
            "The bias c gradient is: \n",
            " [-0.02185912]\n",
            "\n",
            "RUN:\n",
            "  38\n",
            "The sum of the b update is\n",
            " [ 0.00761211 -0.0005917  -0.00901324]\n",
            "The b biases before the update are:\n",
            " [[-0.19453637 -0.69645514  0.03035431]]\n",
            "Updated bs are:\n",
            " [[-0.19461249 -0.69644922  0.03044445]]\n",
            "The W1 is: \n",
            " [[-0.68861907  0.39547529  1.02668306]\n",
            " [-2.58232041  1.16067245  1.09973673]\n",
            " [-1.46475356 -2.78153229 -0.99417884]]\n",
            "The W1 gradient is: \n",
            " [[-0.1036189  -0.13473378 -0.35667223]\n",
            " [-0.07942684 -0.21344141 -0.41569596]\n",
            " [ 0.2868104   0.42385797 -0.0613856 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.26357739]\n",
            " [-0.33338665]\n",
            " [-0.38522718]]\n",
            "The biases b gradient is:\n",
            " [ 0.00761211 -0.0005917  -0.00901324]\n",
            "The bias c gradient is: \n",
            " [-0.02169627]\n",
            "\n",
            "RUN:\n",
            "  39\n",
            "The sum of the b update is\n",
            " [ 0.00758037 -0.00060197 -0.00901031]\n",
            "The b biases before the update are:\n",
            " [[-0.19461249 -0.69644922  0.03044445]]\n",
            "Updated bs are:\n",
            " [[-0.19468829 -0.6964432   0.03053455]]\n",
            "The W1 is: \n",
            " [[-0.68758049  0.39681427  1.03021195]\n",
            " [-2.58152042  1.16279443  1.10385099]\n",
            " [-1.46762666 -2.78577468 -0.99361293]]\n",
            "The W1 gradient is: \n",
            " [[-0.10385783 -0.13389775 -0.3528889 ]\n",
            " [-0.07999937 -0.21219829 -0.4114262 ]\n",
            " [ 0.28731031  0.42423832 -0.05659086]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.26190657]\n",
            " [-0.33074688]\n",
            " [-0.38118144]]\n",
            "The biases b gradient is:\n",
            " [ 0.00758037 -0.00060197 -0.00901031]\n",
            "The bias c gradient is: \n",
            " [-0.02153597]\n",
            "\n",
            "RUN:\n",
            "  40\n",
            "The sum of the b update is\n",
            " [ 0.00754846 -0.00061181 -0.0090073 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19468829 -0.6964432   0.03053455]]\n",
            "Updated bs are:\n",
            " [[-0.19476378 -0.69643708  0.03062462]]\n",
            "The W1 is: \n",
            " [[-0.68653959  0.39814506  1.03370368]\n",
            " [-2.58071479  1.16490418  1.10792327]\n",
            " [-1.47050468 -2.79002073 -0.99309418]]\n",
            "The W1 gradient is: \n",
            " [[-0.10409067 -0.13307864 -0.34917256]\n",
            " [-0.08056313 -0.21097457 -0.40722794]\n",
            " [ 0.28780176  0.42460559 -0.05187503]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.26027266]\n",
            " [-0.32814797]\n",
            " [-0.377163  ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00754846 -0.00061181 -0.0090073 ]\n",
            "The bias c gradient is: \n",
            " [-0.0213782]\n",
            "\n",
            "RUN:\n",
            "  41\n",
            "The sum of the b update is\n",
            " [ 0.00751639 -0.00062124 -0.00900423]\n",
            "The b biases before the update are:\n",
            " [[-0.19476378 -0.69643708  0.03062462]]\n",
            "Updated bs are:\n",
            " [[-0.19483894 -0.69643087  0.03071466]]\n",
            "The W1 is: \n",
            " [[-0.68549641  0.39946782  1.0371589 ]\n",
            " [-2.57990361  1.16700188  1.11195427]\n",
            " [-1.47338753 -2.79427033 -0.99262181]]\n",
            "The W1 gradient is: \n",
            " [[-0.10431748 -0.13227605 -0.34552236]\n",
            " [-0.08111816 -0.20976987 -0.40310031]\n",
            " [ 0.28828479  0.42496    -0.04723735]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.25867459]\n",
            " [-0.32558935]\n",
            " [-0.3731728 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00751639 -0.00062124 -0.00900423]\n",
            "The bias c gradient is: \n",
            " [-0.02122292]\n",
            "\n",
            "RUN:\n",
            "  42\n",
            "The sum of the b update is\n",
            " [ 0.00748415 -0.00063025 -0.00900112]\n",
            "The b biases before the update are:\n",
            " [[-0.19483894 -0.69643087  0.03071466]]\n",
            "Updated bs are:\n",
            " [[-0.19491378 -0.69642457  0.03080467]]\n",
            "The W1 is: \n",
            " [[-0.68445103  0.40078271  1.04057828]\n",
            " [-2.57908696  1.16908771  1.1159447 ]\n",
            " [-1.47627512 -2.79852335 -0.99219504]]\n",
            "The W1 gradient is: \n",
            " [[-0.10453834 -0.13148963 -0.34193744]\n",
            " [-0.08166454 -0.20858382 -0.39904238]\n",
            " [ 0.28875941  0.42530174 -0.04267699]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.25711134]\n",
            " [-0.32307044]\n",
            " [-0.36921167]]\n",
            "The biases b gradient is:\n",
            " [ 0.00748415 -0.00063025 -0.00900112]\n",
            "The bias c gradient is: \n",
            " [-0.0210701]\n",
            "\n",
            "RUN:\n",
            "  43\n",
            "The sum of the b update is\n",
            " [ 0.00745175 -0.00063887 -0.00899798]\n",
            "The b biases before the update are:\n",
            " [[-0.19491378 -0.69642457  0.03080467]]\n",
            "Updated bs are:\n",
            " [[-0.1949883  -0.69641818  0.03089465]]\n",
            "The W1 is: \n",
            " [[-0.68340349  0.4020899   1.04396245]\n",
            " [-2.57826494  1.17116187  1.11989523]\n",
            " [-1.47916738 -2.80277966 -0.99181311]]\n",
            "The W1 gradient is: \n",
            " [[-0.10475331 -0.130719   -0.33841691]\n",
            " [-0.08220232 -0.20741605 -0.39505319]\n",
            " [ 0.28922563  0.42563104 -0.03819306]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.25558194]\n",
            " [-0.32059065]\n",
            " [-0.36528036]]\n",
            "The biases b gradient is:\n",
            " [ 0.00745175 -0.00063887 -0.00899798]\n",
            "The bias c gradient is: \n",
            " [-0.02091971]\n",
            "\n",
            "RUN:\n",
            "  44\n",
            "The sum of the b update is\n",
            " [ 0.00741919 -0.0006471  -0.00899483]\n",
            "The b biases before the update are:\n",
            " [[-0.1949883  -0.69641818  0.03089465]]\n",
            "Updated bs are:\n",
            " [[-0.19506249 -0.69641171  0.0309846 ]]\n",
            "The W1 is: \n",
            " [[-0.68235387  0.40338954  1.04731204]\n",
            " [-2.57743762  1.17322454  1.12380655]\n",
            " [-1.48206421 -2.80703914 -0.99147526]]\n",
            "The W1 gradient is: \n",
            " [[-0.10496245 -0.12996381 -0.33495982]\n",
            " [-0.08273156 -0.20626621 -0.39113177]\n",
            " [ 0.28968348  0.42594808 -0.03378463]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.25408542]\n",
            " [-0.31814941]\n",
            " [-0.36137957]]\n",
            "The biases b gradient is:\n",
            " [ 0.00741919 -0.0006471  -0.00899483]\n",
            "The bias c gradient is: \n",
            " [-0.02077171]\n",
            "\n",
            "RUN:\n",
            "  45\n",
            "The sum of the b update is\n",
            " [ 0.00738647 -0.00065495 -0.00899168]\n",
            "The b biases before the update are:\n",
            " [[-0.19506249 -0.69641171  0.0309846 ]]\n",
            "Updated bs are:\n",
            " [[-0.19513636 -0.69640516  0.03107452]]\n",
            "The W1 is: \n",
            " [[-0.68130221  0.40468178  1.0506277 ]\n",
            " [-2.5766051   1.17527588  1.12767932]\n",
            " [-1.48496554 -2.81130167 -0.99118075]]\n",
            "The W1 gradient is: \n",
            " [[-0.10516583 -0.12922371 -0.33156525]\n",
            " [-0.08325232 -0.20513395 -0.3872771 ]\n",
            " [ 0.29013297  0.42625308 -0.02945073]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.25262086]\n",
            " [-0.31574615]\n",
            " [-0.35750992]]\n",
            "The biases b gradient is:\n",
            " [ 0.00738647 -0.00065495 -0.00899168]\n",
            "The bias c gradient is: \n",
            " [-0.02062607]\n",
            "\n",
            "RUN:\n",
            "  46\n",
            "The sum of the b update is\n",
            " [ 0.0073536  -0.00066244 -0.00898853]\n",
            "The b biases before the update are:\n",
            " [[-0.19513636 -0.69640516  0.03107452]]\n",
            "Updated bs are:\n",
            " [[-0.19520989 -0.69639853  0.0311644 ]]\n",
            "The W1 is: \n",
            " [[-0.68024858  0.40596676  1.05391002]\n",
            " [-2.57576745  1.17731607  1.1315142 ]\n",
            " [-1.48787128 -2.81556713 -0.99092885]]\n",
            "The W1 gradient is: \n",
            " [[-0.1053635  -0.12849838 -0.3282322 ]\n",
            " [-0.08376466 -0.20401892 -0.38348815]\n",
            " [ 0.29057411  0.42654623 -0.02519034]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.25118737]\n",
            " [-0.3133803 ]\n",
            " [-0.35367197]]\n",
            "The biases b gradient is:\n",
            " [ 0.0073536  -0.00066244 -0.00898853]\n",
            "The bias c gradient is: \n",
            " [-0.02048276]\n",
            "\n",
            "RUN:\n",
            "  47\n",
            "The sum of the b update is\n",
            " [ 0.00732058 -0.00066956 -0.0089854 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19520989 -0.69639853  0.0311644 ]]\n",
            "Updated bs are:\n",
            " [[-0.1952831  -0.69639184  0.03125426]]\n",
            "The W1 is: \n",
            " [[-0.67919302  0.40724464  1.05715962]\n",
            " [-2.57492477  1.17934527  1.13531184]\n",
            " [-1.49078135 -2.81983541 -0.99071883]]\n",
            "The W1 gradient is: \n",
            " [[-0.10555551 -0.12778747 -0.3249597 ]\n",
            " [-0.08426862 -0.2029208  -0.37976389]\n",
            " [ 0.29100691  0.42682772 -0.02100243]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.24978409]\n",
            " [-0.31105128]\n",
            " [-0.34986621]]\n",
            "The biases b gradient is:\n",
            " [ 0.00732058 -0.00066956 -0.0089854 ]\n",
            "The bias c gradient is: \n",
            " [-0.02034173]\n",
            "\n",
            "RUN:\n",
            "  48\n",
            "The sum of the b update is\n",
            " [ 0.0072874  -0.00067633 -0.0089823 ]\n",
            "The b biases before the update are:\n",
            " [[-0.1952831  -0.69639184  0.03125426]]\n",
            "Updated bs are:\n",
            " [[-0.19535597 -0.69638507  0.03134408]]\n",
            "The W1 is: \n",
            " [[-0.6781356   0.40851554  1.06037708]\n",
            " [-2.57407713  1.18136367  1.13907287]\n",
            " [-1.49369566 -2.82410639 -0.99054997]]\n",
            "The W1 gradient is: \n",
            " [[-0.10574193 -0.12709068 -0.32174675]\n",
            " [-0.08476427 -0.20183924 -0.37610326]\n",
            " [ 0.29143138  0.42709773 -0.01688593]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.24841017]\n",
            " [-0.30875854]\n",
            " [-0.3460931 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.0072874  -0.00067633 -0.0089823 ]\n",
            "The bias c gradient is: \n",
            " [-0.02020297]\n",
            "\n",
            "RUN:\n",
            "  49\n",
            "The sum of the b update is\n",
            " [ 0.00725408 -0.00068276 -0.00897923]\n",
            "The b biases before the update are:\n",
            " [[-0.19535597 -0.69638507  0.03134408]]\n",
            "Updated bs are:\n",
            " [[-0.19542851 -0.69637825  0.03143387]]\n",
            "The W1 is: \n",
            " [[-0.67707637  0.40977962  1.06356301]\n",
            " [-2.57322461  1.18337141  1.14279792]\n",
            " [-1.49661414 -2.82837995 -0.99042157]]\n",
            "The W1 gradient is: \n",
            " [[-0.1059228  -0.12640768 -0.31859234]\n",
            " [-0.08525165 -0.20077393 -0.37250519]\n",
            " [ 0.29184754  0.42735646 -0.01283976]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.24706481]\n",
            " [-0.30650152]\n",
            " [-0.34235302]]\n",
            "The biases b gradient is:\n",
            " [ 0.00725408 -0.00068276 -0.00897923]\n",
            "The bias c gradient is: \n",
            " [-0.02006643]\n",
            "\n",
            "RUN:\n",
            "  50\n",
            "The sum of the b update is\n",
            " [ 0.0072206  -0.00068886 -0.00897621]\n",
            "The b biases before the update are:\n",
            " [[-0.19542851 -0.69637825  0.03143387]]\n",
            "Updated bs are:\n",
            " [[-0.19550072 -0.69637136  0.03152364]]\n",
            "The W1 is: \n",
            " [[-0.67601539  0.411037    1.06671796]\n",
            " [-2.5723673   1.18536865  1.14648761]\n",
            " [-1.49953669 -2.83265599 -0.99033294]]\n",
            "The W1 gradient is: \n",
            " [[-0.10609817 -0.12573818 -0.31549547]\n",
            " [-0.08573082 -0.19972455 -0.36896863]\n",
            " [ 0.29225539  0.42760409 -0.00886283]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.24574723]\n",
            " [-0.30427967]\n",
            " [-0.33864631]]\n",
            "The biases b gradient is:\n",
            " [ 0.0072206  -0.00068886 -0.00897621]\n",
            "The bias c gradient is: \n",
            " [-0.01993207]\n",
            "\n",
            "RUN:\n",
            "  51\n",
            "The sum of the b update is\n",
            " [ 0.00718698 -0.00069462 -0.00897324]\n",
            "The b biases before the update are:\n",
            " [[-0.19550072 -0.69637136  0.03152364]]\n",
            "Updated bs are:\n",
            " [[-0.19557259 -0.69636441  0.03161337]]\n",
            "The W1 is: \n",
            " [[-0.67495271  0.41228782  1.06984251]\n",
            " [-2.57150528  1.18735556  1.15014253]\n",
            " [-1.50246324 -2.8369344  -0.9902834 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10626808 -0.12508187 -0.31245512]\n",
            " [-0.08620181 -0.1986908  -0.3654925 ]\n",
            " [ 0.29265494  0.4278408  -0.00495403]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.24445667]\n",
            " [-0.30209243]\n",
            " [-0.33497327]]\n",
            "The biases b gradient is:\n",
            " [ 0.00718698 -0.00069462 -0.00897324]\n",
            "The bias c gradient is: \n",
            " [-0.01979988]\n",
            "\n",
            "RUN:\n",
            "  52\n",
            "The sum of the b update is\n",
            " [ 0.00715321 -0.00070007 -0.00897032]\n",
            "The b biases before the update are:\n",
            " [[-0.19557259 -0.69636441  0.03161337]]\n",
            "Updated bs are:\n",
            " [[-0.19564412 -0.69635741  0.03170307]]\n",
            "The W1 is: \n",
            " [[-0.67388839  0.4135322   1.07293722]\n",
            " [-2.57063864  1.18933228  1.15376329]\n",
            " [-1.5053937  -2.84121507 -0.99027228]]\n",
            "The W1 gradient is: \n",
            " [[-0.10643259 -0.12443847 -0.30947028]\n",
            " [-0.08666469 -0.19767238 -0.36207573]\n",
            " [ 0.2930462   0.42806676 -0.00111224]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.24319239]\n",
            " [-0.29993925]\n",
            " [-0.33133414]]\n",
            "The biases b gradient is:\n",
            " [ 0.00715321 -0.00070007 -0.00897032]\n",
            "The bias c gradient is: \n",
            " [-0.01966981]\n",
            "\n",
            "RUN:\n",
            "  53\n",
            "The sum of the b update is\n",
            " [ 0.0071193  -0.0007052  -0.00896746]\n",
            "The b biases before the update are:\n",
            " [[-0.19564412 -0.69635741  0.03170307]]\n",
            "Updated bs are:\n",
            " [[-0.19571532 -0.69635036  0.03179275]]\n",
            "The W1 is: \n",
            " [[-0.67282247  0.41477028  1.07600262]\n",
            " [-2.56976744  1.19129897  1.15735046]\n",
            " [-1.508328   -2.84549789 -0.99029891]]\n",
            "The W1 gradient is: \n",
            " [[-0.10659173 -0.12380769 -0.30653994]\n",
            " [-0.08711949 -0.196669   -0.35871726]\n",
            " [ 0.29342917  0.42828214  0.00266366]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2419537 ]\n",
            " [-0.29781962]\n",
            " [-0.32772913]]\n",
            "The biases b gradient is:\n",
            " [ 0.0071193  -0.0007052  -0.00896746]\n",
            "The bias c gradient is: \n",
            " [-0.01954182]\n",
            "\n",
            "RUN:\n",
            "  54\n",
            "The sum of the b update is\n",
            " [ 0.00708524 -0.00071003 -0.00896466]\n",
            "The b biases before the update are:\n",
            " [[-0.19571532 -0.69635036  0.03179275]]\n",
            "Updated bs are:\n",
            " [[-0.19578617 -0.69634326  0.03188239]]\n",
            "The W1 is: \n",
            " [[-0.67175501  0.41600217  1.07903925]\n",
            " [-2.56889178  1.19325578  1.16090462]\n",
            " [-1.51126604 -2.84978276 -0.99036266]]\n",
            "The W1 gradient is: \n",
            " [[-0.10674555 -0.12318926 -0.30366308]\n",
            " [-0.08756626 -0.19568036 -0.35541603]\n",
            " [ 0.29380385  0.42848712  0.00637479]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.24073989]\n",
            " [-0.29573298]\n",
            " [-0.3241584 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00708524 -0.00071003 -0.00896466]\n",
            "The bias c gradient is: \n",
            " [-0.0194159]\n",
            "\n",
            "RUN:\n",
            "  55\n",
            "The sum of the b update is\n",
            " [ 0.00705104 -0.00071457 -0.00896194]\n",
            "The b biases before the update are:\n",
            " [[-0.19578617 -0.69634326  0.03188239]]\n",
            "Updated bs are:\n",
            " [[-0.19585668 -0.69633611  0.03197201]]\n",
            "The W1 is: \n",
            " [[-0.67068607  0.417228    1.08204763]\n",
            " [-2.56801173  1.19520284  1.16442633]\n",
            " [-1.51420774 -2.85406958 -0.99046288]]\n",
            "The W1 gradient is: \n",
            " [[-0.10689407 -0.1225829  -0.30083871]\n",
            " [-0.08800505 -0.19470619 -0.35217098]\n",
            " [ 0.29417026  0.42868186  0.01002226]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2395503 ]\n",
            " [-0.29367881]\n",
            " [-0.3206221 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00705104 -0.00071457 -0.00896194]\n",
            "The bias c gradient is: \n",
            " [-0.019292]\n",
            "\n",
            "RUN:\n",
            "  56\n",
            "The sum of the b update is\n",
            " [ 0.0070167  -0.00071881 -0.00895928]\n",
            "The b biases before the update are:\n",
            " [[-0.19585668 -0.69633611  0.03197201]]\n",
            "Updated bs are:\n",
            " [[-0.19592685 -0.69632892  0.03206161]]\n",
            "The W1 is: \n",
            " [[-0.6696157   0.41844789  1.08502829]\n",
            " [-2.56712737  1.1971403   1.16791614]\n",
            " [-1.51715302 -2.85835825 -0.99059896]]\n",
            "The W1 gradient is: \n",
            " [[-0.10703735 -0.12198837 -0.29806583]\n",
            " [-0.08843589 -0.1937462  -0.34898106]\n",
            " [ 0.29452839  0.42886652  0.01360719]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2383843 ]\n",
            " [-0.29165659]\n",
            " [-0.31712031]]\n",
            "The biases b gradient is:\n",
            " [ 0.0070167  -0.00071881 -0.00895928]\n",
            "The bias c gradient is: \n",
            " [-0.01917009]\n",
            "\n",
            "RUN:\n",
            "  57\n",
            "The sum of the b update is\n",
            " [ 0.00698222 -0.00072276 -0.00895671]\n",
            "The b biases before the update are:\n",
            " [[-0.19592685 -0.69632892  0.03206161]]\n",
            "Updated bs are:\n",
            " [[-0.19599667 -0.6963217   0.03215117]]\n",
            "The W1 is: \n",
            " [[-0.66854394  0.41966194  1.08798173]\n",
            " [-2.56623878  1.1990683   1.1713746 ]\n",
            " [-1.5201018  -2.86264866 -0.99077026]]\n",
            "The W1 gradient is: \n",
            " [[-0.10717542 -0.1214054  -0.29534346]\n",
            " [-0.08885884 -0.19280014 -0.34584524]\n",
            " [ 0.29487824  0.42904127  0.0171307 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.23724126]\n",
            " [-0.28966581]\n",
            " [-0.31365311]]\n",
            "The biases b gradient is:\n",
            " [ 0.00698222 -0.00072276 -0.00895671]\n",
            "The bias c gradient is: \n",
            " [-0.01905014]\n",
            "\n",
            "RUN:\n",
            "  58\n",
            "The sum of the b update is\n",
            " [ 0.00694759 -0.00072644 -0.00895421]\n",
            "The b biases before the update are:\n",
            " [[-0.19599667 -0.6963217   0.03215117]]\n",
            "Updated bs are:\n",
            " [[-0.19606614 -0.69631443  0.03224071]]\n",
            "The W1 is: \n",
            " [[-0.66747086  0.42087028  1.09090843]\n",
            " [-2.56534604  1.20098698  1.17480222]\n",
            " [-1.523054   -2.86694072 -0.9909762 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10730831 -0.12083373 -0.2926706 ]\n",
            " [-0.08927393 -0.19186774 -0.34276248]\n",
            " [ 0.29521983  0.42920626  0.02059388]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.23612057]\n",
            " [-0.28770595]\n",
            " [-0.31022052]]\n",
            "The biases b gradient is:\n",
            " [ 0.00694759 -0.00072644 -0.00895421]\n",
            "The bias c gradient is: \n",
            " [-0.01893212]\n",
            "\n",
            "RUN:\n",
            "  59\n",
            "The sum of the b update is\n",
            " [ 0.00691282 -0.00072984 -0.00895179]\n",
            "The b biases before the update are:\n",
            " [[-0.19606614 -0.69631443  0.03224071]]\n",
            "Updated bs are:\n",
            " [[-0.19613527 -0.69630713  0.03233023]]\n",
            "The W1 is: \n",
            " [[-0.6663965   0.42207301  1.0938089 ]\n",
            " [-2.56444923  1.20289647  1.17819954]\n",
            " [-1.52600953 -2.87123434 -0.99121618]]\n",
            "The W1 gradient is: \n",
            " [[-0.10743605 -0.12027314 -0.29004631]\n",
            " [-0.0896812  -0.19094874 -0.33973177]\n",
            " [ 0.29555314  0.42936164  0.02399784]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.23502165]\n",
            " [-0.2857765 ]\n",
            " [-0.30682256]]\n",
            "The biases b gradient is:\n",
            " [ 0.00691282 -0.00072984 -0.00895179]\n",
            "The bias c gradient is: \n",
            " [-0.01881599]\n",
            "\n",
            "RUN:\n",
            "  60\n",
            "The sum of the b update is\n",
            " [ 0.00687791 -0.00073298 -0.00894946]\n",
            "The b biases before the update are:\n",
            " [[-0.19613527 -0.69630713  0.03233023]]\n",
            "Updated bs are:\n",
            " [[-0.19620405 -0.6962998   0.03241973]]\n",
            "The W1 is: \n",
            " [[-0.66532091  0.42327024  1.09668359]\n",
            " [-2.56354842  1.2047969   1.18156706]\n",
            " [-1.52896832 -2.87552941 -0.99148962]]\n",
            "The W1 gradient is: \n",
            " [[-0.10755869 -0.11972339 -0.28746961]\n",
            " [-0.09008069 -0.1900429  -0.33675209]\n",
            " [ 0.29587819  0.42950756  0.02734364]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.23394393]\n",
            " [-0.28387698]\n",
            " [-0.30345921]]\n",
            "The biases b gradient is:\n",
            " [ 0.00687791 -0.00073298 -0.00894946]\n",
            "The bias c gradient is: \n",
            " [-0.01870174]\n",
            "\n",
            "RUN:\n",
            "  61\n",
            "The sum of the b update is\n",
            " [ 0.00684285 -0.00073586 -0.00894721]\n",
            "The b biases before the update are:\n",
            " [[-0.19620405 -0.6962998   0.03241973]]\n",
            "Updated bs are:\n",
            " [[-0.19627248 -0.69629245  0.0325092 ]]\n",
            "The W1 is: \n",
            " [[-0.66424415  0.42446209  1.09953299]\n",
            " [-2.5626437   1.20668839  1.18490528]\n",
            " [-1.53193027 -2.87982586 -0.99179594]]\n",
            "The W1 gradient is: \n",
            " [[-0.10767624 -0.11918424 -0.28493957]\n",
            " [-0.09047244 -0.18914995 -0.33382247]\n",
            " [ 0.29619496  0.42964418  0.03063238]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.23288687]\n",
            " [-0.2820069 ]\n",
            " [-0.30013043]]\n",
            "The biases b gradient is:\n",
            " [ 0.00684285 -0.00073586 -0.00894721]\n",
            "The bias c gradient is: \n",
            " [-0.01858931]\n",
            "\n",
            "RUN:\n",
            "  62\n",
            "The sum of the b update is\n",
            " [ 0.00680766 -0.00073848 -0.00894504]\n",
            "The b biases before the update are:\n",
            " [[-0.19627248 -0.69629245  0.0325092 ]]\n",
            "Updated bs are:\n",
            " [[-0.19634056 -0.69628506  0.03259865]]\n",
            "The W1 is: \n",
            " [[-0.66316626  0.42564864  1.10235754]\n",
            " [-2.56173513  1.20857109  1.1882147 ]\n",
            " [-1.5348953  -2.88412357 -0.99213459]]\n",
            "The W1 gradient is: \n",
            " [[-0.10778874 -0.11865546 -0.28245525]\n",
            " [-0.09085649 -0.18826968 -0.33094192]\n",
            " [ 0.29650348  0.42977164  0.03386509]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.23184992]\n",
            " [-0.28016575]\n",
            " [-0.29683614]]\n",
            "The biases b gradient is:\n",
            " [ 0.00680766 -0.00073848 -0.00894504]\n",
            "The bias c gradient is: \n",
            " [-0.0184787]\n",
            "\n",
            "RUN:\n",
            "  63\n",
            "The sum of the b update is\n",
            " [ 0.00677232 -0.00074085 -0.00894297]\n",
            "The b biases before the update are:\n",
            " [[-0.19634056 -0.69628506  0.03259865]]\n",
            "Updated bs are:\n",
            " [[-0.19640828 -0.69627765  0.03268808]]\n",
            "The W1 is: \n",
            " [[-0.6620873   0.42683001  1.1051577 ]\n",
            " [-2.5608228   1.21044511  1.1914958 ]\n",
            " [-1.53786334 -2.88842247 -0.99250502]]\n",
            "The W1 gradient is: \n",
            " [[-0.10789622 -0.11813684 -0.28001574]\n",
            " [-0.09123288 -0.18740183 -0.32810947]\n",
            " [ 0.29680372  0.42989008  0.03704284]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.23083258]\n",
            " [-0.27835308]\n",
            " [-0.29357628]]\n",
            "The biases b gradient is:\n",
            " [ 0.00677232 -0.00074085 -0.00894297]\n",
            "The bias c gradient is: \n",
            " [-0.01836985]\n",
            "\n",
            "RUN:\n",
            "  64\n",
            "The sum of the b update is\n",
            " [ 0.00673684 -0.00074298 -0.00894098]\n",
            "The b biases before the update are:\n",
            " [[-0.19640828 -0.69627765  0.03268808]]\n",
            "Updated bs are:\n",
            " [[-0.19647565 -0.69627022  0.03277749]]\n",
            "The W1 is: \n",
            " [[-0.66100731  0.42800629  1.1079339 ]\n",
            " [-2.55990679  1.21231057  1.19474904]\n",
            " [-1.54083429 -2.89272247 -0.99290669]]\n",
            "The W1 gradient is: \n",
            " [[-0.1079987  -0.11762817 -0.27762013]\n",
            " [-0.09160165 -0.18654619 -0.32532418]\n",
            " [ 0.2970957   0.42999964  0.04016665]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22983434]\n",
            " [-0.2765684 ]\n",
            " [-0.29035072]]\n",
            "The biases b gradient is:\n",
            " [ 0.00673684 -0.00074298 -0.00894098]\n",
            "The bias c gradient is: \n",
            " [-0.01826276]\n",
            "\n",
            "RUN:\n",
            "  65\n",
            "The sum of the b update is\n",
            " [ 0.00670122 -0.00074487 -0.00893908]\n",
            "The b biases before the update are:\n",
            " [[-0.19647565 -0.69627022  0.03277749]]\n",
            "Updated bs are:\n",
            " [[-0.19654266 -0.69626277  0.03286688]]\n",
            "The W1 is: \n",
            " [[-0.65992635  0.42917758  1.11068657]\n",
            " [-2.55898716  1.2141676   1.19797489]\n",
            " [-1.54380809 -2.89702347 -0.99333906]]\n",
            "The W1 gradient is: \n",
            " [[-0.10809622 -0.11712923 -0.27526754]\n",
            " [-0.09196282 -0.18570252 -0.32258511]\n",
            " [ 0.29737941  0.43010046  0.04323753]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22885472]\n",
            " [-0.27481125]\n",
            " [-0.28715935]]\n",
            "The biases b gradient is:\n",
            " [ 0.00670122 -0.00074487 -0.00893908]\n",
            "The bias c gradient is: \n",
            " [-0.01815738]\n",
            "\n",
            "RUN:\n",
            "  66\n",
            "The sum of the b update is\n",
            " [ 0.00666546 -0.00074652 -0.00893727]\n",
            "The b biases before the update are:\n",
            " [[-0.19654266 -0.69626277  0.03286688]]\n",
            "Updated bs are:\n",
            " [[-0.19660931 -0.69625531  0.03295625]]\n",
            "The W1 is: \n",
            " [[-0.65884446  0.43034398  1.11341614]\n",
            " [-2.55806399  1.2160163   1.20117381]\n",
            " [-1.54678464 -2.9013254  -0.99380163]]\n",
            "The W1 gradient is: \n",
            " [[-0.1081888  -0.11663983 -0.27295708]\n",
            " [-0.09231644 -0.18487061 -0.31989134]\n",
            " [ 0.29765485  0.43019268  0.04625649]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22789324]\n",
            " [-0.27308117]\n",
            " [-0.28400202]]\n",
            "The biases b gradient is:\n",
            " [ 0.00666546 -0.00074652 -0.00893727]\n",
            "The bias c gradient is: \n",
            " [-0.01805369]\n",
            "\n",
            "RUN:\n",
            "  67\n",
            "The sum of the b update is\n",
            " [ 0.00662955 -0.00074794 -0.00893556]\n",
            "The b biases before the update are:\n",
            " [[-0.19660931 -0.69625531  0.03295625]]\n",
            "Updated bs are:\n",
            " [[-0.19667561 -0.69624783  0.03304561]]\n",
            "The W1 is: \n",
            " [[-0.6577617   0.43150558  1.11612302]\n",
            " [-2.55713737  1.21785681  1.20434622]\n",
            " [-1.54976386 -2.90562816 -0.99429387]]\n",
            "The W1 gradient is: \n",
            " [[-0.10827647 -0.11615976 -0.2706879 ]\n",
            " [-0.09266254 -0.18405024 -0.31724196]\n",
            " [ 0.29792203  0.43027642  0.04922452]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22694945]\n",
            " [-0.27137771]\n",
            " [-0.28087859]]\n",
            "The biases b gradient is:\n",
            " [ 0.00662955 -0.00074794 -0.00893556]\n",
            "The bias c gradient is: \n",
            " [-0.01795166]\n",
            "\n",
            "RUN:\n",
            "  68\n",
            "The sum of the b update is\n",
            " [ 0.00659351 -0.00074914 -0.00893393]\n",
            "The b biases before the update are:\n",
            " [[-0.19667561 -0.69624783  0.03304561]]\n",
            "Updated bs are:\n",
            " [[-0.19674154 -0.69624034  0.03313495]]\n",
            "The W1 is: \n",
            " [[-0.65667811  0.43266247  1.11880761]\n",
            " [-2.55620736  1.21968922  1.20749259]\n",
            " [-1.55274567 -2.90993168 -0.9948153 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10835925 -0.11568882 -0.26845915]\n",
            " [-0.09300116 -0.1832412  -0.3146361 ]\n",
            " [ 0.29818094  0.43035181  0.05214257]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2260229 ]\n",
            " [-0.26970042]\n",
            " [-0.27778888]]\n",
            "The biases b gradient is:\n",
            " [ 0.00659351 -0.00074914 -0.00893393]\n",
            "The bias c gradient is: \n",
            " [-0.01785126]\n",
            "\n",
            "RUN:\n",
            "  69\n",
            "The sum of the b update is\n",
            " [ 0.00655731 -0.00075011 -0.0089324 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19674154 -0.69624034  0.03313495]]\n",
            "Updated bs are:\n",
            " [[-0.19680712 -0.69623284  0.03322427]]\n",
            "The W1 is: \n",
            " [[-0.65559374  0.43381474  1.12147031]\n",
            " [-2.55527403  1.22151365  1.21061331]\n",
            " [-1.55572998 -2.91423587 -0.99536541]]\n",
            "The W1 gradient is: \n",
            " [[-0.10843716 -0.11522684 -0.26627   ]\n",
            " [-0.09333234 -0.18244329 -0.31207287]\n",
            " [ 0.29843157  0.43041899  0.0550116 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22511315]\n",
            " [-0.26804886]\n",
            " [-0.27473271]]\n",
            "The biases b gradient is:\n",
            " [ 0.00655731 -0.00075011 -0.0089324 ]\n",
            "The bias c gradient is: \n",
            " [-0.01775246]\n",
            "\n",
            "RUN:\n",
            "  70\n",
            "The sum of the b update is\n",
            " [ 0.00652098 -0.00075087 -0.00893095]\n",
            "The b biases before the update are:\n",
            " [[-0.19680712 -0.69623284  0.03322427]]\n",
            "Updated bs are:\n",
            " [[-0.19687233 -0.69622533  0.03331358]]\n",
            "The W1 is: \n",
            " [[-0.65450863  0.43496247  1.12411151]\n",
            " [-2.55433747  1.22333021  1.21370883]\n",
            " [-1.55871672 -2.91854065 -0.99594374]]\n",
            "The W1 gradient is: \n",
            " [[-0.10851023 -0.11477363 -0.26411964]\n",
            " [-0.0936561  -0.1816563  -0.30955143]\n",
            " [ 0.29867395  0.43047808  0.05783254]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2242198 ]\n",
            " [-0.2664226 ]\n",
            " [-0.27170988]]\n",
            "The biases b gradient is:\n",
            " [ 0.00652098 -0.00075087 -0.00893095]\n",
            "The bias c gradient is: \n",
            " [-0.01765525]\n",
            "\n",
            "RUN:\n",
            "  71\n",
            "The sum of the b update is\n",
            " [ 0.0064845  -0.00075142 -0.0089296 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19687233 -0.69622533  0.03331358]]\n",
            "Updated bs are:\n",
            " [[-0.19693717 -0.69621781  0.03340288]]\n",
            "The W1 is: \n",
            " [[-0.65342285  0.43610576  1.12673158]\n",
            " [-2.55339775  1.22513901  1.21677954]\n",
            " [-1.5617058  -2.92284595 -0.9965498 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10857849 -0.11432899 -0.26200727]\n",
            " [-0.09397249 -0.18088003 -0.30707093]\n",
            " [ 0.29890805  0.4305292   0.0606063 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22334244]\n",
            " [-0.26482122]\n",
            " [-0.26872019]]\n",
            "The biases b gradient is:\n",
            " [ 0.0064845  -0.00075142 -0.0089296 ]\n",
            "The bias c gradient is: \n",
            " [-0.01755958]\n",
            "\n",
            "RUN:\n",
            "  72\n",
            "The sum of the b update is\n",
            " [ 0.00644788 -0.00075176 -0.00892834]\n",
            "The b biases before the update are:\n",
            " [[-0.19693717 -0.69621781  0.03340288]]\n",
            "Updated bs are:\n",
            " [[-0.19700165 -0.6962103   0.03349216]]\n",
            "The W1 is: \n",
            " [[-0.65233643  0.43724469  1.12933091]\n",
            " [-2.55245493  1.22694016  1.21982584]\n",
            " [-1.56469714 -2.92715167 -0.99718314]]\n",
            "The W1 gradient is: \n",
            " [[-0.10864195 -0.11389277 -0.25993211]\n",
            " [-0.09428154 -0.1801143  -0.30463055]\n",
            " [ 0.29913388  0.43057248  0.06333379]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22248066]\n",
            " [-0.26324428]\n",
            " [-0.26576342]]\n",
            "The biases b gradient is:\n",
            " [ 0.00644788 -0.00075176 -0.00892834]\n",
            "The bias c gradient is: \n",
            " [-0.01746545]\n",
            "\n",
            "RUN:\n",
            "  73\n",
            "The sum of the b update is\n",
            " [ 0.00641111 -0.0007519  -0.00892717]\n",
            "The b biases before the update are:\n",
            " [[-0.19700165 -0.6962103   0.03349216]]\n",
            "Updated bs are:\n",
            " [[-0.19706576 -0.69620278  0.03358143]]\n",
            "The W1 is: \n",
            " [[-0.65124942  0.43837934  1.13190984]\n",
            " [-2.5515091   1.22873375  1.22284814]\n",
            " [-1.56769066 -2.93145775 -0.9978433 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10870064 -0.11346479 -0.25789337]\n",
            " [-0.09458327 -0.17935892 -0.30222948]\n",
            " [ 0.29935145  0.43060802  0.06601589]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22163409]\n",
            " [-0.26169138]\n",
            " [-0.26283935]]\n",
            "The biases b gradient is:\n",
            " [ 0.00641111 -0.0007519  -0.00892717]\n",
            "The bias c gradient is: \n",
            " [-0.01737281]\n",
            "\n",
            "RUN:\n",
            "  74\n",
            "The sum of the b update is\n",
            " [ 0.0063742  -0.00075183 -0.00892609]\n",
            "The b biases before the update are:\n",
            " [[-0.19706576 -0.69620278  0.03358143]]\n",
            "Updated bs are:\n",
            " [[-0.1971295  -0.69619526  0.03367069]]\n",
            "The W1 is: \n",
            " [[-0.65016188  0.43950979  1.13446874]\n",
            " [-2.55056032  1.23051988  1.22584681]\n",
            " [-1.57068626 -2.93576411 -0.99852983]]\n",
            "The W1 gradient is: \n",
            " [[-0.10875458 -0.11304488 -0.25589033]\n",
            " [-0.09487773 -0.17861369 -0.29986694]\n",
            " [ 0.29956075  0.43063595  0.06865346]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.22080234]\n",
            " [-0.26016212]\n",
            " [-0.25994774]]\n",
            "The biases b gradient is:\n",
            " [ 0.0063742  -0.00075183 -0.00892609]\n",
            "The bias c gradient is: \n",
            " [-0.01728164]\n",
            "\n",
            "RUN:\n",
            "  75\n",
            "The sum of the b update is\n",
            " [ 0.00633714 -0.00075157 -0.0089251 ]\n",
            "The b biases before the update are:\n",
            " [[-0.1971295  -0.69619526  0.03367069]]\n",
            "Updated bs are:\n",
            " [[-0.19719288 -0.69618774  0.03375994]]\n",
            "The W1 is: \n",
            " [[-0.64907384  0.44063611  1.13700796]\n",
            " [-2.54960867  1.23229867  1.22882223]\n",
            " [-1.57368388 -2.94007067 -0.99924231]]\n",
            "The W1 gradient is: \n",
            " [[-0.1088038  -0.11263287 -0.25392222]\n",
            " [-0.09516496 -0.17787845 -0.29754214]\n",
            " [ 0.29976178  0.43065638  0.07124734]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21998506]\n",
            " [-0.25865608]\n",
            " [-0.25708835]]\n",
            "The biases b gradient is:\n",
            " [ 0.00633714 -0.00075157 -0.0089251 ]\n",
            "The bias c gradient is: \n",
            " [-0.01719193]\n",
            "\n",
            "RUN:\n",
            "  76\n",
            "The sum of the b update is\n",
            " [ 0.00629994 -0.00075112 -0.00892419]\n",
            "The b biases before the update are:\n",
            " [[-0.19719288 -0.69618774  0.03375994]]\n",
            "Updated bs are:\n",
            " [[-0.19725588 -0.69618023  0.03384919]]\n",
            "The W1 is: \n",
            " [[-0.64798536  0.4417584   1.13952785]\n",
            " [-2.54865422  1.2340702   1.23177477]\n",
            " [-1.57668343 -2.94437737 -0.99998029]]\n",
            "The W1 gradient is: \n",
            " [[-0.10884831 -0.11222861 -0.25198834]\n",
            " [-0.09544497 -0.17715301 -0.29525432]\n",
            " [ 0.29995455  0.43066943  0.07379837]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2191819 ]\n",
            " [-0.25717287]\n",
            " [-0.25426092]]\n",
            "The biases b gradient is:\n",
            " [ 0.00629994 -0.00075112 -0.00892419]\n",
            "The bias c gradient is: \n",
            " [-0.01710364]\n",
            "\n",
            "RUN:\n",
            "  77\n",
            "The sum of the b update is\n",
            " [ 0.00626259 -0.00075048 -0.00892338]\n",
            "The b biases before the update are:\n",
            " [[-0.19725588 -0.69618023  0.03384919]]\n",
            "Updated bs are:\n",
            " [[-0.1973185  -0.69617273  0.03393842]]\n",
            "The W1 is: \n",
            " [[-0.64689647  0.44287672  1.14202873]\n",
            " [-2.54769705  1.23583457  1.2347048 ]\n",
            " [-1.57968482 -2.94868412 -1.00074336]]\n",
            "The W1 gradient is: \n",
            " [[-0.10888814 -0.11183195 -0.25008798]\n",
            " [-0.09571782 -0.1764372  -0.29300275]\n",
            " [ 0.30013905  0.4306752   0.07630735]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2183925 ]\n",
            " [-0.25571211]\n",
            " [-0.25146522]]\n",
            "The biases b gradient is:\n",
            " [ 0.00626259 -0.00075048 -0.00892338]\n",
            "The bias c gradient is: \n",
            " [-0.01701675]\n",
            "\n",
            "RUN:\n",
            "  78\n",
            "The sum of the b update is\n",
            " [ 0.00622509 -0.00074965 -0.00892266]\n",
            "The b biases before the update are:\n",
            " [[-0.1973185  -0.69617273  0.03393842]]\n",
            "Updated bs are:\n",
            " [[-0.19738075 -0.69616523  0.03402765]]\n",
            "The W1 is: \n",
            " [[-0.64580724  0.44399115  1.14451093]\n",
            " [-2.54673721  1.23759188  1.23761267]\n",
            " [-1.58268797 -2.95299086 -1.00153111]]\n",
            "The W1 gradient is: \n",
            " [[-0.10892331 -0.11144272 -0.24822043]\n",
            " [-0.09598353 -0.17573085 -0.2907867 ]\n",
            " [ 0.3003153   0.4306738   0.07877508]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21761653]\n",
            " [-0.25427341]\n",
            " [-0.24870096]]\n",
            "The biases b gradient is:\n",
            " [ 0.00622509 -0.00074965 -0.00892266]\n",
            "The bias c gradient is: \n",
            " [-0.01693124]\n",
            "\n",
            "RUN:\n",
            "  79\n",
            "The sum of the b update is\n",
            " [ 0.00618745 -0.00074864 -0.00892202]\n",
            "The b biases before the update are:\n",
            " [[-0.19738075 -0.69616523  0.03402765]]\n",
            "Updated bs are:\n",
            " [[-0.19744263 -0.69615774  0.03411687]]\n",
            "The W1 is: \n",
            " [[-0.6447177   0.44510176  1.14697478]\n",
            " [-2.54577479  1.23934222  1.24049872]\n",
            " [-1.5856928  -2.95729751 -1.00234314]]\n",
            "The W1 gradient is: \n",
            " [[-0.10895383 -0.11106078 -0.24638503]\n",
            " [-0.09624213 -0.17503379 -0.28860545]\n",
            " [ 0.30048329  0.43066534  0.08120233]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21685367]\n",
            " [-0.25285639]\n",
            " [-0.2459679 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00618745 -0.00074864 -0.00892202]\n",
            "The bias c gradient is: \n",
            " [-0.01684709]\n",
            "\n",
            "RUN:\n",
            "  80\n",
            "The sum of the b update is\n",
            " [ 0.00614966 -0.00074746 -0.00892147]\n",
            "The b biases before the update are:\n",
            " [[-0.19744263 -0.69615774  0.03411687]]\n",
            "Updated bs are:\n",
            " [[-0.19750412 -0.69615027  0.03420608]]\n",
            "The W1 is: \n",
            " [[-0.64362791  0.44620862  1.14942059]\n",
            " [-2.54480985  1.24108567  1.2433633 ]\n",
            " [-1.58869923 -2.96160401 -1.00317904]]\n",
            "The W1 gradient is: \n",
            " [[-0.10897975 -0.11068599 -0.24458111]\n",
            " [-0.09649367 -0.17434587 -0.2864583 ]\n",
            " [ 0.30064302  0.43064992  0.08358987]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2161036 ]\n",
            " [-0.25146069]\n",
            " [-0.24326575]]\n",
            "The biases b gradient is:\n",
            " [ 0.00614966 -0.00074746 -0.00892147]\n",
            "The bias c gradient is: \n",
            " [-0.01676427]\n",
            "\n",
            "RUN:\n",
            "  81\n",
            "The sum of the b update is\n",
            " [ 0.00611172 -0.00074609 -0.00892101]\n",
            "The b biases before the update are:\n",
            " [[-0.19750412 -0.69615027  0.03420608]]\n",
            "Updated bs are:\n",
            " [[-0.19756524 -0.69614281  0.03429529]]\n",
            "The W1 is: \n",
            " [[-0.6425379   0.4473118   1.15184867]\n",
            " [-2.54384247  1.24282234  1.24620675]\n",
            " [-1.59170718 -2.96591029 -1.00403842]]\n",
            "The W1 gradient is: \n",
            " [[-0.10900106 -0.11031821 -0.24280802]\n",
            " [-0.09673817 -0.17366692 -0.28434458]\n",
            " [ 0.3007945   0.43062765  0.08593844]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21536601]\n",
            " [-0.25008593]\n",
            " [-0.24059424]]\n",
            "The biases b gradient is:\n",
            " [ 0.00611172 -0.00074609 -0.00892101]\n",
            "The bias c gradient is: \n",
            " [-0.01668275]\n",
            "\n",
            "RUN:\n",
            "  82\n",
            "The sum of the b update is\n",
            " [ 0.00607363 -0.00074456 -0.00892063]\n",
            "The b biases before the update are:\n",
            " [[-0.19756524 -0.69614281  0.03429529]]\n",
            "Updated bs are:\n",
            " [[-0.19762598 -0.69613536  0.0343845 ]]\n",
            "The W1 is: \n",
            " [[-0.64144772  0.44841137  1.15425932]\n",
            " [-2.54287271  1.24455231  1.24902939]\n",
            " [-1.59471656 -2.97021627 -1.00492091]]\n",
            "The W1 gradient is: \n",
            " [[-0.1090178  -0.10995728 -0.24106512]\n",
            " [-0.09697567 -0.17299678 -0.28226361]\n",
            " [ 0.30093774  0.43059863  0.08824876]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.2146406 ]\n",
            " [-0.24873177]\n",
            " [-0.2379531 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00607363 -0.00074456 -0.00892063]\n",
            "The bias c gradient is: \n",
            " [-0.01660253]\n",
            "\n",
            "RUN:\n",
            "  83\n",
            "The sum of the b update is\n",
            " [ 0.00603539 -0.00074285 -0.00892034]\n",
            "The b biases before the update are:\n",
            " [[-0.19762598 -0.69613536  0.0343845 ]]\n",
            "Updated bs are:\n",
            " [[-0.19768633 -0.69612793  0.0344737 ]]\n",
            "The W1 is: \n",
            " [[-0.64035742  0.4495074   1.15665284]\n",
            " [-2.54190065  1.24627566  1.25183153]\n",
            " [-1.59772728 -2.9745219  -1.00582612]]\n",
            "The W1 gradient is: \n",
            " [[-0.10902999 -0.10960309 -0.2393518 ]\n",
            " [-0.09720621 -0.17233531 -0.28021474]\n",
            " [ 0.30107273  0.43056295  0.09052155]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21392707]\n",
            " [-0.24739784]\n",
            " [-0.23534203]]\n",
            "The biases b gradient is:\n",
            " [ 0.00603539 -0.00074285 -0.00892034]\n",
            "The bias c gradient is: \n",
            " [-0.01652357]\n",
            "\n",
            "RUN:\n",
            "  84\n",
            "The sum of the b update is\n",
            " [ 0.005997   -0.00074098 -0.00892013]\n",
            "The b biases before the update are:\n",
            " [[-0.19768633 -0.69612793  0.0344737 ]]\n",
            "Updated bs are:\n",
            " [[-0.1977463  -0.69612052  0.0345629 ]]\n",
            "The W1 is: \n",
            " [[-0.63926704  0.45059996  1.15902952]\n",
            " [-2.54092635  1.24799249  1.25461351]\n",
            " [-1.60073928 -2.97882711 -1.0067537 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10903765 -0.10925549 -0.23766744]\n",
            " [-0.09742982 -0.17168235 -0.27819734]\n",
            " [ 0.30119949  0.43052072  0.0927575 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21322514]\n",
            " [-0.24608379]\n",
            " [-0.23276077]]\n",
            "The biases b gradient is:\n",
            " [ 0.005997   -0.00074098 -0.00892013]\n",
            "The bias c gradient is: \n",
            " [-0.01644585]\n",
            "\n",
            "RUN:\n",
            "  85\n",
            "The sum of the b update is\n",
            " [ 0.00595846 -0.00073895 -0.00892001]\n",
            "The b biases before the update are:\n",
            " [[-0.1977463  -0.69612052  0.0345629 ]]\n",
            "Updated bs are:\n",
            " [[-0.19780589 -0.69611313  0.0346521 ]]\n",
            "The W1 is: \n",
            " [[-0.63817663  0.4516891   1.16138963]\n",
            " [-2.53994989  1.24970287  1.25737561]\n",
            " [-1.60375246 -2.98313183 -1.00770327]]\n",
            "The W1 gradient is: \n",
            " [[-0.1090408  -0.10891436 -0.23601146]\n",
            " [-0.09764654 -0.17103776 -0.27621077]\n",
            " [ 0.30131803  0.43047202  0.09495729]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21253454]\n",
            " [-0.2447893 ]\n",
            " [-0.23020902]]\n",
            "The biases b gradient is:\n",
            " [ 0.00595846 -0.00073895 -0.00892001]\n",
            "The bias c gradient is: \n",
            " [-0.01636936]\n",
            "\n",
            "RUN:\n",
            "  86\n",
            "The sum of the b update is\n",
            " [ 0.00591978 -0.00073676 -0.00891996]\n",
            "The b biases before the update are:\n",
            " [[-0.19780589 -0.69611313  0.0346521 ]]\n",
            "Updated bs are:\n",
            " [[-0.19786508 -0.69610577  0.0347413 ]]\n",
            "The W1 is: \n",
            " [[-0.63708624  0.4527749   1.16373346]\n",
            " [-2.53897132  1.25140688  1.26011816]\n",
            " [-1.60676674 -2.987436   -1.00867449]]\n",
            "The W1 gradient is: \n",
            " [[-0.10903946 -0.10857957 -0.23438326]\n",
            " [-0.09785639 -0.17040139 -0.27425442]\n",
            " [ 0.30142834  0.43041696  0.09712158]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21185498]\n",
            " [-0.24351402]\n",
            " [-0.22768649]]\n",
            "The biases b gradient is:\n",
            " [ 0.00591978 -0.00073676 -0.00891996]\n",
            "The bias c gradient is: \n",
            " [-0.01629407]\n",
            "\n",
            "RUN:\n",
            "  87\n",
            "The sum of the b update is\n",
            " [ 0.00588094 -0.00073441 -0.00892   ]\n",
            "The b biases before the update are:\n",
            " [[-0.19786508 -0.69610577  0.0347413 ]]\n",
            "Updated bs are:\n",
            " [[-0.19792389 -0.69609842  0.0348305 ]]\n",
            "The W1 is: \n",
            " [[-0.6359959   0.45385741  1.16606129]\n",
            " [-2.53799073  1.25310461  1.26284144]\n",
            " [-1.60978205 -2.99173956 -1.009667  ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10903366 -0.108251   -0.23278229]\n",
            " [-0.09805943 -0.16977311 -0.27232771]\n",
            " [ 0.30153044  0.43035562  0.09925102]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21118621]\n",
            " [-0.24225761]\n",
            " [-0.22519289]]\n",
            "The biases b gradient is:\n",
            " [ 0.00588094 -0.00073441 -0.00892   ]\n",
            "The bias c gradient is: \n",
            " [-0.01621997]\n",
            "\n",
            "RUN:\n",
            "  88\n",
            "The sum of the b update is\n",
            " [ 0.00584195 -0.0007319  -0.00892012]\n",
            "The b biases before the update are:\n",
            " [[-0.19792389 -0.69609842  0.0348305 ]]\n",
            "Updated bs are:\n",
            " [[-0.19798231 -0.6960911   0.0349197 ]]\n",
            "The W1 is: \n",
            " [[-0.63490567  0.45493669  1.16837337]\n",
            " [-2.53700817  1.25479614  1.26554574]\n",
            " [-1.61279829 -2.99604244 -1.01068046]]\n",
            "The W1 gradient is: \n",
            " [[-0.10902341 -0.10792852 -0.23120798]\n",
            " [-0.09825567 -0.16915277 -0.27043004]\n",
            " [ 0.30162433  0.43028811  0.10134625]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.21052796]\n",
            " [-0.24101977]\n",
            " [-0.22272794]]\n",
            "The biases b gradient is:\n",
            " [ 0.00584195 -0.0007319  -0.00892012]\n",
            "The bias c gradient is: \n",
            " [-0.01614703]\n",
            "\n",
            "RUN:\n",
            "  89\n",
            "The sum of the b update is\n",
            " [ 0.00580281 -0.00072925 -0.00892032]\n",
            "The b biases before the update are:\n",
            " [[-0.19798231 -0.6960911   0.0349197 ]]\n",
            "Updated bs are:\n",
            " [[-0.19804034 -0.69608381  0.03500891]]\n",
            "The W1 is: \n",
            " [[-0.63381558  0.45601281  1.17066997]\n",
            " [-2.53602372  1.25648154  1.26823134]\n",
            " [-1.61581539 -3.00034458 -1.01171454]]\n",
            "The W1 gradient is: \n",
            " [[-0.10900875 -0.10761202 -0.2296598 ]\n",
            " [-0.09844517 -0.16854025 -0.26856084]\n",
            " [ 0.30171004  0.43021449  0.10340789]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20987999]\n",
            " [-0.23980015]\n",
            " [-0.22029133]]\n",
            "The biases b gradient is:\n",
            " [ 0.00580281 -0.00072925 -0.00892032]\n",
            "The bias c gradient is: \n",
            " [-0.01607523]\n",
            "\n",
            "RUN:\n",
            "  90\n",
            "The sum of the b update is\n",
            " [ 0.00576352 -0.00072644 -0.0089206 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19804034 -0.69608381  0.03500891]]\n",
            "Updated bs are:\n",
            " [[-0.19809798 -0.69607655  0.03509811]]\n",
            "The W1 is: \n",
            " [[-0.63272568  0.45708582  1.17295134]\n",
            " [-2.53503744  1.25816089  1.27089854]\n",
            " [-1.61883326 -3.00464593 -1.01276891]]\n",
            "The W1 gradient is: \n",
            " [[-0.10898969 -0.10730139 -0.2281372 ]\n",
            " [-0.09862796 -0.1679354  -0.26671955]\n",
            " [ 0.30178755  0.43013488  0.10543654]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20924205]\n",
            " [-0.23859846]\n",
            " [-0.21788278]]\n",
            "The biases b gradient is:\n",
            " [ 0.00576352 -0.00072644 -0.0089206 ]\n",
            "The bias c gradient is: \n",
            " [-0.01600456]\n",
            "\n",
            "RUN:\n",
            "  91\n",
            "The sum of the b update is\n",
            " [ 0.00572407 -0.00072349 -0.00892096]\n",
            "The b biases before the update are:\n",
            " [[-0.19809798 -0.69607655  0.03509811]]\n",
            "Updated bs are:\n",
            " [[-0.19815522 -0.69606931  0.03518732]]\n",
            "The W1 is: \n",
            " [[-0.63163602  0.45815579  1.17521773]\n",
            " [-2.5340494   1.25983428  1.2735476 ]\n",
            " [-1.62185183 -3.00894642 -1.01384323]]\n",
            "The W1 gradient is: \n",
            " [[-0.10896625 -0.1069965  -0.22663969]\n",
            " [-0.09880406 -0.1673381  -0.26490564]\n",
            " [ 0.3018569   0.43004935  0.10743278]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20861389]\n",
            " [-0.23741438]\n",
            " [-0.215502  ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00572407 -0.00072349 -0.00892096]\n",
            "The bias c gradient is: \n",
            " [-0.01593499]\n",
            "\n",
            "RUN:\n",
            "  92\n",
            "The sum of the b update is\n",
            " [ 0.00568448 -0.00072039 -0.00892139]\n",
            "The b biases before the update are:\n",
            " [[-0.19815522 -0.69606931  0.03518732]]\n",
            "Updated bs are:\n",
            " [[-0.19821206 -0.69606211  0.03527654]]\n",
            "The W1 is: \n",
            " [[-0.63054664  0.45922276  1.1774694 ]\n",
            " [-2.53305967  1.26150176  1.27617878]\n",
            " [-1.62487101 -3.013246   -1.01493721]]\n",
            "The W1 gradient is: \n",
            " [[-0.10893847 -0.10669726 -0.22516673]\n",
            " [-0.09897354 -0.16674822 -0.26311855]\n",
            " [ 0.30191809  0.42995798  0.10939721]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20799529]\n",
            " [-0.2362476 ]\n",
            " [-0.21314869]]\n",
            "The biases b gradient is:\n",
            " [ 0.00568448 -0.00072039 -0.00892139]\n",
            "The bias c gradient is: \n",
            " [-0.01586651]\n",
            "\n",
            "RUN:\n",
            "  93\n",
            "The sum of the b update is\n",
            " [ 0.00564473 -0.00071715 -0.0089219 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19821206 -0.69606211  0.03527654]]\n",
            "Updated bs are:\n",
            " [[-0.19826851 -0.69605494  0.03536575]]\n",
            "The W1 is: \n",
            " [[-0.62945757  0.4602868   1.17970658]\n",
            " [-2.5320683   1.26316341  1.27879236]\n",
            " [-1.62789073 -3.01754461 -1.01605051]]\n",
            "The W1 gradient is: \n",
            " [[-0.10890636 -0.10640354 -0.22371785]\n",
            " [-0.09913641 -0.16616563 -0.26135777]\n",
            " [ 0.30197113  0.42986086  0.11133038]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20738601]\n",
            " [-0.23509783]\n",
            " [-0.21082256]]\n",
            "The biases b gradient is:\n",
            " [ 0.00564473 -0.00071715 -0.0089219 ]\n",
            "The bias c gradient is: \n",
            " [-0.01579911]\n",
            "\n",
            "RUN:\n",
            "  94\n",
            "The sum of the b update is\n",
            " [ 0.00560483 -0.00071378 -0.00892249]\n",
            "The b biases before the update are:\n",
            " [[-0.19826851 -0.69605494  0.03536575]]\n",
            "Updated bs are:\n",
            " [[-0.19832456 -0.6960478   0.03545498]]\n",
            "The W1 is: \n",
            " [[-0.62836887  0.46134795  1.18192951]\n",
            " [-2.53107537  1.26481932  1.28138859]\n",
            " [-1.63091089 -3.02184219 -1.01718284]]\n",
            "The W1 gradient is: \n",
            " [[-0.10886994 -0.10611525 -0.22229256]\n",
            " [-0.09929272 -0.16559022 -0.2596228 ]\n",
            " [ 0.30201605  0.42975808  0.11323284]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20678583]\n",
            " [-0.23396477]\n",
            " [-0.20852331]]\n",
            "The biases b gradient is:\n",
            " [ 0.00560483 -0.00071378 -0.00892249]\n",
            "The bias c gradient is: \n",
            " [-0.01573275]\n",
            "\n",
            "RUN:\n",
            "  95\n",
            "The sum of the b update is\n",
            " [ 0.00556477 -0.00071026 -0.00892315]\n",
            "The b biases before the update are:\n",
            " [[-0.19832456 -0.6960478   0.03545498]]\n",
            "Updated bs are:\n",
            " [[-0.1983802  -0.6960407   0.03554421]]\n",
            "The W1 is: \n",
            " [[-0.62728058  0.46240627  1.18413841]\n",
            " [-2.53008095  1.26646954  1.28396772]\n",
            " [-1.63393141 -3.02613869 -1.01833389]]\n",
            "The W1 gradient is: \n",
            " [[-0.10882926 -0.10583228 -0.22089037]\n",
            " [-0.09944251 -0.16502187 -0.25791312]\n",
            " [ 0.30205284  0.42964971  0.11510513]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20619454]\n",
            " [-0.23284814]\n",
            " [-0.20625066]]\n",
            "The biases b gradient is:\n",
            " [ 0.00556477 -0.00071026 -0.00892315]\n",
            "The bias c gradient is: \n",
            " [-0.01566743]\n",
            "\n",
            "RUN:\n",
            "  96\n",
            "The sum of the b update is\n",
            " [ 0.00552457 -0.00070661 -0.00892389]\n",
            "The b biases before the update are:\n",
            " [[-0.1983802  -0.6960407   0.03554421]]\n",
            "Updated bs are:\n",
            " [[-0.19843545 -0.69603363  0.03563345]]\n",
            "The W1 is: \n",
            " [[-0.62619274  0.46346182  1.18633352]\n",
            " [-2.52908509  1.26811414  1.28653   ]\n",
            " [-1.63695223 -3.03043405 -1.01950337]]\n",
            "The W1 gradient is: \n",
            " [[-0.10878431 -0.10555453 -0.21951084]\n",
            " [-0.09958582 -0.16446045 -0.25622826]\n",
            " [ 0.30208154  0.42953584  0.11694778]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20561192]\n",
            " [-0.23174765]\n",
            " [-0.20400431]]\n",
            "The biases b gradient is:\n",
            " [ 0.00552457 -0.00070661 -0.00892389]\n",
            "The bias c gradient is: \n",
            " [-0.01560313]\n",
            "\n",
            "RUN:\n",
            "  97\n",
            "The sum of the b update is\n",
            " [ 0.00548421 -0.00070283 -0.0089247 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19843545 -0.69603363  0.03563345]]\n",
            "Updated bs are:\n",
            " [[-0.19849029 -0.6960266   0.0357227 ]]\n",
            "The W1 is: \n",
            " [[-0.62510539  0.46451464  1.18851505]\n",
            " [-2.52808786  1.2697532   1.28907568]\n",
            " [-1.63997325 -3.03472821 -1.02069098]]\n",
            "The W1 gradient is: \n",
            " [[-0.10873515 -0.1052819  -0.21815351]\n",
            " [-0.09972268 -0.16390585 -0.25456773]\n",
            " [ 0.30210216  0.42941654  0.1187613 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20503775]\n",
            " [-0.23066301]\n",
            " [-0.20178397]]\n",
            "The biases b gradient is:\n",
            " [ 0.00548421 -0.00070283 -0.0089247 ]\n",
            "The bias c gradient is: \n",
            " [-0.01553982]\n",
            "\n",
            "RUN:\n",
            "  98\n",
            "The sum of the b update is\n",
            " [ 0.0054437  -0.00069892 -0.00892558]\n",
            "The b biases before the update are:\n",
            " [[-0.19849029 -0.6960266   0.0357227 ]]\n",
            "Updated bs are:\n",
            " [[-0.19854473 -0.69601961  0.03581195]]\n",
            "The W1 is: \n",
            " [[-0.62401857  0.46556478  1.19068323]\n",
            " [-2.52708933  1.27138678  1.29160499]\n",
            " [-1.6429944  -3.03902113 -1.02189644]]\n",
            "The W1 gradient is: \n",
            " [[-0.10868178 -0.1050143  -0.21681793]\n",
            " [-0.09985314 -0.16335795 -0.25293108]\n",
            " [ 0.30211471  0.42929189  0.12054619]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20447185]\n",
            " [-0.22959396]\n",
            " [-0.19958935]]\n",
            "The biases b gradient is:\n",
            " [ 0.0054437  -0.00069892 -0.00892558]\n",
            "The bias c gradient is: \n",
            " [-0.01547751]\n",
            "\n",
            "RUN:\n",
            "  99\n",
            "The sum of the b update is\n",
            " [ 0.00540303 -0.00069488 -0.00892653]\n",
            "The b biases before the update are:\n",
            " [[-0.19854473 -0.69601961  0.03581195]]\n",
            "Updated bs are:\n",
            " [[-0.19859876 -0.69601266  0.03590122]]\n",
            "The W1 is: \n",
            " [[-0.62293233  0.4666123   1.19283827]\n",
            " [-2.52608956  1.27301494  1.29411817]\n",
            " [-1.64601559 -3.04331275 -1.02311947]]\n",
            "The W1 gradient is: \n",
            " [[-0.10862424 -0.10475163 -0.21550368]\n",
            " [-0.09997724 -0.16281666 -0.25131784]\n",
            " [ 0.30211923  0.42916197  0.12230294]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20391401]\n",
            " [-0.22854022]\n",
            " [-0.19742017]]\n",
            "The biases b gradient is:\n",
            " [ 0.00540303 -0.00069488 -0.00892653]\n",
            "The bias c gradient is: \n",
            " [-0.01541616]\n",
            "\n",
            "RUN:\n",
            "  100\n",
            "The sum of the b update is\n",
            " [ 0.00536221 -0.00069071 -0.00892755]\n",
            "The b biases before the update are:\n",
            " [[-0.19859876 -0.69601266  0.03590122]]\n",
            "Updated bs are:\n",
            " [[-0.19865238 -0.69600576  0.03599049]]\n",
            "The W1 is: \n",
            " [[-0.6218467   0.46765723  1.19498037]\n",
            " [-2.52508861  1.27463776  1.29661544]\n",
            " [-1.64903675 -3.04760302 -1.02435979]]\n",
            "The W1 gradient is: \n",
            " [[-0.10856254 -0.10449379 -0.21421033]\n",
            " [-0.10009502 -0.16228185 -0.24972757]\n",
            " [ 0.30211571  0.42902685  0.12403204]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20336404]\n",
            " [-0.22750154]\n",
            " [-0.19527614]]\n",
            "The biases b gradient is:\n",
            " [ 0.00536221 -0.00069071 -0.00892755]\n",
            "The bias c gradient is: \n",
            " [-0.01535576]\n",
            "\n",
            "RUN:\n",
            "  101\n",
            "The sum of the b update is\n",
            " [ 0.00532124 -0.00068642 -0.00892864]\n",
            "The b biases before the update are:\n",
            " [[-0.19865238 -0.69600576  0.03599049]]\n",
            "Updated bs are:\n",
            " [[-0.19870559 -0.69599889  0.03607978]]\n",
            "The W1 is: \n",
            " [[-0.62076173  0.46869964  1.19710975]\n",
            " [-2.52408654  1.2762553   1.29909704]\n",
            " [-1.65205779 -3.05189189 -1.02561713]]\n",
            "The W1 gradient is: \n",
            " [[-0.10849673 -0.10424069 -0.21293747]\n",
            " [-0.10020653 -0.16175343 -0.24815983]\n",
            " [ 0.3021042   0.42888661  0.12573394]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20282174]\n",
            " [-0.22647763]\n",
            " [-0.19315696]]\n",
            "The biases b gradient is:\n",
            " [ 0.00532124 -0.00068642 -0.00892864]\n",
            "The bias c gradient is: \n",
            " [-0.01529631]\n",
            "\n",
            "RUN:\n",
            "  102\n",
            "The sum of the b update is\n",
            " [ 0.00528012 -0.00068201 -0.00892981]\n",
            "The b biases before the update are:\n",
            " [[-0.19870559 -0.69599889  0.03607978]]\n",
            "Updated bs are:\n",
            " [[-0.19875839 -0.69599207  0.03616908]]\n",
            "The W1 is: \n",
            " [[-0.61967746  0.46973956  1.19922659]\n",
            " [-2.52308343  1.27786761  1.30156318]\n",
            " [-1.65507864 -3.0561793  -1.02689122]]\n",
            "The W1 gradient is: \n",
            " [[-0.10842683 -0.10399226 -0.2116847 ]\n",
            " [-0.1003118  -0.16123128 -0.24661421]\n",
            " [ 0.30208471  0.42874131  0.1274091 ]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20228693]\n",
            " [-0.22546826]\n",
            " [-0.19106236]]\n",
            "The biases b gradient is:\n",
            " [ 0.00528012 -0.00068201 -0.00892981]\n",
            "The bias c gradient is: \n",
            " [-0.01523777]\n",
            "\n",
            "RUN:\n",
            "  103\n",
            "The sum of the b update is\n",
            " [ 0.00523885 -0.00067748 -0.00893104]\n",
            "The b biases before the update are:\n",
            " [[-0.19875839 -0.69599207  0.03616908]]\n",
            "Updated bs are:\n",
            " [[-0.19881078 -0.6959853   0.03625839]]\n",
            "The W1 is: \n",
            " [[-0.61859394  0.47077705  1.20133111]\n",
            " [-2.52207932  1.27947476  1.30401409]\n",
            " [-1.65809921 -3.06046521 -1.0281818 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10835286 -0.10374839 -0.21045162]\n",
            " [-0.10041087 -0.16071531 -0.24509027]\n",
            " [ 0.30205727  0.42859104  0.12905797]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20175944]\n",
            " [-0.22447316]\n",
            " [-0.18899206]]\n",
            "The biases b gradient is:\n",
            " [ 0.00523885 -0.00067748 -0.00893104]\n",
            "The bias c gradient is: \n",
            " [-0.01518014]\n",
            "\n",
            "RUN:\n",
            "  104\n",
            "The sum of the b update is\n",
            " [ 0.00519742 -0.00067283 -0.00893233]\n",
            "The b biases before the update are:\n",
            " [[-0.19881078 -0.6959853   0.03625839]]\n",
            "Updated bs are:\n",
            " [[-0.19886276 -0.69597857  0.03634771]]\n",
            "The W1 is: \n",
            " [[-0.61751119  0.47181214  1.20342349]\n",
            " [-2.52107428  1.28107682  1.30644996]\n",
            " [-1.66111943 -3.06474957 -1.02948861]]\n",
            "The W1 gradient is: \n",
            " [[-0.10827486 -0.10350901 -0.20923786]\n",
            " [-0.1005038  -0.1602054  -0.24358762]\n",
            " [ 0.3020219   0.42843585  0.13068099]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20123907]\n",
            " [-0.2234921 ]\n",
            " [-0.18694577]]\n",
            "The biases b gradient is:\n",
            " [ 0.00519742 -0.00067283 -0.00893233]\n",
            "The bias c gradient is: \n",
            " [-0.0151234]\n",
            "\n",
            "RUN:\n",
            "  105\n",
            "The sum of the b update is\n",
            " [ 0.00515584 -0.00066806 -0.0089337 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19886276 -0.69597857  0.03634771]]\n",
            "Updated bs are:\n",
            " [[-0.19891432 -0.69597189  0.03643705]]\n",
            "The W1 is: \n",
            " [[-0.61642926  0.47284488  1.20550392]\n",
            " [-2.52006837  1.28267383  1.30887102]\n",
            " [-1.66413922 -3.06903233 -1.0308114 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10819284 -0.10327402 -0.20804302]\n",
            " [-0.10059062 -0.15970148 -0.24210586]\n",
            " [ 0.30197862  0.42827583  0.13227858]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20072567]\n",
            " [-0.22252481]\n",
            " [-0.18492322]]\n",
            "The biases b gradient is:\n",
            " [ 0.00515584 -0.00066806 -0.0089337 ]\n",
            "The bias c gradient is: \n",
            " [-0.01506754]\n",
            "\n",
            "RUN:\n",
            "  106\n",
            "The sum of the b update is\n",
            " [ 0.00511411 -0.00066318 -0.00893513]\n",
            "The b biases before the update are:\n",
            " [[-0.19891432 -0.69597189  0.03643705]]\n",
            "Updated bs are:\n",
            " [[-0.19896546 -0.69596526  0.0365264 ]]\n",
            "The W1 is: \n",
            " [[-0.61534819  0.47387531  1.20757259]\n",
            " [-2.51906166  1.28426587  1.31127747]\n",
            " [-1.66715849 -3.07331344 -1.03214991]]\n",
            "The W1 gradient is: \n",
            " [[-0.10810685 -0.10304336 -0.20686675]\n",
            " [-0.10067139 -0.15920343 -0.2406446 ]\n",
            " [ 0.30192747  0.42811103  0.13385115]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.20021905]\n",
            " [-0.22157107]\n",
            " [-0.18292412]]\n",
            "The biases b gradient is:\n",
            " [ 0.00511411 -0.00066318 -0.00893513]\n",
            "The bias c gradient is: \n",
            " [-0.01501255]\n",
            "\n",
            "RUN:\n",
            "  107\n",
            "The sum of the b update is\n",
            " [ 0.00507223 -0.00065819 -0.00893662]\n",
            "The b biases before the update are:\n",
            " [[-0.19896546 -0.69596526  0.0365264 ]]\n",
            "Updated bs are:\n",
            " [[-0.19901618 -0.69595868  0.03661577]]\n",
            "The W1 is: \n",
            " [[-0.61426802  0.47490348  1.20962967]\n",
            " [-2.5180542   1.28585298  1.3136695 ]\n",
            " [-1.67017717 -3.07759285 -1.0335039 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10801691 -0.10281693 -0.20570869]\n",
            " [-0.10074614 -0.15871116 -0.23920346]\n",
            " [ 0.30186848  0.42794153  0.13539912]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19971906]\n",
            " [-0.22063064]\n",
            " [-0.18094821]]\n",
            "The biases b gradient is:\n",
            " [ 0.00507223 -0.00065819 -0.00893662]\n",
            "The bias c gradient is: \n",
            " [-0.0149584]\n",
            "\n",
            "RUN:\n",
            "  108\n",
            "The sum of the b update is\n",
            " [ 0.00503019 -0.00065309 -0.00893818]\n",
            "The b biases before the update are:\n",
            " [[-0.19901618 -0.69595868  0.03661577]]\n",
            "Updated bs are:\n",
            " [[-0.19906648 -0.69595214  0.03670515]]\n",
            "The W1 is: \n",
            " [[-0.61318879  0.47592943  1.21167536]\n",
            " [-2.51704605  1.28743522  1.31604732]\n",
            " [-1.67319519 -3.08187053 -1.03487313]]\n",
            "The W1 gradient is: \n",
            " [[-0.10792306 -0.10259467 -0.20456848]\n",
            " [-0.10081492 -0.15822458 -0.23778207]\n",
            " [ 0.30180167  0.42776739  0.13692288]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19922553]\n",
            " [-0.21970328]\n",
            " [-0.17899521]]\n",
            "The biases b gradient is:\n",
            " [ 0.00503019 -0.00065309 -0.00893818]\n",
            "The bias c gradient is: \n",
            " [-0.01490509]\n",
            "\n",
            "RUN:\n",
            "  109\n",
            "The sum of the b update is\n",
            " [ 0.00498801 -0.00064788 -0.0089398 ]\n",
            "The b biases before the update are:\n",
            " [[-0.19906648 -0.69595214  0.03670515]]\n",
            "Updated bs are:\n",
            " [[-0.19911636 -0.69594567  0.03679455]]\n",
            "The W1 is: \n",
            " [[-0.61211054  0.47695319  1.21370982]\n",
            " [-2.51603727  1.28901266  1.31841112]\n",
            " [-1.67621246 -3.08614641 -1.03625736]]\n",
            "The W1 gradient is: \n",
            " [[-0.10782532 -0.10237648 -0.20344578]\n",
            " [-0.10087777 -0.1577436  -0.23638006]\n",
            " [ 0.30172707  0.42758867  0.13842282]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19873831]\n",
            " [-0.21878877]\n",
            " [-0.17706484]]\n",
            "The biases b gradient is:\n",
            " [ 0.00498801 -0.00064788 -0.0089398 ]\n",
            "The bias c gradient is: \n",
            " [-0.0148526]\n",
            "\n",
            "RUN:\n",
            "  110\n",
            "The sum of the b update is\n",
            " [ 0.00494568 -0.00064256 -0.00894148]\n",
            "The b biases before the update are:\n",
            " [[-0.19911636 -0.69594567  0.03679455]]\n",
            "Updated bs are:\n",
            " [[-0.19916582 -0.69593924  0.03688396]]\n",
            "The W1 is: \n",
            " [[-0.6110333   0.47797482  1.21573322]\n",
            " [-2.51502792  1.29058534  1.32076109]\n",
            " [-1.67922891 -3.09042047 -1.03765635]]\n",
            "The W1 gradient is: \n",
            " [[-0.10772372 -0.10216231 -0.20234026]\n",
            " [-0.10093475 -0.15726812 -0.23499708]\n",
            " [ 0.30164472  0.42740545  0.13989931]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19825723]\n",
            " [-0.21788689]\n",
            " [-0.17515685]]\n",
            "The biases b gradient is:\n",
            " [ 0.00494568 -0.00064256 -0.00894148]\n",
            "The bias c gradient is: \n",
            " [-0.01480092]\n",
            "\n",
            "RUN:\n",
            "  111\n",
            "The sum of the b update is\n",
            " [ 0.00490319 -0.00063713 -0.00894323]\n",
            "The b biases before the update are:\n",
            " [[-0.19916582 -0.69593924  0.03688396]]\n",
            "Updated bs are:\n",
            " [[-0.19921485 -0.69593287  0.03697339]]\n",
            "The W1 is: \n",
            " [[-0.60995712  0.47899434  1.21774573]\n",
            " [-2.51401807  1.29215332  1.32309742]\n",
            " [-1.68224446 -3.09469265 -1.03906988]]\n",
            "The W1 gradient is: \n",
            " [[-0.10761831 -0.10195206 -0.20125159]\n",
            " [-0.1009859  -0.15679806 -0.23363279]\n",
            " [ 0.30155465  0.42721779  0.14135274]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19778215]\n",
            " [-0.2169974 ]\n",
            " [-0.17327096]]\n",
            "The biases b gradient is:\n",
            " [ 0.00490319 -0.00063713 -0.00894323]\n",
            "The bias c gradient is: \n",
            " [-0.01475004]\n",
            "\n",
            "RUN:\n",
            "  112\n",
            "The sum of the b update is\n",
            " [ 0.00486056 -0.0006316  -0.00894504]\n",
            "The b biases before the update are:\n",
            " [[-0.19921485 -0.69593287  0.03697339]]\n",
            "Updated bs are:\n",
            " [[-0.19926346 -0.69592655  0.03706284]]\n",
            "The W1 is: \n",
            " [[-0.60888203  0.48001179  1.21974753]\n",
            " [-2.51300775  1.29371665  1.32542029]\n",
            " [-1.68525902 -3.0989629  -1.04049771]]\n",
            "The W1 gradient is: \n",
            " [[-0.1075091  -0.10174568 -0.20017944]\n",
            " [-0.10103127 -0.15633334 -0.23228683]\n",
            " [ 0.30145689  0.42702574  0.14278345]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19731291]\n",
            " [-0.2161201 ]\n",
            " [-0.17140692]]\n",
            "The biases b gradient is:\n",
            " [ 0.00486056 -0.0006316  -0.00894504]\n",
            "The bias c gradient is: \n",
            " [-0.01469995]\n",
            "\n",
            "RUN:\n",
            "  113\n",
            "The sum of the b update is\n",
            " [ 0.00481778 -0.00062597 -0.00894691]\n",
            "The b biases before the update are:\n",
            " [[-0.19926346 -0.69592655  0.03706284]]\n",
            "Updated bs are:\n",
            " [[-0.19931163 -0.69592029  0.03715231]]\n",
            "The W1 is: \n",
            " [[-0.60780806  0.48102722  1.22173876]\n",
            " [-2.51199704  1.29527539  1.32772988]\n",
            " [-1.68827254 -3.1032312  -1.04193963]]\n",
            "The W1 gradient is: \n",
            " [[-0.10739613 -0.10154309 -0.19912351]\n",
            " [-0.10107091 -0.15587385 -0.23095889]\n",
            " [ 0.30135148  0.42682937  0.14419181]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19684939]\n",
            " [-0.21525477]\n",
            " [-0.16956445]]\n",
            "The biases b gradient is:\n",
            " [ 0.00481778 -0.00062597 -0.00894691]\n",
            "The bias c gradient is: \n",
            " [-0.01465062]\n",
            "\n",
            "RUN:\n",
            "  114\n",
            "The sum of the b update is\n",
            " [ 0.00477485 -0.00062024 -0.00894883]\n",
            "The b biases before the update are:\n",
            " [[-0.19931163 -0.69592029  0.03715231]]\n",
            "Updated bs are:\n",
            " [[-0.19935938 -0.69591409  0.0372418 ]]\n",
            "The W1 is: \n",
            " [[-0.60673527  0.48204067  1.2237196 ]\n",
            " [-2.51098599  1.29682959  1.33002637]\n",
            " [-1.69128492 -3.10749748 -1.04339541]]\n",
            "The W1 gradient is: \n",
            " [[-0.10727945 -0.10134422 -0.19808349]\n",
            " [-0.10110486 -0.15541954 -0.22964863]\n",
            " [ 0.30123846  0.42662874  0.14557815]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19639142]\n",
            " [-0.2144012 ]\n",
            " [-0.1677433 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00477485 -0.00062024 -0.00894883]\n",
            "The bias c gradient is: \n",
            " [-0.01460205]\n",
            "\n",
            "RUN:\n",
            "  115\n",
            "The sum of the b update is\n",
            " [ 0.00473177 -0.00061441 -0.00895082]\n",
            "The b biases before the update are:\n",
            " [[-0.19935938 -0.69591409  0.0372418 ]]\n",
            "Updated bs are:\n",
            " [[-0.1994067  -0.69590795  0.03733131]]\n",
            "The W1 is: \n",
            " [[-0.60566368  0.48305216  1.22569019]\n",
            " [-2.50997466  1.29837929  1.33230992]\n",
            " [-1.6942961  -3.11176172 -1.04486484]]\n",
            "The W1 gradient is: \n",
            " [[-0.10715907 -0.101149   -0.19705908]\n",
            " [-0.10113318 -0.1549703  -0.22835574]\n",
            " [ 0.30111786  0.4264239   0.14694283]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19593887]\n",
            " [-0.21355919]\n",
            " [-0.16594321]]\n",
            "The biases b gradient is:\n",
            " [ 0.00473177 -0.00061441 -0.00895082]\n",
            "The bias c gradient is: \n",
            " [-0.01455423]\n",
            "\n",
            "RUN:\n",
            "  116\n",
            "The sum of the b update is\n",
            " [ 0.00468854 -0.00060848 -0.00895286]\n",
            "The b biases before the update are:\n",
            " [[-0.1994067  -0.69590795  0.03733131]]\n",
            "Updated bs are:\n",
            " [[-0.19945358 -0.69590186  0.03742084]]\n",
            "The W1 is: \n",
            " [[-0.60459333  0.48406173  1.22765069]\n",
            " [-2.5089631   1.29992455  1.33458072]\n",
            " [-1.697306   -3.11602387 -1.0463477 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10703504 -0.10095737 -0.19604998]\n",
            " [-0.10115591 -0.15452606 -0.22707991]\n",
            " [ 0.30098972  0.42621493  0.14828617]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19549161]\n",
            " [-0.21272853]\n",
            " [-0.16416393]]\n",
            "The biases b gradient is:\n",
            " [ 0.00468854 -0.00060848 -0.00895286]\n",
            "The bias c gradient is: \n",
            " [-0.01450715]\n",
            "\n",
            "RUN:\n",
            "  117\n",
            "The sum of the b update is\n",
            " [ 0.00464517 -0.00060246 -0.00895497]\n",
            "The b biases before the update are:\n",
            " [[-0.19945358 -0.69590186  0.03742084]]\n",
            "Updated bs are:\n",
            " [[-0.19950004 -0.69589584  0.03751039]]\n",
            "The W1 is: \n",
            " [[-0.60352426  0.48506942  1.22960125]\n",
            " [-2.50795137  1.30146542  1.33683893]\n",
            " [-1.70031454 -3.12028389 -1.04784379]]\n",
            "The W1 gradient is: \n",
            " [[-0.10690738 -0.10076926 -0.19505592]\n",
            " [-0.10117311 -0.15408674 -0.22582083]\n",
            " [ 0.30085409  0.42600187  0.14960849]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.1950495 ]\n",
            " [-0.21190903]\n",
            " [-0.1624052 ]]\n",
            "The biases b gradient is:\n",
            " [ 0.00464517 -0.00060246 -0.00895497]\n",
            "The bias c gradient is: \n",
            " [-0.01446079]\n",
            "\n",
            "RUN:\n",
            "  118\n",
            "The sum of the b update is\n",
            " [ 0.00460166 -0.00059634 -0.00895713]\n",
            "The b biases before the update are:\n",
            " [[-0.19950004 -0.69589584  0.03751039]]\n",
            "Updated bs are:\n",
            " [[-0.19954605 -0.69588987  0.03759996]]\n",
            "The W1 is: \n",
            " [[-0.60245649  0.48607527  1.23154201]\n",
            " [-2.50693952  1.30300194  1.33908471]\n",
            " [-1.70332165 -3.12454174 -1.04935289]]\n",
            "The W1 gradient is: \n",
            " [[-0.10677615 -0.1005846  -0.1940766 ]\n",
            " [-0.10118483 -0.15365226 -0.2245782 ]\n",
            " [ 0.300711    0.42578479  0.15091011]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19461241]\n",
            " [-0.21110048]\n",
            " [-0.16066678]]\n",
            "The biases b gradient is:\n",
            " [ 0.00460166 -0.00059634 -0.00895713]\n",
            "The bias c gradient is: \n",
            " [-0.01441514]\n",
            "\n",
            "RUN:\n",
            "  119\n",
            "The sum of the b update is\n",
            " [ 0.004558   -0.00059013 -0.00895934]\n",
            "The b biases before the update are:\n",
            " [[-0.19954605 -0.69588987  0.03759996]]\n",
            "Updated bs are:\n",
            " [[-0.19959163 -0.69588397  0.03768955]]\n",
            "The W1 is: \n",
            " [[-0.60139008  0.4870793   1.23347313]\n",
            " [-2.50592761  1.30453417  1.34131823]\n",
            " [-1.70632726 -3.12879738 -1.0508748 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10664137 -0.10040334 -0.19311177]\n",
            " [-0.10119112 -0.15322255 -0.22335174]\n",
            " [ 0.3005605   0.42556373  0.15219134]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19418022]\n",
            " [-0.2103027 ]\n",
            " [-0.15894841]]\n",
            "The biases b gradient is:\n",
            " [ 0.004558   -0.00059013 -0.00895934]\n",
            "The bias c gradient is: \n",
            " [-0.01437019]\n",
            "\n",
            "RUN:\n",
            "  120\n",
            "The sum of the b update is\n",
            " [ 0.00451419 -0.00058382 -0.00896161]\n",
            "The b biases before the update are:\n",
            " [[-0.19959163 -0.69588397  0.03768955]]\n",
            "Updated bs are:\n",
            " [[-0.19963678 -0.69587813  0.03777917]]\n",
            "The W1 is: \n",
            " [[-0.60032505  0.48808156  1.23539474]\n",
            " [-2.50491569  1.30606214  1.34353964]\n",
            " [-1.70933128 -3.13305076 -1.05240933]]\n",
            "The W1 gradient is: \n",
            " [[-0.10650307 -0.10022541 -0.19216114]\n",
            " [-0.10119202 -0.15279753 -0.22214116]\n",
            " [ 0.30040263  0.42533877  0.15345248]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.1937528 ]\n",
            " [-0.20951549]\n",
            " [-0.15724986]]\n",
            "The biases b gradient is:\n",
            " [ 0.00451419 -0.00058382 -0.00896161]\n",
            "The bias c gradient is: \n",
            " [-0.01432593]\n",
            "The current average loss is\n",
            " 6\n",
            "\n",
            "RUN:\n",
            "  121\n",
            "The sum of the b update is\n",
            " [ 0.00447024 -0.00057743 -0.00896393]\n",
            "The b biases before the update are:\n",
            " [[-0.19963678 -0.69587813  0.03777917]]\n",
            "Updated bs are:\n",
            " [[-0.19968148 -0.69587236  0.03786881]]\n",
            "The W1 is: \n",
            " [[-0.59926144  0.48908206  1.23730699]\n",
            " [-2.50390382  1.30758591  1.3457491 ]\n",
            " [-1.71233366 -3.13730186 -1.05395626]]\n",
            "The W1 gradient is: \n",
            " [[-0.1063613  -0.10005075 -0.19122445]\n",
            " [-0.1011876  -0.15237713 -0.22094618]\n",
            " [ 0.30023744  0.42510994  0.15469384]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19333003]\n",
            " [-0.20873868]\n",
            " [-0.15557088]]\n",
            "The biases b gradient is:\n",
            " [ 0.00447024 -0.00057743 -0.00896393]\n",
            "The bias c gradient is: \n",
            " [-0.01428235]\n",
            "The current average loss is\n",
            " 6\n",
            "\n",
            "RUN:\n",
            "  122\n",
            "The sum of the b update is\n",
            " [ 0.00442615 -0.00057095 -0.00896631]\n",
            "The b biases before the update are:\n",
            " [[-0.19968148 -0.69587236  0.03786881]]\n",
            "Updated bs are:\n",
            " [[-0.19972574 -0.69586665  0.03795847]]\n",
            "The W1 is: \n",
            " [[-0.59819928  0.49008086  1.23921   ]\n",
            " [-2.50289204  1.30910553  1.34794677]\n",
            " [-1.71533431 -3.14155064 -1.05551542]]\n",
            "The W1 gradient is: \n",
            " [[-0.10621609 -0.09987931 -0.19030146]\n",
            " [-0.1011779  -0.15196127 -0.21976653]\n",
            " [ 0.30006496  0.4248773   0.15591569]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19291178]\n",
            " [-0.20797207]\n",
            " [-0.15391122]]\n",
            "The biases b gradient is:\n",
            " [ 0.00442615 -0.00057095 -0.00896631]\n",
            "The bias c gradient is: \n",
            " [-0.01423944]\n",
            "The current average loss is\n",
            " 6\n",
            "\n",
            "RUN:\n",
            "  123\n",
            "The sum of the b update is\n",
            " [ 0.00438192 -0.00056438 -0.00896875]\n",
            "The b biases before the update are:\n",
            " [[-0.19972574 -0.69586665  0.03795847]]\n",
            "Updated bs are:\n",
            " [[-0.19976956 -0.69586101  0.03804816]]\n",
            "The W1 is: \n",
            " [[-0.5971386   0.49107797  1.24110392]\n",
            " [-2.50188041  1.31062103  1.35013279]\n",
            " [-1.71833316 -3.14579705 -1.0570866 ]]\n",
            "The W1 gradient is: \n",
            " [[-0.10606749 -0.09971101 -0.18939191]\n",
            " [-0.10116299 -0.15154989 -0.21860194]\n",
            " [ 0.29988525  0.42464092  0.15711833]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19249795]\n",
            " [-0.20721548]\n",
            " [-0.15227066]]\n",
            "The biases b gradient is:\n",
            " [ 0.00438192 -0.00056438 -0.00896875]\n",
            "The bias c gradient is: \n",
            " [-0.01419719]\n",
            "The current average loss is\n",
            " 6\n",
            "\n",
            "RUN:\n",
            "  124\n",
            "The sum of the b update is\n",
            " [ 0.00433755 -0.00055772 -0.00897123]\n",
            "The b biases before the update are:\n",
            " [[-0.19976956 -0.69586101  0.03804816]]\n",
            "Updated bs are:\n",
            " [[-0.19981293 -0.69585543  0.03813787]]\n",
            "The W1 is: \n",
            " [[-0.59607945  0.49207342  1.24298888]\n",
            " [-2.50086898  1.31213245  1.35230731]\n",
            " [-1.72133014 -3.15004105 -1.05866962]]\n",
            "The W1 gradient is: \n",
            " [[-0.10591552 -0.09954582 -0.18849556]\n",
            " [-0.10114291 -0.15114291 -0.21745216]\n",
            " [ 0.29969836  0.42440083  0.15830202]]\n",
            "The W2 gradient  is: \n",
            " [[ 0.19208841]\n",
            " [-0.20646875]\n",
            " [-0.15064896]]\n",
            "The biases b gradient is:\n",
            " [ 0.00433755 -0.00055772 -0.00897123]\n",
            "The bias c gradient is: \n",
            " [-0.01415559]\n",
            "The current average loss is\n",
            " 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-LT5-yg0CmF9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}